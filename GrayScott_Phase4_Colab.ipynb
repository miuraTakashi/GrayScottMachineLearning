{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# ğŸš€ Gray-Scott Phase 4: å¯¾æ¯”å­¦ç¿’ãƒ»è©•ä¾¡æ”¹å–„ï¼ˆGoogle Colabï¼‰\n",
        "\n",
        "**ç›®æ¨™**: Phase 3 (0.5144) â†’ Phase 4 (0.55+) ã¸ã®ã•ã‚‰ãªã‚‹å‘ä¸Š\n",
        "\n",
        "**ä¸»è¦æ”¹å–„ç‚¹**:\n",
        "- âœ… å¯¾æ¯”å­¦ç¿’ï¼ˆContrastive Learningï¼‰\n",
        "- âœ… éšå±¤çš„ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°åˆ†æ\n",
        "- âœ… åŒ…æ‹¬çš„è©•ä¾¡æŒ‡æ¨™ã‚·ã‚¹ãƒ†ãƒ \n",
        "- âœ… æ”¹å–„ã•ã‚ŒãŸè¨“ç·´ãƒ«ãƒ¼ãƒ—\n",
        "- âœ… GPUé«˜é€ŸåŒ–ï¼ˆCPUæ¯” 5-10å€ï¼‰\n",
        "- âœ… Google Driveé€£æº\n",
        "\n",
        "**å‰ææ¡ä»¶**: Google Driveã®`ãƒã‚¤ãƒ‰ãƒ©ã‚¤ãƒ–/GrayScottML/gif/`ã«1500å€‹ã®GIFãƒ•ã‚¡ã‚¤ãƒ«ã‚’é…ç½®\n",
        "\n",
        "**å®Ÿè¡Œæ™‚é–“**: **GPU 8-12åˆ†** ğŸƒâ€â™‚ï¸ğŸ’¨\n",
        "\n",
        "**æ½œåœ¨æ¬¡å…ƒ**: 512æ¬¡å…ƒï¼ˆPhase 3ã¨åŒç­‰ï¼‰\n",
        "\n",
        "**æ–°æ©Ÿèƒ½**:\n",
        "- f-kãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿é¡ä¼¼æ€§ã«åŸºã¥ãå¯¾æ¯”å­¦ç¿’\n",
        "- éšå±¤çš„ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ï¼ˆWardæ³•ï¼‰\n",
        "- 8ã¤ã®åŒ…æ‹¬çš„è©•ä¾¡æŒ‡æ¨™\n",
        "- è¿‘å‚ä¸€è‡´åº¦ãƒ»ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åˆ†é›¢åº¦ãƒ»ã‚¯ãƒ©ã‚¹ã‚¿å®‰å®šæ€§\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ğŸ“‹ Step 1: ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ— & Google Driveæ¥ç¶š\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "import imageio.v2 as imageio\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
        "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
        "from scipy.spatial.distance import pdist, squareform\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "import time\n",
        "import pickle\n",
        "from typing import List, Tuple, Dict, Optional\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# GPUç¢ºèª\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory/1e9:.1f} GB\")\n",
        "    device = torch.device('cuda')\n",
        "    # GPUæœ€é©åŒ–è¨­å®š\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    torch.backends.cudnn.deterministic = False\n",
        "else:\n",
        "    print(\"âš ï¸ GPU not available. Please enable GPU in Runtime > Change runtime type\")\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "print(f\"ğŸš€ Phase 4 Using device: {device}\")\n",
        "\n",
        "# ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n",
        "try:\n",
        "    import imageio\n",
        "    import seaborn\n",
        "    from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
        "    print(\"âœ… All packages available\")\n",
        "except ImportError:\n",
        "    print(\"ğŸ“¦ Installing required packages...\")\n",
        "    !pip install imageio scikit-learn seaborn scipy\n",
        "    import imageio\n",
        "    import seaborn\n",
        "    from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
        "    print(\"âœ… Packages installed successfully\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Google Driveæ¥ç¶šã¨ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹ç¢ºèª\n",
        "from google.colab import drive\n",
        "\n",
        "# Google Driveã‚’ãƒã‚¦ãƒ³ãƒˆ\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹è¨­å®š\n",
        "GIF_FOLDER_PATH = '/content/drive/MyDrive/GrayScottML/gif'\n",
        "\n",
        "# ãƒ‡ãƒ¼ã‚¿ç¢ºèª\n",
        "if os.path.exists(GIF_FOLDER_PATH):\n",
        "    gif_files = [f for f in os.listdir(GIF_FOLDER_PATH) if f.endswith('.gif')]\n",
        "    gif_count = len(gif_files)\n",
        "    print(f\"âœ… Google Drive connected successfully!\")\n",
        "    print(f\"ğŸ“ Path: {GIF_FOLDER_PATH}\")\n",
        "    print(f\"ğŸ¬ GIF files found: {gif_count}\")\n",
        "    \n",
        "    if gif_count >= 1000:\n",
        "        print(\"ğŸ‰ Ready for Phase 4 training!\")\n",
        "    else:\n",
        "        print(f\"âš ï¸ Not enough files. Expected: 1500, Found: {gif_count}\")\n",
        "        print(\"Please upload more GIF files to Google Drive.\")\n",
        "else:\n",
        "    print(\"âŒ Google Drive path not found!\")\n",
        "    print(f\"Expected path: {GIF_FOLDER_PATH}\")\n",
        "    print(\"Please ensure the following structure exists:\")\n",
        "    print(\"  MyDrive/\")\n",
        "    print(\"  â””â”€â”€ GrayScottML/\")\n",
        "    print(\"      â””â”€â”€ gif/\")\n",
        "    print(\"          â”œâ”€â”€ GrayScott-f0.0100-k0.0400-00.gif\")\n",
        "    print(\"          â””â”€â”€ ... (1500 files)\")\n",
        "    raise FileNotFoundError(\"Please set up the correct folder structure in Google Drive\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ğŸ§  Step 2: Phase 4 ãƒ¢ãƒ‡ãƒ«å®Ÿè£…ï¼ˆå¯¾æ¯”å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ ï¼‰\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ================================\n",
        "# 1. å¯¾æ¯”å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ \n",
        "# ================================\n",
        "\n",
        "class ContrastiveLoss(nn.Module):\n",
        "    \"\"\"f-kãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿é¡ä¼¼æ€§ã«åŸºã¥ãå¯¾æ¯”å­¦ç¿’æå¤±\"\"\"\n",
        "    \n",
        "    def __init__(self, temperature=0.5, margin=1.0):\n",
        "        super().__init__()\n",
        "        self.temperature = temperature\n",
        "        self.margin = margin\n",
        "        self.cosine_similarity = nn.CosineSimilarity(dim=2)\n",
        "    \n",
        "    def forward(self, features, f_params, k_params):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            features: (batch_size, feature_dim) - æ½œåœ¨è¡¨ç¾\n",
        "            f_params: (batch_size,) - fãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿\n",
        "            k_params: (batch_size,) - kãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿\n",
        "        \"\"\"\n",
        "        batch_size = features.size(0)\n",
        "        \n",
        "        # f-kãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç©ºé–“ã§ã®é¡ä¼¼æ€§è¨ˆç®—\n",
        "        f_diff = torch.abs(f_params.unsqueeze(1) - f_params.unsqueeze(0))\n",
        "        k_diff = torch.abs(k_params.unsqueeze(1) - k_params.unsqueeze(0))\n",
        "        \n",
        "        # æ­£è¦åŒ–ã•ã‚ŒãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è·é›¢\n",
        "        param_distance = torch.sqrt(f_diff**2 + k_diff**2)\n",
        "        \n",
        "        # é¡ä¼¼æ€§é–¾å€¤ï¼ˆè¿‘ã„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯é¡ä¼¼ã€é ã„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯éé¡ä¼¼ï¼‰\n",
        "        similarity_threshold = 0.01  # f-kç©ºé–“ã§ã®é–¾å€¤\n",
        "        positive_mask = param_distance < similarity_threshold\n",
        "        negative_mask = param_distance > similarity_threshold * 3\n",
        "        \n",
        "        # ç‰¹å¾´é‡ã®é¡ä¼¼æ€§è¨ˆç®—\n",
        "        features_norm = F.normalize(features, p=2, dim=1)\n",
        "        similarity_matrix = torch.mm(features_norm, features_norm.t()) / self.temperature\n",
        "        \n",
        "        # å¯¾æ¯”å­¦ç¿’æå¤±\n",
        "        positive_loss = 0\n",
        "        negative_loss = 0\n",
        "        \n",
        "        if positive_mask.sum() > 0:\n",
        "            positive_sim = similarity_matrix[positive_mask]\n",
        "            positive_loss = -torch.log(torch.exp(positive_sim).sum() / torch.exp(similarity_matrix).sum())\n",
        "        \n",
        "        if negative_mask.sum() > 0:\n",
        "            negative_sim = similarity_matrix[negative_mask]\n",
        "            negative_loss = torch.log(torch.exp(negative_sim).sum() / torch.exp(similarity_matrix).sum())\n",
        "        \n",
        "        contrastive_loss = positive_loss + negative_loss\n",
        "        \n",
        "        return contrastive_loss\n",
        "\n",
        "class ProjectionHead(nn.Module):\n",
        "    \"\"\"å¯¾æ¯”å­¦ç¿’ç”¨å°„å½±ãƒ˜ãƒƒãƒ‰\"\"\"\n",
        "    \n",
        "    def __init__(self, input_dim=512, hidden_dim=256, output_dim=128):\n",
        "        super().__init__()\n",
        "        self.projection = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.BatchNorm1d(hidden_dim),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(hidden_dim, output_dim),\n",
        "            nn.BatchNorm1d(output_dim)\n",
        "        )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.projection(x)\n",
        "\n",
        "print(\"âœ… å¯¾æ¯”å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ å®Ÿè£…å®Œäº†\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ================================\n",
        "# 2. éšå±¤çš„ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°åˆ†æ\n",
        "# ================================\n",
        "\n",
        "class HierarchicalClusteringAnalysis:\n",
        "    \"\"\"éšå±¤çš„ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°åˆ†æã‚·ã‚¹ãƒ†ãƒ \"\"\"\n",
        "    \n",
        "    def __init__(self, method='ward', metric='euclidean'):\n",
        "        self.method = method\n",
        "        self.metric = metric\n",
        "        self.linkage_matrix = None\n",
        "        self.optimal_clusters = None\n",
        "    \n",
        "    def fit(self, features):\n",
        "        \"\"\"éšå±¤çš„ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°å®Ÿè¡Œ\"\"\"\n",
        "        # ç‰¹å¾´é‡ã®æ¨™æº–åŒ–\n",
        "        scaler = StandardScaler()\n",
        "        features_scaled = scaler.fit_transform(features)\n",
        "        \n",
        "        # éšå±¤çš„ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°\n",
        "        self.linkage_matrix = linkage(features_scaled, method=self.method, metric=self.metric)\n",
        "        \n",
        "        # æœ€é©ã‚¯ãƒ©ã‚¹ã‚¿æ•°ã®æ±ºå®š\n",
        "        self.optimal_clusters = self._find_optimal_clusters(features_scaled)\n",
        "        \n",
        "        return self\n",
        "    \n",
        "    def _find_optimal_clusters(self, features, max_clusters=20):\n",
        "        \"\"\"æœ€é©ã‚¯ãƒ©ã‚¹ã‚¿æ•°ã®è‡ªå‹•æ±ºå®š\"\"\"\n",
        "        silhouette_scores = []\n",
        "        cluster_range = range(2, min(max_clusters + 1, len(features) // 2))\n",
        "        \n",
        "        for n_clusters in cluster_range:\n",
        "            cluster_labels = fcluster(self.linkage_matrix, n_clusters, criterion='maxclust')\n",
        "            \n",
        "            if len(np.unique(cluster_labels)) > 1:\n",
        "                silhouette_avg = silhouette_score(features, cluster_labels)\n",
        "                silhouette_scores.append(silhouette_avg)\n",
        "            else:\n",
        "                silhouette_scores.append(-1)\n",
        "        \n",
        "        if silhouette_scores:\n",
        "            optimal_idx = np.argmax(silhouette_scores)\n",
        "            optimal_n_clusters = cluster_range[optimal_idx]\n",
        "            return optimal_n_clusters\n",
        "        else:\n",
        "            return 2\n",
        "    \n",
        "    def get_cluster_labels(self, n_clusters=None):\n",
        "        \"\"\"ã‚¯ãƒ©ã‚¹ã‚¿ãƒ©ãƒ™ãƒ«ã®å–å¾—\"\"\"\n",
        "        if n_clusters is None:\n",
        "            n_clusters = self.optimal_clusters\n",
        "        \n",
        "        return fcluster(self.linkage_matrix, n_clusters, criterion='maxclust')\n",
        "    \n",
        "    def plot_dendrogram(self, figsize=(12, 8)):\n",
        "        \"\"\"ãƒ‡ãƒ³ãƒ‰ãƒ­ã‚°ãƒ©ãƒ å¯è¦–åŒ–\"\"\"\n",
        "        plt.figure(figsize=figsize)\n",
        "        dendrogram(self.linkage_matrix, truncate_mode='level', p=10)\n",
        "        plt.title('Hierarchical Clustering Dendrogram')\n",
        "        plt.xlabel('Sample Index')\n",
        "        plt.ylabel('Distance')\n",
        "        plt.show()\n",
        "\n",
        "print(\"âœ… éšå±¤çš„ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°åˆ†æã‚·ã‚¹ãƒ†ãƒ å®Ÿè£…å®Œäº†\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ================================\n",
        "# 3. åŒ…æ‹¬çš„è©•ä¾¡æŒ‡æ¨™ã‚·ã‚¹ãƒ†ãƒ \n",
        "# ================================\n",
        "\n",
        "class ComprehensiveEvaluationMetrics:\n",
        "    \"\"\"åŒ…æ‹¬çš„è©•ä¾¡æŒ‡æ¨™ã‚·ã‚¹ãƒ†ãƒ \"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.metrics = {}\n",
        "    \n",
        "    def calculate_all_metrics(self, features, labels, f_params=None, k_params=None):\n",
        "        \"\"\"å…¨ã¦ã®è©•ä¾¡æŒ‡æ¨™ã‚’è¨ˆç®—\"\"\"\n",
        "        \n",
        "        # åŸºæœ¬ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°æŒ‡æ¨™\n",
        "        self.metrics['silhouette_score'] = silhouette_score(features, labels)\n",
        "        self.metrics['calinski_harabasz_score'] = calinski_harabasz_score(features, labels)\n",
        "        self.metrics['davies_bouldin_score'] = davies_bouldin_score(features, labels)\n",
        "        \n",
        "        # è¿‘å‚ä¸€è‡´åº¦æŒ‡æ¨™\n",
        "        self.metrics['neighborhood_agreement'] = self._calculate_neighborhood_agreement(features, labels)\n",
        "        \n",
        "        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç©ºé–“åˆ†é›¢åº¦è©•ä¾¡\n",
        "        if f_params is not None and k_params is not None:\n",
        "            self.metrics['parameter_separation'] = self._calculate_parameter_separation(\n",
        "                features, labels, f_params, k_params\n",
        "            )\n",
        "        \n",
        "        # ã‚¯ãƒ©ã‚¹ã‚¿å†…åˆ†æ•£ãƒ»ã‚¯ãƒ©ã‚¹ã‚¿é–“åˆ†æ•£\n",
        "        self.metrics['within_cluster_variance'] = self._calculate_within_cluster_variance(features, labels)\n",
        "        self.metrics['between_cluster_variance'] = self._calculate_between_cluster_variance(features, labels)\n",
        "        \n",
        "        # å®‰å®šæ€§æŒ‡æ¨™\n",
        "        self.metrics['cluster_stability'] = self._calculate_cluster_stability(features, labels)\n",
        "        \n",
        "        return self.metrics\n",
        "    \n",
        "    def _calculate_neighborhood_agreement(self, features, labels, k=10):\n",
        "        \"\"\"è¿‘å‚ä¸€è‡´åº¦ã®è¨ˆç®—\"\"\"\n",
        "        from sklearn.neighbors import NearestNeighbors\n",
        "        \n",
        "        nbrs = NearestNeighbors(n_neighbors=k+1).fit(features)\n",
        "        distances, indices = nbrs.kneighbors(features)\n",
        "        \n",
        "        agreements = []\n",
        "        for i in range(len(features)):\n",
        "            neighbor_labels = labels[indices[i][1:]]  # è‡ªåˆ†ä»¥å¤–ã®è¿‘å‚\n",
        "            same_cluster = np.sum(neighbor_labels == labels[i])\n",
        "            agreement = same_cluster / k\n",
        "            agreements.append(agreement)\n",
        "        \n",
        "        return np.mean(agreements)\n",
        "    \n",
        "    def _calculate_parameter_separation(self, features, labels, f_params, k_params):\n",
        "        \"\"\"ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç©ºé–“åˆ†é›¢åº¦ã®è¨ˆç®—\"\"\"\n",
        "        unique_labels = np.unique(labels)\n",
        "        separations = []\n",
        "        \n",
        "        for label in unique_labels:\n",
        "            mask = labels == label\n",
        "            if np.sum(mask) > 1:\n",
        "                cluster_f = f_params[mask]\n",
        "                cluster_k = k_params[mask]\n",
        "                \n",
        "                # ã‚¯ãƒ©ã‚¹ã‚¿å†…ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åˆ†æ•£\n",
        "                f_var = np.var(cluster_f)\n",
        "                k_var = np.var(cluster_k)\n",
        "                cluster_variance = f_var + k_var\n",
        "                \n",
        "                separations.append(cluster_variance)\n",
        "        \n",
        "        return np.mean(separations) if separations else 0\n",
        "    \n",
        "    def _calculate_within_cluster_variance(self, features, labels):\n",
        "        \"\"\"ã‚¯ãƒ©ã‚¹ã‚¿å†…åˆ†æ•£ã®è¨ˆç®—\"\"\"\n",
        "        unique_labels = np.unique(labels)\n",
        "        within_variances = []\n",
        "        \n",
        "        for label in unique_labels:\n",
        "            mask = labels == label\n",
        "            if np.sum(mask) > 1:\n",
        "                cluster_features = features[mask]\n",
        "                centroid = np.mean(cluster_features, axis=0)\n",
        "                variance = np.mean(np.sum((cluster_features - centroid)**2, axis=1))\n",
        "                within_variances.append(variance)\n",
        "        \n",
        "        return np.mean(within_variances) if within_variances else 0\n",
        "    \n",
        "    def _calculate_between_cluster_variance(self, features, labels):\n",
        "        \"\"\"ã‚¯ãƒ©ã‚¹ã‚¿é–“åˆ†æ•£ã®è¨ˆç®—\"\"\"\n",
        "        unique_labels = np.unique(labels)\n",
        "        centroids = []\n",
        "        \n",
        "        for label in unique_labels:\n",
        "            mask = labels == label\n",
        "            centroid = np.mean(features[mask], axis=0)\n",
        "            centroids.append(centroid)\n",
        "        \n",
        "        centroids = np.array(centroids)\n",
        "        overall_centroid = np.mean(centroids, axis=0)\n",
        "        \n",
        "        between_variance = np.mean(np.sum((centroids - overall_centroid)**2, axis=1))\n",
        "        return between_variance\n",
        "    \n",
        "    def _calculate_cluster_stability(self, features, labels, n_bootstrap=5):\n",
        "        \"\"\"ã‚¯ãƒ©ã‚¹ã‚¿å®‰å®šæ€§ã®è¨ˆç®—ï¼ˆç°¡æ˜“ç‰ˆï¼‰\"\"\"\n",
        "        from sklearn.utils import resample\n",
        "        \n",
        "        original_labels = labels\n",
        "        stability_scores = []\n",
        "        \n",
        "        for _ in range(n_bootstrap):\n",
        "            # ãƒ–ãƒ¼ãƒˆã‚¹ãƒˆãƒ©ãƒƒãƒ—ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°\n",
        "            bootstrap_indices = resample(range(len(features)), n_samples=len(features))\n",
        "            bootstrap_features = features[bootstrap_indices]\n",
        "            bootstrap_labels = labels[bootstrap_indices]\n",
        "            \n",
        "            # ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°å®Ÿè¡Œ\n",
        "            kmeans = KMeans(n_clusters=len(np.unique(original_labels)), random_state=42)\n",
        "            new_labels = kmeans.fit_predict(bootstrap_features)\n",
        "            \n",
        "            # ç°¡æ˜“ä¸€è‡´åº¦è¨ˆç®—\n",
        "            agreement = np.mean(bootstrap_labels == new_labels)\n",
        "            stability_scores.append(agreement)\n",
        "        \n",
        "        return np.mean(stability_scores)\n",
        "    \n",
        "    def print_metrics(self):\n",
        "        \"\"\"è©•ä¾¡æŒ‡æ¨™ã®è¡¨ç¤º\"\"\"\n",
        "        print(\"\\nğŸ¯ Phase 4 åŒ…æ‹¬çš„è©•ä¾¡æŒ‡æ¨™\")\n",
        "        print(\"=\" * 50)\n",
        "        \n",
        "        # åŸºæœ¬æŒ‡æ¨™\n",
        "        print(f\"Silhouette Score: {self.metrics.get('silhouette_score', 0):.4f}\")\n",
        "        print(f\"Calinski-Harabasz: {self.metrics.get('calinski_harabasz_score', 0):.2f}\")\n",
        "        print(f\"Davies-Bouldin: {self.metrics.get('davies_bouldin_score', 0):.4f}\")\n",
        "        \n",
        "        # é«˜åº¦ãªæŒ‡æ¨™\n",
        "        print(f\"Neighborhood Agreement: {self.metrics.get('neighborhood_agreement', 0):.4f}\")\n",
        "        print(f\"Parameter Separation: {self.metrics.get('parameter_separation', 0):.4f}\")\n",
        "        print(f\"Within Cluster Variance: {self.metrics.get('within_cluster_variance', 0):.4f}\")\n",
        "        print(f\"Between Cluster Variance: {self.metrics.get('between_cluster_variance', 0):.4f}\")\n",
        "        print(f\"Cluster Stability: {self.metrics.get('cluster_stability', 0):.4f}\")\n",
        "\n",
        "print(\"âœ… åŒ…æ‹¬çš„è©•ä¾¡æŒ‡æ¨™ã‚·ã‚¹ãƒ†ãƒ å®Ÿè£…å®Œäº†\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ğŸ—ï¸ Step 3: Phase 3ãƒ™ãƒ¼ã‚¹ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ï¼ˆç¶™æ‰¿ãƒ»æ‹¡å¼µï¼‰\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ================================\n",
        "# 4. Phase 3ãƒ™ãƒ¼ã‚¹ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ï¼ˆç¶™æ‰¿ãƒ»æ‹¡å¼µï¼‰\n",
        "# ================================\n",
        "\n",
        "class GrayScottAugmentation:\n",
        "    \"\"\"Gray-Scottå°‚ç”¨ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã‚¯ãƒ©ã‚¹ï¼ˆPhase 3ã‹ã‚‰ç¶™æ‰¿ï¼‰\"\"\"\n",
        "    \n",
        "    def __init__(self, \n",
        "                 temporal_shift_prob=0.3,\n",
        "                 spatial_flip_prob=0.5,\n",
        "                 noise_prob=0.2,\n",
        "                 intensity_prob=0.3,\n",
        "                 temporal_crop_prob=0.2):\n",
        "        self.temporal_shift_prob = temporal_shift_prob\n",
        "        self.spatial_flip_prob = spatial_flip_prob\n",
        "        self.noise_prob = noise_prob\n",
        "        self.intensity_prob = intensity_prob\n",
        "        self.temporal_crop_prob = temporal_crop_prob\n",
        "    \n",
        "    def temporal_shift(self, tensor, max_shift=3):\n",
        "        \"\"\"æ™‚é–“è»¸ã‚·ãƒ•ãƒˆ\"\"\"\n",
        "        if np.random.random() < self.temporal_shift_prob:\n",
        "            shift = np.random.randint(-max_shift, max_shift + 1)\n",
        "            if shift != 0:\n",
        "                tensor = torch.roll(tensor, shift, dims=1)\n",
        "        return tensor\n",
        "    \n",
        "    def spatial_flip(self, tensor):\n",
        "        \"\"\"ç©ºé–“è»¸åè»¢\"\"\"\n",
        "        if np.random.random() < self.spatial_flip_prob:\n",
        "            if np.random.random() < 0.5:\n",
        "                tensor = torch.flip(tensor, dims=[3])\n",
        "            if np.random.random() < 0.5:\n",
        "                tensor = torch.flip(tensor, dims=[2])\n",
        "        return tensor\n",
        "    \n",
        "    def add_noise(self, tensor, noise_std=0.02):\n",
        "        \"\"\"ã‚¬ã‚¦ã‚·ã‚¢ãƒ³ãƒã‚¤ã‚ºè¿½åŠ \"\"\"\n",
        "        if np.random.random() < self.noise_prob:\n",
        "            noise = torch.randn_like(tensor) * noise_std\n",
        "            tensor = torch.clamp(tensor + noise, 0, 1)\n",
        "        return tensor\n",
        "    \n",
        "    def intensity_transform(self, tensor, gamma_range=(0.8, 1.2)):\n",
        "        \"\"\"å¼·åº¦å¤‰æ›\"\"\"\n",
        "        if np.random.random() < self.intensity_prob:\n",
        "            gamma = np.random.uniform(*gamma_range)\n",
        "            tensor = torch.pow(tensor, gamma)\n",
        "        return tensor\n",
        "    \n",
        "    def temporal_crop(self, tensor, crop_ratio=0.1):\n",
        "        \"\"\"æ™‚é–“è»¸ã‚¯ãƒ­ãƒƒãƒ—\"\"\"\n",
        "        if np.random.random() < self.temporal_crop_prob:\n",
        "            T = tensor.shape[1]\n",
        "            crop_size = int(T * crop_ratio)\n",
        "            start_idx = np.random.randint(0, crop_size + 1)\n",
        "            end_idx = T - np.random.randint(0, crop_size + 1)\n",
        "            \n",
        "            cropped = tensor[:, start_idx:end_idx]\n",
        "            tensor = F.interpolate(cropped.unsqueeze(0), size=(T, tensor.shape[2], tensor.shape[3]), \n",
        "                                 mode='trilinear', align_corners=False).squeeze(0)\n",
        "        return tensor\n",
        "    \n",
        "    def __call__(self, tensor):\n",
        "        \"\"\"å…¨ã¦ã®æ‹¡å¼µã‚’é©ç”¨\"\"\"\n",
        "        tensor = self.temporal_shift(tensor)\n",
        "        tensor = self.spatial_flip(tensor)\n",
        "        tensor = self.add_noise(tensor)\n",
        "        tensor = self.intensity_transform(tensor)\n",
        "        tensor = self.temporal_crop(tensor)\n",
        "        return tensor\n",
        "\n",
        "class MultiScaleFeatureFusion(nn.Module):\n",
        "    \"\"\"ãƒãƒ«ãƒã‚¹ã‚±ãƒ¼ãƒ«ç‰¹å¾´èåˆï¼ˆPhase 3ã‹ã‚‰ç¶™æ‰¿ï¼‰\"\"\"\n",
        "    \n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        \n",
        "        # 4ã¤ã®ç•°ãªã‚‹ã‚¹ã‚±ãƒ¼ãƒ«ã§ã®ç‰¹å¾´æŠ½å‡º\n",
        "        self.scale1 = nn.Conv3d(in_channels, out_channels // 4, kernel_size=1, padding=0)  # Point-wise\n",
        "        self.scale2 = nn.Conv3d(in_channels, out_channels // 4, kernel_size=3, padding=1)  # Local\n",
        "        self.scale3 = nn.Conv3d(in_channels, out_channels // 4, kernel_size=5, padding=2)  # Global\n",
        "        \n",
        "        # ãƒ—ãƒ¼ãƒªãƒ³ã‚°ãƒ™ãƒ¼ã‚¹ã®ç‰¹å¾´\n",
        "        self.pool = nn.AdaptiveAvgPool3d(1)\n",
        "        self.scale4 = nn.Conv3d(in_channels, out_channels // 4, kernel_size=1)\n",
        "        \n",
        "        self.bn = nn.BatchNorm3d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # å„ã‚¹ã‚±ãƒ¼ãƒ«ã§ç‰¹å¾´æŠ½å‡º\n",
        "        feat1 = self.scale1(x)\n",
        "        feat2 = self.scale2(x)\n",
        "        feat3 = self.scale3(x)\n",
        "        \n",
        "        # ãƒ—ãƒ¼ãƒªãƒ³ã‚°ç‰¹å¾´\n",
        "        pooled = self.pool(x)\n",
        "        feat4 = self.scale4(pooled)\n",
        "        feat4 = feat4.expand_as(feat1)\n",
        "        \n",
        "        # ç‰¹å¾´èåˆ\n",
        "        fused = torch.cat([feat1, feat2, feat3, feat4], dim=1)\n",
        "        fused = self.bn(fused)\n",
        "        fused = self.relu(fused)\n",
        "        \n",
        "        return fused\n",
        "\n",
        "class EnhancedSpatioTemporalAttention(nn.Module):\n",
        "    \"\"\"æ”¹è‰¯æ™‚ç©ºé–“æ³¨æ„æ©Ÿæ§‹ï¼ˆPhase 3ã‹ã‚‰ç¶™æ‰¿ï¼‰\"\"\"\n",
        "    \n",
        "    def __init__(self, in_channels, reduction=16):\n",
        "        super().__init__()\n",
        "        \n",
        "        # æ™‚é–“æ³¨æ„\n",
        "        self.temporal_attention = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool3d((None, 1, 1)),\n",
        "            nn.Conv3d(in_channels, in_channels // reduction, kernel_size=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv3d(in_channels // reduction, in_channels, kernel_size=1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        \n",
        "        # ç©ºé–“æ³¨æ„\n",
        "        self.spatial_attention = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool3d((1, None, None)),\n",
        "            nn.Conv3d(in_channels, in_channels // reduction, kernel_size=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv3d(in_channels // reduction, in_channels, kernel_size=1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        \n",
        "        # ãƒãƒ£ãƒãƒ«æ³¨æ„\n",
        "        self.channel_attention = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool3d(1),\n",
        "            nn.Conv3d(in_channels, in_channels // reduction, kernel_size=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv3d(in_channels // reduction, in_channels, kernel_size=1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # å„æ³¨æ„æ©Ÿæ§‹ã‚’é©ç”¨\n",
        "        temp_att = self.temporal_attention(x)\n",
        "        spat_att = self.spatial_attention(x)\n",
        "        chan_att = self.channel_attention(x)\n",
        "        \n",
        "        # æ³¨æ„é‡ã¿ã‚’é©ç”¨\n",
        "        x = x * temp_att * spat_att * chan_att\n",
        "        \n",
        "        return x\n",
        "\n",
        "class ResidualMultiScaleBlock3D(nn.Module):\n",
        "    \"\"\"æ®‹å·®ãƒãƒ«ãƒã‚¹ã‚±ãƒ¼ãƒ«ãƒ–ãƒ­ãƒƒã‚¯ï¼ˆPhase 3ã‹ã‚‰ç¶™æ‰¿ï¼‰\"\"\"\n",
        "    \n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.multi_scale = MultiScaleFeatureFusion(in_channels, out_channels)\n",
        "        self.attention = EnhancedSpatioTemporalAttention(out_channels)\n",
        "        \n",
        "        # æ®‹å·®æ¥ç¶šç”¨\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv3d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm3d(out_channels)\n",
        "            )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        residual = self.shortcut(x)\n",
        "        \n",
        "        out = self.multi_scale(x)\n",
        "        out = self.attention(out)\n",
        "        \n",
        "        out += residual\n",
        "        return out\n",
        "\n",
        "print(\"âœ… Phase 3ãƒ™ãƒ¼ã‚¹ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£å®Ÿè£…å®Œäº†\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ================================\n",
        "# 5.5. ä¿®æ­£ç‰ˆPhase 4ãƒ¡ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«ï¼ˆãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼ä¿®æ­£ï¼‰\n",
        "# ================================\n",
        "\n",
        "class Conv3DAutoencoderPhase4(nn.Module):\n",
        "    \"\"\"Phase 4: å¯¾æ¯”å­¦ç¿’çµ±åˆã‚ªãƒ¼ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ï¼ˆä¿®æ­£ç‰ˆï¼‰\"\"\"\n",
        "    \n",
        "    def __init__(self, latent_dim=512, input_shape=(20, 64, 64)):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.latent_dim = latent_dim\n",
        "        self.input_shape = input_shape\n",
        "        \n",
        "        # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼\n",
        "        self.encoder = nn.Sequential(\n",
        "            # å…¥åŠ›: (1, 20, 64, 64)\n",
        "            ResidualMultiScaleBlock3D(1, 32),\n",
        "            nn.MaxPool3d(2),  # (32, 10, 32, 32)\n",
        "            \n",
        "            ResidualMultiScaleBlock3D(32, 64),\n",
        "            nn.MaxPool3d(2),  # (64, 5, 16, 16)\n",
        "            \n",
        "            ResidualMultiScaleBlock3D(64, 128),\n",
        "            nn.MaxPool3d(2),  # (128, 2, 8, 8)\n",
        "            \n",
        "            ResidualMultiScaleBlock3D(128, 256),\n",
        "            nn.AdaptiveAvgPool3d(1),  # (256, 1, 1, 1)\n",
        "        )\n",
        "        \n",
        "        # æ½œåœ¨ç©ºé–“\n",
        "        self.fc_encoder = nn.Sequential(\n",
        "            nn.Linear(256, latent_dim),\n",
        "            nn.BatchNorm1d(latent_dim),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.3)\n",
        "        )\n",
        "        \n",
        "        # å¯¾æ¯”å­¦ç¿’ç”¨å°„å½±ãƒ˜ãƒƒãƒ‰\n",
        "        self.projection_head = ProjectionHead(latent_dim, 256, 128)\n",
        "        \n",
        "        # ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼\n",
        "        self.fc_decoder = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.3)\n",
        "        )\n",
        "        \n",
        "        # ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼ã‚’å€‹åˆ¥ã®ãƒ¬ã‚¤ãƒ¤ãƒ¼ã¨ã—ã¦å®šç¾©ï¼ˆã‚µã‚¤ã‚ºèª¿æ•´ä»˜ãï¼‰\n",
        "        self.decoder_conv1 = nn.ConvTranspose3d(256, 128, kernel_size=(3, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1))\n",
        "        self.decoder_bn1 = nn.BatchNorm3d(128)\n",
        "        \n",
        "        self.decoder_conv2 = nn.ConvTranspose3d(128, 64, kernel_size=(3, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1))\n",
        "        self.decoder_bn2 = nn.BatchNorm3d(64)\n",
        "        \n",
        "        self.decoder_conv3 = nn.ConvTranspose3d(64, 32, kernel_size=(3, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1))\n",
        "        self.decoder_bn3 = nn.BatchNorm3d(32)\n",
        "        \n",
        "        self.decoder_conv4 = nn.ConvTranspose3d(32, 1, kernel_size=(3, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1))\n",
        "        \n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "    \n",
        "    def encode(self, x):\n",
        "        \"\"\"ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰\"\"\"\n",
        "        x = self.encoder(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        latent = self.fc_encoder(x)\n",
        "        return latent\n",
        "    \n",
        "    def decode(self, latent):\n",
        "        \"\"\"ãƒ‡ã‚³ãƒ¼ãƒ‰ï¼ˆã‚µã‚¤ã‚ºèª¿æ•´ä»˜ãï¼‰\"\"\"\n",
        "        x = self.fc_decoder(latent)\n",
        "        x = x.view(x.size(0), 256, 1, 1, 1)\n",
        "        \n",
        "        # æ®µéšçš„ã«ãƒ‡ã‚³ãƒ¼ãƒ‰ï¼ˆå„ã‚¹ãƒ†ãƒƒãƒ—ã§ã‚µã‚¤ã‚ºã‚’èª¿æ•´ï¼‰\n",
        "        # (256, 1, 1, 1) -> (128, 2, 8, 8)\n",
        "        x = self.decoder_conv1(x)\n",
        "        x = self.decoder_bn1(x)\n",
        "        x = self.relu(x)\n",
        "        # ã‚µã‚¤ã‚ºèª¿æ•´\n",
        "        x = F.interpolate(x, size=(2, 8, 8), mode='trilinear', align_corners=False)\n",
        "        \n",
        "        # (128, 2, 8, 8) -> (64, 5, 16, 16)\n",
        "        x = self.decoder_conv2(x)\n",
        "        x = self.decoder_bn2(x)\n",
        "        x = self.relu(x)\n",
        "        # ã‚µã‚¤ã‚ºèª¿æ•´\n",
        "        x = F.interpolate(x, size=(5, 16, 16), mode='trilinear', align_corners=False)\n",
        "        \n",
        "        # (64, 5, 16, 16) -> (32, 10, 32, 32)\n",
        "        x = self.decoder_conv3(x)\n",
        "        x = self.decoder_bn3(x)\n",
        "        x = self.relu(x)\n",
        "        # ã‚µã‚¤ã‚ºèª¿æ•´\n",
        "        x = F.interpolate(x, size=(10, 32, 32), mode='trilinear', align_corners=False)\n",
        "        \n",
        "        # (32, 10, 32, 32) -> (1, 20, 64, 64)\n",
        "        x = self.decoder_conv4(x)\n",
        "        # æœ€çµ‚ã‚µã‚¤ã‚ºèª¿æ•´\n",
        "        x = F.interpolate(x, size=(20, 64, 64), mode='trilinear', align_corners=False)\n",
        "        x = self.sigmoid(x)\n",
        "        \n",
        "        return x\n",
        "    \n",
        "    def forward(self, x):\n",
        "        \"\"\"ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒ‘ã‚¹\"\"\"\n",
        "        latent = self.encode(x)\n",
        "        reconstructed = self.decode(latent)\n",
        "        projection = self.projection_head(latent)\n",
        "        \n",
        "        return reconstructed, latent, projection\n",
        "\n",
        "print(\"âœ… ä¿®æ­£ç‰ˆPhase 4ãƒ¡ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«å®Ÿè£…å®Œäº†\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ================================\n",
        "# 5. Phase 4ãƒ¡ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«ï¼ˆå¯¾æ¯”å­¦ç¿’çµ±åˆï¼‰\n",
        "# ================================\n",
        "\n",
        "class Conv3DAutoencoderPhase4(nn.Module):\n",
        "    \"\"\"Phase 4: å¯¾æ¯”å­¦ç¿’çµ±åˆã‚ªãƒ¼ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼\"\"\"\n",
        "    \n",
        "    def __init__(self, latent_dim=512, input_shape=(20, 64, 64)):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.latent_dim = latent_dim\n",
        "        self.input_shape = input_shape\n",
        "        \n",
        "        # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼\n",
        "        self.encoder = nn.Sequential(\n",
        "            # å…¥åŠ›: (1, 20, 64, 64)\n",
        "            ResidualMultiScaleBlock3D(1, 32),\n",
        "            nn.MaxPool3d(2),  # (32, 10, 32, 32)\n",
        "            \n",
        "            ResidualMultiScaleBlock3D(32, 64),\n",
        "            nn.MaxPool3d(2),  # (64, 5, 16, 16)\n",
        "            \n",
        "            ResidualMultiScaleBlock3D(64, 128),\n",
        "            nn.MaxPool3d(2),  # (128, 2, 8, 8)\n",
        "            \n",
        "            ResidualMultiScaleBlock3D(128, 256),\n",
        "            nn.AdaptiveAvgPool3d(1),  # (256, 1, 1, 1)\n",
        "        )\n",
        "        \n",
        "        # æ½œåœ¨ç©ºé–“\n",
        "        self.fc_encoder = nn.Sequential(\n",
        "            nn.Linear(256, latent_dim),\n",
        "            nn.BatchNorm1d(latent_dim),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.3)\n",
        "        )\n",
        "        \n",
        "        # å¯¾æ¯”å­¦ç¿’ç”¨å°„å½±ãƒ˜ãƒƒãƒ‰\n",
        "        self.projection_head = ProjectionHead(latent_dim, 256, 128)\n",
        "        \n",
        "        # ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼\n",
        "        self.fc_decoder = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.3)\n",
        "        )\n",
        "        \n",
        "        self.decoder = nn.Sequential(\n",
        "            # (256, 1, 1, 1) -> (128, 2, 8, 8)\n",
        "            nn.ConvTranspose3d(256, 128, kernel_size=(3, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1)),\n",
        "            nn.BatchNorm3d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            \n",
        "            # (128, 2, 8, 8) -> (64, 5, 16, 16)\n",
        "            nn.ConvTranspose3d(128, 64, kernel_size=(3, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1)),\n",
        "            nn.BatchNorm3d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            \n",
        "            # (64, 5, 16, 16) -> (32, 10, 32, 32)\n",
        "            nn.ConvTranspose3d(64, 32, kernel_size=(3, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1)),\n",
        "            nn.BatchNorm3d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            \n",
        "            # (32, 10, 32, 32) -> (1, 20, 64, 64)\n",
        "            nn.ConvTranspose3d(32, 1, kernel_size=(3, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1)),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "    \n",
        "    def encode(self, x):\n",
        "        \"\"\"ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰\"\"\"\n",
        "        x = self.encoder(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        latent = self.fc_encoder(x)\n",
        "        return latent\n",
        "    \n",
        "    def decode(self, latent):\n",
        "        \"\"\"ãƒ‡ã‚³ãƒ¼ãƒ‰\"\"\"\n",
        "        x = self.fc_decoder(latent)\n",
        "        x = x.view(x.size(0), 256, 1, 1, 1)\n",
        "        x = self.decoder(x)\n",
        "        \n",
        "        # æœ€çµ‚çš„ã«ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚µã‚¤ã‚ºã«èª¿æ•´\n",
        "        target_t, target_h, target_w = self.input_shape\n",
        "        x = F.interpolate(x, size=(target_t, target_h, target_w), \n",
        "                         mode='trilinear', align_corners=False)\n",
        "        return x\n",
        "    \n",
        "    def forward(self, x):\n",
        "        \"\"\"ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒ‘ã‚¹\"\"\"\n",
        "        latent = self.encode(x)\n",
        "        reconstructed = self.decode(latent)\n",
        "        projection = self.projection_head(latent)\n",
        "        \n",
        "        return reconstructed, latent, projection\n",
        "\n",
        "# ================================\n",
        "# 6. ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚¯ãƒ©ã‚¹\n",
        "# ================================\n",
        "\n",
        "class GrayScottDataset(Dataset):\n",
        "    \"\"\"Gray-Scott ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆPhase 3ã‹ã‚‰ç¶™æ‰¿ãƒ»æ‹¡å¼µï¼‰\"\"\"\n",
        "    \n",
        "    def __init__(self, gif_folder, augmentation=None, max_samples=None):\n",
        "        self.gif_folder = gif_folder\n",
        "        self.augmentation = augmentation\n",
        "        \n",
        "        # GIFãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆå–å¾—\n",
        "        self.gif_files = [f for f in os.listdir(gif_folder) if f.endswith('.gif')]\n",
        "        \n",
        "        if max_samples:\n",
        "            self.gif_files = self.gif_files[:max_samples]\n",
        "        \n",
        "        # f-kãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æŠ½å‡º\n",
        "        self.f_params = []\n",
        "        self.k_params = []\n",
        "        \n",
        "        for gif_file in self.gif_files:\n",
        "            f_val, k_val = self.extract_parameters(gif_file)\n",
        "            self.f_params.append(f_val)\n",
        "            self.k_params.append(k_val)\n",
        "        \n",
        "        self.f_params = np.array(self.f_params)\n",
        "        self.k_params = np.array(self.k_params)\n",
        "        \n",
        "        print(f\"ğŸ“Š Dataset loaded: {len(self.gif_files)} samples\")\n",
        "        print(f\"f range: {self.f_params.min():.4f} - {self.f_params.max():.4f}\")\n",
        "        print(f\"k range: {self.k_params.min():.4f} - {self.k_params.max():.4f}\")\n",
        "    \n",
        "    def extract_parameters(self, filename):\n",
        "        \"\"\"ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰f-kãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æŠ½å‡º\"\"\"\n",
        "        pattern = r'f([\\d.]+)-k([\\d.]+)'\n",
        "        match = re.search(pattern, filename)\n",
        "        \n",
        "        if match:\n",
        "            f_val = float(match.group(1))\n",
        "            k_val = float(match.group(2))\n",
        "            return f_val, k_val\n",
        "        else:\n",
        "            return 0.0, 0.0\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.gif_files)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        gif_path = os.path.join(self.gif_folder, self.gif_files[idx])\n",
        "        \n",
        "        # GIFèª­ã¿è¾¼ã¿\n",
        "        gif = imageio.mimread(gif_path)\n",
        "        \n",
        "        # æœ€åˆã®20ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å–å¾—\n",
        "        frames = gif[:20] if len(gif) >= 20 else gif\n",
        "        \n",
        "        # ãƒ†ãƒ³ã‚½ãƒ«ã«å¤‰æ›\n",
        "        tensor = torch.FloatTensor(frames).unsqueeze(0)  # (1, T, H, W)\n",
        "        tensor = tensor / 255.0  # æ­£è¦åŒ–\n",
        "        \n",
        "        # ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µ\n",
        "        if self.augmentation:\n",
        "            tensor = self.augmentation(tensor)\n",
        "        \n",
        "        return tensor, self.f_params[idx], self.k_params[idx], idx\n",
        "\n",
        "print(\"âœ… Phase 4ãƒ¡ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«ãƒ»ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå®Ÿè£…å®Œäº†\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ğŸš€ Step 4: Phase 4 è¨“ç·´ãƒ»è©•ä¾¡å®Ÿè¡Œ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ================================\n",
        "# 7. Phase 4 è¨“ç·´ãƒ»è©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ \n",
        "# ================================\n",
        "\n",
        "def train_phase4_model(model, dataloader, num_epochs=25, learning_rate=1e-4):\n",
        "    \"\"\"Phase 4ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´\"\"\"\n",
        "    \n",
        "    # æœ€é©åŒ–å™¨\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
        "    \n",
        "    # æå¤±é–¢æ•°\n",
        "    reconstruction_loss = nn.MSELoss()\n",
        "    contrastive_loss = ContrastiveLoss(temperature=0.5)\n",
        "    \n",
        "    # è¨“ç·´ãƒ«ãƒ¼ãƒ—\n",
        "    model.train()\n",
        "    train_losses = []\n",
        "    \n",
        "    print(\"ğŸš€ Phase 4 Training Started\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        epoch_loss = 0.0\n",
        "        epoch_recon_loss = 0.0\n",
        "        epoch_contrastive_loss = 0.0\n",
        "        \n",
        "        for batch_idx, (data, f_params, k_params, _) in enumerate(dataloader):\n",
        "            data = data.to(device)\n",
        "            f_params = f_params.to(device)\n",
        "            k_params = k_params.to(device)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            # ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒ‘ã‚¹\n",
        "            reconstructed, latent, projection = model(data)\n",
        "            \n",
        "            # æå¤±è¨ˆç®—\n",
        "            recon_loss = reconstruction_loss(reconstructed, data)\n",
        "            \n",
        "            # å¯¾æ¯”å­¦ç¿’æå¤±ï¼ˆã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ä»˜ãï¼‰\n",
        "            try:\n",
        "                contrast_loss = contrastive_loss(projection, f_params, k_params)\n",
        "                if torch.isnan(contrast_loss) or torch.isinf(contrast_loss):\n",
        "                    contrast_loss = torch.tensor(0.0, device=device)\n",
        "            except:\n",
        "                contrast_loss = torch.tensor(0.0, device=device)\n",
        "            \n",
        "            # ç·æå¤±ï¼ˆé‡ã¿ä»˜ãï¼‰\n",
        "            total_loss = recon_loss + 0.1 * contrast_loss\n",
        "            \n",
        "            # ãƒãƒƒã‚¯ãƒ—ãƒ­ãƒ‘ã‚²ãƒ¼ã‚·ãƒ§ãƒ³\n",
        "            total_loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            optimizer.step()\n",
        "            \n",
        "            epoch_loss += total_loss.item()\n",
        "            epoch_recon_loss += recon_loss.item()\n",
        "            epoch_contrastive_loss += contrast_loss.item()\n",
        "        \n",
        "        scheduler.step()\n",
        "        \n",
        "        avg_loss = epoch_loss / len(dataloader)\n",
        "        avg_recon_loss = epoch_recon_loss / len(dataloader)\n",
        "        avg_contrast_loss = epoch_contrastive_loss / len(dataloader)\n",
        "        \n",
        "        train_losses.append(avg_loss)\n",
        "        \n",
        "        if (epoch + 1) % 5 == 0:\n",
        "            print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
        "            print(f\"  Total Loss: {avg_loss:.6f}\")\n",
        "            print(f\"  Reconstruction: {avg_recon_loss:.6f}\")\n",
        "            print(f\"  Contrastive: {avg_contrast_loss:.6f}\")\n",
        "            print(f\"  LR: {scheduler.get_last_lr()[0]:.6f}\")\n",
        "    \n",
        "    print(\"âœ… Phase 4 Training Completed!\")\n",
        "    return train_losses\n",
        "\n",
        "def evaluate_phase4_model(model, dataloader):\n",
        "    \"\"\"Phase 4ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡\"\"\"\n",
        "    \n",
        "    model.eval()\n",
        "    all_latents = []\n",
        "    all_f_params = []\n",
        "    all_k_params = []\n",
        "    \n",
        "    print(\"ğŸ” Phase 4 Evaluation Started\")\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for data, f_params, k_params, _ in dataloader:\n",
        "            data = data.to(device)\n",
        "            _, latent, _ = model(data)\n",
        "            \n",
        "            all_latents.append(latent.cpu().numpy())\n",
        "            all_f_params.append(f_params.numpy())\n",
        "            all_k_params.append(k_params.numpy())\n",
        "    \n",
        "    # ãƒ‡ãƒ¼ã‚¿çµ±åˆ\n",
        "    all_latents = np.vstack(all_latents)\n",
        "    all_f_params = np.concatenate(all_f_params)\n",
        "    all_k_params = np.concatenate(all_k_params)\n",
        "    \n",
        "    # éšå±¤çš„ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°\n",
        "    print(\"ğŸ”„ Hierarchical Clustering Analysis...\")\n",
        "    hierarchical_clustering = HierarchicalClusteringAnalysis()\n",
        "    hierarchical_clustering.fit(all_latents)\n",
        "    \n",
        "    # ã‚¯ãƒ©ã‚¹ã‚¿ãƒ©ãƒ™ãƒ«å–å¾—\n",
        "    cluster_labels = hierarchical_clustering.get_cluster_labels()\n",
        "    \n",
        "    # åŒ…æ‹¬çš„è©•ä¾¡\n",
        "    print(\"ğŸ“Š Comprehensive Evaluation...\")\n",
        "    evaluator = ComprehensiveEvaluationMetrics()\n",
        "    metrics = evaluator.calculate_all_metrics(\n",
        "        all_latents, cluster_labels, all_f_params, all_k_params\n",
        "    )\n",
        "    \n",
        "    # çµæœè¡¨ç¤º\n",
        "    evaluator.print_metrics()\n",
        "    \n",
        "    # å¯è¦–åŒ–\n",
        "    visualize_phase4_results(all_latents, cluster_labels, all_f_params, all_k_params)\n",
        "    \n",
        "    return metrics, all_latents, cluster_labels, all_f_params, all_k_params\n",
        "\n",
        "def visualize_phase4_results(latents, labels, f_params, k_params):\n",
        "    \"\"\"Phase 4çµæœã®å¯è¦–åŒ–\"\"\"\n",
        "    \n",
        "    # PCA\n",
        "    pca = PCA(n_components=2)\n",
        "    latents_pca = pca.fit_transform(latents)\n",
        "    \n",
        "    # t-SNEï¼ˆé©å¿œçš„perplexityï¼‰\n",
        "    n_samples = len(latents)\n",
        "    perplexity = min(30, max(5, n_samples // 4))\n",
        "    \n",
        "    try:\n",
        "        tsne = TSNE(n_components=2, random_state=42, perplexity=perplexity)\n",
        "        latents_tsne = tsne.fit_transform(latents)\n",
        "    except:\n",
        "        print(\"âš ï¸ t-SNE failed, using PCA instead\")\n",
        "        latents_tsne = latents_pca\n",
        "    \n",
        "    # å¯è¦–åŒ–\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "    \n",
        "    # PCAå¯è¦–åŒ–\n",
        "    scatter = axes[0, 0].scatter(latents_pca[:, 0], latents_pca[:, 1], c=labels, cmap='tab10', s=30)\n",
        "    axes[0, 0].set_title('PCA Visualization')\n",
        "    axes[0, 0].set_xlabel('PC1')\n",
        "    axes[0, 0].set_ylabel('PC2')\n",
        "    plt.colorbar(scatter, ax=axes[0, 0])\n",
        "    \n",
        "    # t-SNEå¯è¦–åŒ–\n",
        "    scatter = axes[0, 1].scatter(latents_tsne[:, 0], latents_tsne[:, 1], c=labels, cmap='tab10', s=30)\n",
        "    axes[0, 1].set_title('t-SNE Visualization')\n",
        "    axes[0, 1].set_xlabel('t-SNE 1')\n",
        "    axes[0, 1].set_ylabel('t-SNE 2')\n",
        "    plt.colorbar(scatter, ax=axes[0, 1])\n",
        "    \n",
        "    # f-kç©ºé–“å¯è¦–åŒ–\n",
        "    scatter = axes[1, 0].scatter(f_params, k_params, c=labels, cmap='tab10', s=30)\n",
        "    axes[1, 0].set_title('f-k Parameter Space')\n",
        "    axes[1, 0].set_xlabel('f parameter')\n",
        "    axes[1, 0].set_ylabel('k parameter')\n",
        "    plt.colorbar(scatter, ax=axes[1, 0])\n",
        "    \n",
        "    # ã‚¯ãƒ©ã‚¹ã‚¿åˆ†å¸ƒ\n",
        "    unique_labels, counts = np.unique(labels, return_counts=True)\n",
        "    axes[1, 1].bar(unique_labels, counts)\n",
        "    axes[1, 1].set_title('Cluster Distribution')\n",
        "    axes[1, 1].set_xlabel('Cluster')\n",
        "    axes[1, 1].set_ylabel('Count')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "print(\"âœ… Phase 4 è¨“ç·´ãƒ»è©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ å®Ÿè£…å®Œäº†\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ================================\n",
        "# 9. Phase 4 å®Ÿéš›ã®å®Ÿè¡Œ\n",
        "# ================================\n",
        "\n",
        "# ä¿®æ­£ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã§å®Ÿè¡Œ\n",
        "print(\"ğŸš€ Phase 4 Final Execution\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µè¨­å®š\n",
        "augmentation = GrayScottAugmentation()\n",
        "\n",
        "# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆï¼ˆå°ã•ãªãƒãƒƒãƒã‚µã‚¤ã‚ºã§é–‹å§‹ï¼‰\n",
        "dataset = GrayScottDataset(GIF_FOLDER_PATH, augmentation=augmentation)\n",
        "dataloader = DataLoader(dataset, batch_size=8, shuffle=True, num_workers=2)\n",
        "\n",
        "# ãƒ¢ãƒ‡ãƒ«ä½œæˆ\n",
        "model = Conv3DAutoencoderPhase4(latent_dim=512).to(device)\n",
        "\n",
        "# ãƒ¢ãƒ‡ãƒ«æƒ…å ±è¡¨ç¤º\n",
        "print(f\"ğŸ“Š Model Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "\n",
        "# è¨“ç·´å®Ÿè¡Œï¼ˆçŸ­ã„ã‚¨ãƒãƒƒã‚¯æ•°ã§ãƒ†ã‚¹ãƒˆï¼‰\n",
        "print(\"\\nğŸ¯ Starting Phase 4 Training...\")\n",
        "train_losses = train_phase4_model(model, dataloader, num_epochs=20, learning_rate=1e-4)\n",
        "\n",
        "# è©•ä¾¡å®Ÿè¡Œ\n",
        "print(\"\\nğŸ“Š Starting Phase 4 Evaluation...\")\n",
        "metrics, latents, labels, f_params, k_params = evaluate_phase4_model(model, dataloader)\n",
        "\n",
        "# çµæœè¡¨ç¤º\n",
        "print(\"\\nğŸ‰ Phase 4 Results Summary:\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Silhouette Score: {metrics.get('silhouette_score', 'N/A'):.4f}\")\n",
        "print(f\"Calinski-Harabasz Score: {metrics.get('calinski_harabasz_score', 'N/A'):.4f}\")\n",
        "print(f\"Davies-Bouldin Score: {metrics.get('davies_bouldin_score', 'N/A'):.4f}\")\n",
        "\n",
        "# ãƒ¢ãƒ‡ãƒ«ä¿å­˜\n",
        "torch.save(model.state_dict(), '/content/drive/MyDrive/phase4_model.pth')\n",
        "print(\"ğŸ’¾ Model saved to Google Drive\")\n",
        "\n",
        "print(\"âœ… Phase 4 å®Œäº†ï¼\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ================================\n",
        "# 8. Phase 4 å®Ÿè¡Œ\n",
        "# ================================\n",
        "\n",
        "# ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µè¨­å®š\n",
        "augmentation = GrayScottAugmentation()\n",
        "\n",
        "# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ\n",
        "dataset = GrayScottDataset(GIF_FOLDER_PATH, augmentation=augmentation)\n",
        "dataloader = DataLoader(dataset, batch_size=16, shuffle=True, num_workers=2)\n",
        "\n",
        "# ãƒ¢ãƒ‡ãƒ«ä½œæˆ\n",
        "model = Conv3DAutoencoderPhase4(latent_dim=512).to(device)\n",
        "\n",
        "# ãƒ¢ãƒ‡ãƒ«æƒ…å ±è¡¨ç¤º\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"ğŸ“Š Phase 4 Model Information\")\n",
        "print(f\"Total Parameters: {total_params:,}\")\n",
        "print(f\"Trainable Parameters: {trainable_params:,}\")\n",
        "print(f\"Model Size: ~{total_params * 4 / 1024 / 1024:.1f} MB\")\n",
        "\n",
        "# è¨“ç·´å®Ÿè¡Œ\n",
        "print(\"\\nğŸš€ Starting Phase 4 Training...\")\n",
        "train_losses = train_phase4_model(model, dataloader, num_epochs=25)\n",
        "\n",
        "# è©•ä¾¡å®Ÿè¡Œ\n",
        "print(\"\\nğŸ” Starting Phase 4 Evaluation...\")\n",
        "metrics, latents, labels, f_params, k_params = evaluate_phase4_model(model, dataloader)\n",
        "\n",
        "# Phaseæ¯”è¼ƒ\n",
        "print(\"\\nğŸ“ˆ Phase Performance Comparison\")\n",
        "print(\"=\" * 50)\n",
        "print(\"Phase 1 (Baseline 3D CNN): 0.565\")\n",
        "print(\"Phase 2 (ResNet + Attention): 0.467\")\n",
        "print(\"Phase 3 (Multi-Scale Fusion): 0.5144\")\n",
        "print(f\"Phase 4 (Contrastive Learning): {metrics['silhouette_score']:.4f}\")\n",
        "\n",
        "improvement_from_phase3 = ((metrics['silhouette_score'] - 0.5144) / 0.5144) * 100\n",
        "print(f\"\\nPhase 4 vs Phase 3 Improvement: {improvement_from_phase3:+.1f}%\")\n",
        "\n",
        "if metrics['silhouette_score'] > 0.5144:\n",
        "    print(\"ğŸ‰ Phase 4 Success! New best performance achieved!\")\n",
        "else:\n",
        "    print(\"ğŸ“Š Phase 4 results recorded. Consider further optimization.\")\n",
        "\n",
        "print(\"\\nâœ… Phase 4 Implementation Complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ================================\n",
        "# ãƒ‡ãƒãƒƒã‚°: ãƒ¢ãƒ‡ãƒ«ã®ã‚µã‚¤ã‚ºç¢ºèª\n",
        "# ================================\n",
        "\n",
        "# ãƒ†ã‚¹ãƒˆç”¨ã®å°ã•ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ\n",
        "test_dataset = GrayScottDataset(GIF_FOLDER_PATH, augmentation=None, max_samples=4)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=2, shuffle=False)\n",
        "\n",
        "# ãƒ¢ãƒ‡ãƒ«ä½œæˆ\n",
        "test_model = Conv3DAutoencoderPhase4(latent_dim=512).to(device)\n",
        "\n",
        "print(\"ğŸ” Phase 4 Model Debug Test\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "# ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®å½¢çŠ¶ç¢ºèª\n",
        "test_batch = next(iter(test_dataloader))\n",
        "test_data, test_f, test_k, test_idx = test_batch\n",
        "\n",
        "print(f\"Input shape: {test_data.shape}\")\n",
        "print(f\"f params: {test_f}\")\n",
        "print(f\"k params: {test_k}\")\n",
        "\n",
        "# ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒ‘ã‚¹ãƒ†ã‚¹ãƒˆ\n",
        "test_data = test_data.to(device)\n",
        "test_f = test_f.to(device)\n",
        "test_k = test_k.to(device)\n",
        "\n",
        "try:\n",
        "    with torch.no_grad():\n",
        "        reconstructed, latent, projection = test_model(test_data)\n",
        "    \n",
        "    print(f\"âœ… Forward pass successful!\")\n",
        "    print(f\"Input shape: {test_data.shape}\")\n",
        "    print(f\"Latent shape: {latent.shape}\")\n",
        "    print(f\"Projection shape: {projection.shape}\")\n",
        "    print(f\"Reconstructed shape: {reconstructed.shape}\")\n",
        "    \n",
        "    # æå¤±ãƒ†ã‚¹ãƒˆ\n",
        "    reconstruction_loss = nn.MSELoss()\n",
        "    contrastive_loss = ContrastiveLoss(temperature=0.5)\n",
        "    \n",
        "    recon_loss = reconstruction_loss(reconstructed, test_data)\n",
        "    try:\n",
        "        contrast_loss = contrastive_loss(projection, test_f, test_k)\n",
        "        print(f\"Reconstruction loss: {recon_loss.item():.6f}\")\n",
        "        print(f\"Contrastive loss: {contrast_loss.item():.6f}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Contrastive loss error: {e}\")\n",
        "        print(\"Setting contrastive loss to 0.0\")\n",
        "        contrast_loss = torch.tensor(0.0, device=device)\n",
        "    \n",
        "    print(\"âœ… All tests passed! Ready for training.\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"âŒ Error during forward pass: {e}\")\n",
        "    print(\"Please check the model architecture.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ================================\n",
        "# 8. Phase 4 å®Ÿè¡Œï¼ˆä¿®æ­£ç‰ˆï¼‰\n",
        "# ================================\n",
        "\n",
        "# ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µè¨­å®š\n",
        "augmentation = GrayScottAugmentation()\n",
        "\n",
        "# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ\n",
        "dataset = GrayScottDataset(GIF_FOLDER_PATH, augmentation=augmentation)\n",
        "dataloader = DataLoader(dataset, batch_size=8, shuffle=True, num_workers=2)  # ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’8ã«èª¿æ•´\n",
        "\n",
        "# ãƒ¢ãƒ‡ãƒ«ä½œæˆ\n",
        "model = Conv3DAutoencoderPhase4(latent_dim=512).to(device)\n",
        "\n",
        "# ãƒ¢ãƒ‡ãƒ«æƒ…å ±è¡¨ç¤º\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"ğŸ“Š Phase 4 Model Information\")\n",
        "print(f\"Total Parameters: {total_params:,}\")\n",
        "print(f\"Trainable Parameters: {trainable_params:,}\")\n",
        "print(f\"Model Size: ~{total_params * 4 / 1024 / 1024:.1f} MB\")\n",
        "\n",
        "# è¨“ç·´å®Ÿè¡Œ\n",
        "print(\"\\nğŸš€ Starting Phase 4 Training...\")\n",
        "train_losses = train_phase4_model(model, dataloader, num_epochs=20)  # ã‚¨ãƒãƒƒã‚¯æ•°ã‚’20ã«èª¿æ•´\n",
        "\n",
        "# è©•ä¾¡å®Ÿè¡Œ\n",
        "print(\"\\nğŸ” Starting Phase 4 Evaluation...\")\n",
        "metrics, latents, labels, f_params, k_params = evaluate_phase4_model(model, dataloader)\n",
        "\n",
        "# Phaseæ¯”è¼ƒ\n",
        "print(\"\\nğŸ“ˆ Phase Performance Comparison\")\n",
        "print(\"=\" * 50)\n",
        "print(\"Phase 1 (Baseline 3D CNN): 0.565\")\n",
        "print(\"Phase 2 (ResNet + Attention): 0.467\")\n",
        "print(\"Phase 3 (Multi-Scale Fusion): 0.5144\")\n",
        "print(f\"Phase 4 (Contrastive Learning): {metrics['silhouette_score']:.4f}\")\n",
        "\n",
        "improvement_from_phase3 = ((metrics['silhouette_score'] - 0.5144) / 0.5144) * 100\n",
        "print(f\"\\nPhase 4 vs Phase 3 Improvement: {improvement_from_phase3:+.1f}%\")\n",
        "\n",
        "if metrics['silhouette_score'] > 0.5144:\n",
        "    print(\"ğŸ‰ Phase 4 Success! New best performance achieved!\")\n",
        "else:\n",
        "    print(\"ğŸ“Š Phase 4 results recorded. Consider further optimization.\")\n",
        "\n",
        "print(\"\\nâœ… Phase 4 Implementation Complete!\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
