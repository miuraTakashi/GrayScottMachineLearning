{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# \ud83d\ude80 Gray-Scott Phase 3: Last 64 Frames GPU\u7248\uff08Google Colab\uff09\n", "\n", "**\u76ee\u6a19**: \u5f8c\u534a64\u30d5\u30ec\u30fc\u30e0\u306e\u307f\u3092\u4f7f\u7528\u3057\u305f\u5b66\u7fd2\u3067Phase 1 (0.565) \u2192 Phase 3 (0.65+) \u3078\u306e\u3055\u3089\u306a\u308b\u5411\u4e0a\n", "\n", "**\u4e3b\u8981\u6539\u5584\u70b9**:\n", "- \u2705 \u6b8b\u5dee\u63a5\u7d9a\uff08ResNet\uff09+ \u6642\u7a7a\u9593\u6ce8\u610f\u6a5f\u69cb\n", "- \u2705 GPU\u9ad8\u901f\u5316\uff08CPU\u6bd4 5-10\u500d\uff09\n", "- \u2705 Google Drive\u9023\u643a\n", "- \u2705 **\u5f8c\u534a64\u30d5\u30ec\u30fc\u30e0\u306e\u307f\u3092\u4f7f\u7528** - \u3088\u308a\u5b89\u5b9a\u3057\u305f\u5f8c\u671f\u30d1\u30bf\u30fc\u30f3\u306b\u7126\u70b9\n", "\n", "**\u524d\u63d0\u6761\u4ef6**: Google Drive\u306e`\u30de\u30a4\u30c9\u30e9\u30a4\u30d6/GrayScottML/gif/`\u306b1500\u500b\u306eGIF\u30d5\u30a1\u30a4\u30eb\u3092\u914d\u7f6e\n", "\n", "**\u5b9f\u884c\u6642\u9593**: **GPU 3-5\u5206** \ud83c\udfc3\u200d\u2642\ufe0f\ud83d\udca8\n", "\n", "## \u66f4\u65b0\u5c65\u6b74\n", "- 2025-08-11: Data augmentation\uff08\u5e73\u884c\u79fb\u52d5\u30fb90/180/270\u5ea6\u56de\u8ee2\u30fb\u6c34\u5e73/\u5782\u76f4\u53cd\u8ee2\uff09\u3092\u5c0e\u5165\u3002\n", "  - \u5b66\u7fd2: GrayScottDatasetLast64Aug(augment=True) \u3067\u30aa\u30f3\u30b6\u30d5\u30e9\u30a4\u9069\u7528\n", "  - \u8a55\u4fa1/\u6f5c\u5728\u30d9\u30af\u30c8\u30eb\u62bd\u51fa: augment=False \u3067\u30c7\u30fc\u30bf\u5206\u5e03\u3092\u56fa\u5b9a\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \ud83d\udccb Step 1: \u74b0\u5883\u30bb\u30c3\u30c8\u30a2\u30c3\u30d7 & Google Drive\u63a5\u7d9a\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# \u74b0\u5883\u30bb\u30c3\u30c8\u30a2\u30c3\u30d7\n", "import os\n", "import re\n", "import numpy as np\n", "import pandas as pd\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "from PIL import Image\n", "import imageio.v2 as imageio\n", "from sklearn.decomposition import PCA\n", "from sklearn.manifold import TSNE\n", "from sklearn.cluster import KMeans\n", "from sklearn.preprocessing import StandardScaler\n", "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n", "import torch\n", "import torch.nn as nn\n", "import torch.optim as optim\n", "from torch.utils.data import Dataset, DataLoader\n", "import torch.nn.functional as F\n", "import time\n", "import pickle\n", "\n", "# GPU\u78ba\u8a8d\n", "print(f\"PyTorch version: {torch.__version__}\")\n", "print(f\"CUDA available: {torch.cuda.is_available()}\")\n", "if torch.cuda.is_available():\n", "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n", "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory/1e9:.1f} GB\")\n", "    device = torch.device('cuda')\n", "    # GPU\u6700\u9069\u5316\u8a2d\u5b9a\n", "    torch.backends.cudnn.benchmark = True\n", "    torch.backends.cudnn.deterministic = False\n", "else:\n", "    print(\"\u26a0\ufe0f GPU not available. Please enable GPU in Runtime > Change runtime type\")\n", "    device = torch.device('cpu')\n", "\n", "print(f\"\ud83d\ude80 Using device: {device}\")\n", "\n", "# \u30d1\u30c3\u30b1\u30fc\u30b8\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\n", "try:\n", "    import imageio\n", "    import seaborn\n", "    print(\"\u2705 All packages available\")\n", "except ImportError:\n", "    print(\"\ud83d\udce6 Installing required packages...\")\n", "    !pip install imageio scikit-learn seaborn\n", "    import imageio\n", "    import seaborn\n", "    print(\"\u2705 Packages installed successfully\")\n", "\n", "# \u8ffd\u52a0\u30d1\u30c3\u30b1\u30fc\u30b8\u78ba\u8a8d\n", "try:\n", "    import umap\n", "    import hdbscan\n", "    print(\"\u2705 UMAP/HDBSCAN available\")\n", "except Exception:\n", "    print(\"\ud83d\udce6 Installing umap-learn and hdbscan...\")\n", "    !pip install umap-learn hdbscan\n", "    import umap\n", "    import hdbscan\n", "    print(\"\u2705 UMAP/HDBSCAN installed\")\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Google Drive\u63a5\u7d9a\u3068\u30c7\u30fc\u30bf\u30d1\u30b9\u78ba\u8a8d\n", "from google.colab import drive\n", "\n", "# Google Drive\u3092\u30de\u30a6\u30f3\u30c8\n", "drive.mount('/content/drive')\n", "\n", "# \u30c7\u30fc\u30bf\u30d1\u30b9\u8a2d\u5b9a\n", "GIF_FOLDER_PATH = '/content/drive/MyDrive/GrayScottML/gif'\n", "\n", "# \u30c7\u30fc\u30bf\u78ba\u8a8d\n", "if os.path.exists(GIF_FOLDER_PATH):\n", "    gif_files = [f for f in os.listdir(GIF_FOLDER_PATH) if f.endswith('.gif')]\n", "    gif_count = len(gif_files)\n", "    print(f\"\u2705 Google Drive connected successfully!\")\n", "    print(f\"\ud83d\udcc1 Path: {GIF_FOLDER_PATH}\")\n", "    print(f\"\ud83c\udfac GIF files found: {gif_count}\")\n", "    \n", "    if gif_count >= 1000:\n", "        print(\"\ud83c\udf89 Ready for Phase 2 training with last 64 frames!\")\n", "    else:\n", "        print(f\"\u26a0\ufe0f Not enough files. Expected: 1500, Found: {gif_count}\")\n", "        print(\"Please upload more GIF files to Google Drive.\")\n", "else:\n", "    print(\"\u274c Google Drive path not found!\")\n", "    print(f\"Expected path: {GIF_FOLDER_PATH}\")\n", "    print(\"Please ensure the following structure exists:\")\n", "    print(\"  MyDrive/\")\n", "    print(\"  \u2514\u2500\u2500 GrayScottML/\")\n", "    print(\"      \u2514\u2500\u2500 gif/\")\n", "    print(\"          \u251c\u2500\u2500 GrayScott-f0.0100-k0.0400-00.gif\")\n", "    print(\"          \u2514\u2500\u2500 ... (1500 files)\")\n", "    \n", "    # \u30de\u30a4\u30c9\u30e9\u30a4\u30d6\u306e\u5185\u5bb9\u3092\u8868\u793a\n", "    mydrive_path = '/content/drive/MyDrive'\n", "    if os.path.exists(mydrive_path):\n", "        print(f\"\\n\ud83d\udcc2 Contents of MyDrive:\")\n", "        for item in sorted(os.listdir(mydrive_path))[:10]:\n", "            print(f\"   \ud83d\udcc1 {item}\")\n", "        print(\"   ... (showing first 10 items)\")\n", "    raise FileNotFoundError(\"Please set up the correct folder structure in Google Drive\")\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \ud83e\udde0 Step 2: Phase 2 \u30e2\u30c7\u30eb\u5b9f\u88c5\uff08\u5f8c\u534a64\u30d5\u30ec\u30fc\u30e0\u5bfe\u5fdc\uff09\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# \u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u30af\u30e9\u30b9\uff08\u5f8c\u534a64\u30d5\u30ec\u30fc\u30e0 + Augmentation\uff09\n", "class GrayScottDatasetLast64Aug(Dataset):\n", "    def __init__(self, gif_folder, fixed_frames=64, target_size=(64, 64), max_samples=None, augment=True, max_shift_ratio=0.1):\n", "        self.gif_folder = gif_folder\n", "        self.fixed_frames = fixed_frames\n", "        self.target_size = target_size\n", "        self.max_samples = max_samples\n", "        self.augment = augment\n", "        self.max_shift_ratio = max_shift_ratio\n", "        \n", "        self.gif_files = []\n", "        self.f_values = []\n", "        self.k_values = []\n", "        self.tensors = []\n", "        \n", "        self._load_data()\n", "    \n", "    def _parse_filename(self, filename):\n", "        pattern = r\"GrayScott-f([0-9.]+)-k([0-9.]+)-\\d+\\.gif\"\n", "        m = re.match(pattern, filename)\n", "        if m:\n", "            return float(m.group(1)), float(m.group(2))\n", "        return None, None\n", "    \n", "    def _load_gif_as_tensor(self, gif_path):\n", "        try:\n", "            gif = imageio.mimread(gif_path)\n", "            total_frames = len(gif)\n", "            if total_frames >= self.fixed_frames:\n", "                start_idx = total_frames - self.fixed_frames\n", "                selected_frames = gif[start_idx:]\n", "            else:\n", "                selected_frames = gif\n", "            frames = []\n", "            for frame in selected_frames:\n", "                if len(frame.shape) == 3:\n", "                    frame = np.mean(frame, axis=2)\n", "                pil_frame = Image.fromarray(frame.astype(np.uint8))\n", "                pil_frame = pil_frame.resize(self.target_size)\n", "                frame_array = np.array(pil_frame) / 255.0\n", "                frames.append(frame_array)\n", "            while len(frames) < self.fixed_frames:\n", "                frames.append(frames[-1] if frames else np.zeros(self.target_size))\n", "            frames = frames[:self.fixed_frames]\n", "            tensor = torch.FloatTensor(np.array(frames))  # (T, H, W)\n", "            return tensor.unsqueeze(0)  # (1, T, H, W)\n", "        except Exception as e:\n", "            print(f\"Error loading {gif_path}: {e}\")\n", "            return None\n", "    \n", "    def _load_data(self):\n", "        gif_files = [f for f in os.listdir(self.gif_folder) if f.endswith('.gif')]\n", "        if self.max_samples:\n", "            gif_files = gif_files[:self.max_samples]\n", "        print(f\"Loading {len(gif_files)} GIF files (last 64 frames each) with augmentation={self.augment}...\")\n", "        for i, filename in enumerate(gif_files):\n", "            if i % 100 == 0:\n", "                print(f\"Progress: {i+1}/{len(gif_files)} ({(i+1)/len(gif_files)*100:.1f}%)\")\n", "            f_val, k_val = self._parse_filename(filename)\n", "            if f_val is None or k_val is None:\n", "                continue\n", "            gif_path = os.path.join(self.gif_folder, filename)\n", "            tensor = self._load_gif_as_tensor(gif_path)\n", "            if tensor is not None:\n", "                self.gif_files.append(filename)\n", "                self.f_values.append(f_val)\n", "                self.k_values.append(k_val)\n", "                self.tensors.append(tensor)\n", "        print(f\"\u2705 Successfully loaded {len(self.tensors)} samples\")\n", "    \n", "    def __len__(self):\n", "        return len(self.tensors)\n", "    \n", "    def _random_flip(self, x):\n", "        # x: (1, T, H, W)\n", "        if np.random.rand() < 0.5:\n", "            x = torch.flip(x, dims=[-1])  # horizontal\n", "        if np.random.rand() < 0.5:\n", "            x = torch.flip(x, dims=[-2])  # vertical\n", "        return x\n", "    \n", "    def _random_rotate_90(self, x):\n", "        k = np.random.choice([0,1,2,3])\n", "        if k:\n", "            x = torch.rot90(x, k=k, dims=(-2, -1))\n", "        return x\n", "    \n", "    def _random_translate(self, x):\n", "        # zero-padded translation by up to max_shift_ratio of size\n", "        _, _, H, W = x.shape\n", "        max_dx = int(W * self.max_shift_ratio)\n", "        max_dy = int(H * self.max_shift_ratio)\n", "        if max_dx == 0 and max_dy == 0:\n", "            return x\n", "        dx = int(np.random.randint(-max_dx, max_dx+1))\n", "        dy = int(np.random.randint(-max_dy, max_dy+1))\n", "        if dx == 0 and dy == 0:\n", "            return x\n", "        pad_left = max(dx, 0)\n", "        pad_right = max(-dx, 0)\n", "        pad_top = max(dy, 0)\n", "        pad_bottom = max(-dy, 0)\n", "        x_padded = F.pad(x, (pad_left, pad_right, pad_top, pad_bottom), mode='constant', value=0.0)\n", "        x_cropped = x_padded[:, :, pad_bottom:pad_bottom+H, pad_right:pad_right+W]\n", "        return x_cropped\n", "    \n", "    def _apply_augmentation(self, x):\n", "        x = self._random_flip(x)\n", "        x = self._random_rotate_90(x)\n", "        x = self._random_translate(x)\n", "        return x\n", "    \n", "    def __getitem__(self, idx):\n", "        sample = self.tensors[idx].clone()  # (1, T, H, W)\n", "        if self.augment:\n", "            sample = self._apply_augmentation(sample)\n", "        return {\n", "            'tensor': sample,\n", "            'f_value': self.f_values[idx],\n", "            'k_value': self.k_values[idx],\n", "            'filename': self.gif_files[idx]\n", "        }\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# \u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u30af\u30e9\u30b9\uff08\u5f8c\u534a64\u30d5\u30ec\u30fc\u30e0\u5c02\u7528\uff09\n", "class GrayScottDatasetLast64(Dataset):\n", "    def __init__(self, gif_folder, fixed_frames=64, target_size=(64, 64), max_samples=None):\n", "        self.gif_folder = gif_folder\n", "        self.fixed_frames = fixed_frames\n", "        self.target_size = target_size\n", "        self.max_samples = max_samples\n", "        \n", "        self.gif_files = []\n", "        self.f_values = []\n", "        self.k_values = []\n", "        self.tensors = []\n", "        \n", "        self._load_data()\n", "    \n", "    def _parse_filename(self, filename):\n", "        pattern = r'GrayScott-f([0-9.]+)-k([0-9.]+)-\\d+\\.gif'\n", "        match = re.match(pattern, filename)\n", "        if match:\n", "            return float(match.group(1)), float(match.group(2))\n", "        return None, None\n", "    \n", "    def _load_gif_as_tensor(self, gif_path):\n", "        try:\n", "            gif = imageio.mimread(gif_path)\n", "            total_frames = len(gif)\n", "            \n", "            # \u5f8c\u534a64\u30d5\u30ec\u30fc\u30e0\u3092\u62bd\u51fa\n", "            if total_frames >= self.fixed_frames:\n", "                # \u5f8c\u534a64\u30d5\u30ec\u30fc\u30e0\u3092\u53d6\u5f97\n", "                start_idx = total_frames - self.fixed_frames\n", "                selected_frames = gif[start_idx:]\n", "            else:\n", "                # \u30d5\u30ec\u30fc\u30e0\u6570\u304c64\u672a\u6e80\u306e\u5834\u5408\u306f\u5168\u30d5\u30ec\u30fc\u30e0\u3092\u4f7f\u7528\n", "                selected_frames = gif\n", "                print(f\"Warning: Only {total_frames} frames available, using all frames\")\n", "            \n", "            frames = []\n", "            for frame in selected_frames:\n", "                if len(frame.shape) == 3:\n", "                    frame = np.mean(frame, axis=2)\n", "                \n", "                pil_frame = Image.fromarray(frame.astype(np.uint8))\n", "                pil_frame = pil_frame.resize(self.target_size)\n", "                frame_array = np.array(pil_frame) / 255.0\n", "                frames.append(frame_array)\n", "            \n", "            # 64\u30d5\u30ec\u30fc\u30e0\u306b\u306a\u308b\u3088\u3046\u306b\u30d1\u30c7\u30a3\u30f3\u30b0\uff08\u5fc5\u8981\u306b\u5fdc\u3058\u3066\uff09\n", "            while len(frames) < self.fixed_frames:\n", "                frames.append(frames[-1] if frames else np.zeros(self.target_size))\n", "            \n", "            # \u6b63\u78ba\u306b64\u30d5\u30ec\u30fc\u30e0\u306b\u3059\u308b\n", "            frames = frames[:self.fixed_frames]\n", "            \n", "            tensor = torch.FloatTensor(np.array(frames))\n", "            return tensor.unsqueeze(0)  # \u30c1\u30e3\u30f3\u30cd\u30eb\u6b21\u5143\u3092\u8ffd\u52a0\n", "            \n", "        except Exception as e:\n", "            print(f\"Error loading {gif_path}: {e}\")\n", "            return None\n", "    \n", "    def _load_data(self):\n", "        gif_files = [f for f in os.listdir(self.gif_folder) if f.endswith('.gif')]\n", "        \n", "        if self.max_samples:\n", "            gif_files = gif_files[:self.max_samples]\n", "        \n", "        print(f\"Loading {len(gif_files)} GIF files (last 64 frames each)...\")\n", "        \n", "        for i, filename in enumerate(gif_files):\n", "            if i % 100 == 0:\n", "                print(f\"Progress: {i+1}/{len(gif_files)} ({(i+1)/len(gif_files)*100:.1f}%)\")\n", "            \n", "            f_val, k_val = self._parse_filename(filename)\n", "            if f_val is None or k_val is None:\n", "                continue\n", "            \n", "            gif_path = os.path.join(self.gif_folder, filename)\n", "            tensor = self._load_gif_as_tensor(gif_path)\n", "            \n", "            if tensor is not None:\n", "                self.gif_files.append(filename)\n", "                self.f_values.append(f_val)\n", "                self.k_values.append(k_val)\n", "                self.tensors.append(tensor)\n", "        \n", "        print(f\"\u2705 Successfully loaded {len(self.tensors)} samples with last 64 frames each\")\n", "    \n", "    def __len__(self):\n", "        return len(self.tensors)\n", "    \n", "    def __getitem__(self, idx):\n", "        return {\n", "            'tensor': self.tensors[idx],\n", "            'f_value': self.f_values[idx],\n", "            'k_value': self.k_values[idx],\n", "            'filename': self.gif_files[idx]\n", "        }\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# \u6ce8\u610f\u6a5f\u69cb\u30e2\u30b8\u30e5\u30fc\u30eb\n", "class SpatioTemporalAttention(nn.Module):\n", "    def __init__(self, channels):\n", "        super().__init__()\n", "        \n", "        # \u7a7a\u9593\u6ce8\u610f\n", "        self.spatial_attention = nn.Sequential(\n", "            nn.AdaptiveAvgPool3d((None, 1, 1)),\n", "            nn.Conv3d(channels, channels//4, 1),\n", "            nn.ReLU(inplace=True),\n", "            nn.Conv3d(channels//4, channels, 1),\n", "            nn.Sigmoid()\n", "        )\n", "        \n", "        # \u6642\u9593\u6ce8\u610f\n", "        self.temporal_attention = nn.Sequential(\n", "            nn.AdaptiveAvgPool3d((1, None, None)),\n", "            nn.Conv3d(channels, channels//4, 1),\n", "            nn.ReLU(inplace=True),\n", "            nn.Conv3d(channels//4, channels, 1),\n", "            nn.Sigmoid()\n", "        )\n", "        \n", "        # \u30c1\u30e3\u30f3\u30cd\u30eb\u6ce8\u610f\n", "        self.channel_attention = nn.Sequential(\n", "            nn.AdaptiveAvgPool3d(1),\n", "            nn.Conv3d(channels, channels//4, 1),\n", "            nn.ReLU(inplace=True),\n", "            nn.Conv3d(channels//4, channels, 1),\n", "            nn.Sigmoid()\n", "        )\n", "    \n", "    def forward(self, x):\n", "        identity = x\n", "        \n", "        # 3\u3064\u306e\u6ce8\u610f\u6a5f\u69cb\u3092\u9069\u7528\n", "        x = x * self.spatial_attention(x)\n", "        x = x * self.temporal_attention(x)\n", "        x = x * self.channel_attention(x)\n", "        \n", "        return x + identity * 0.1\n", "\n", "# \u6b8b\u5dee\u6ce8\u610f\u30d6\u30ed\u30c3\u30af\n", "class ResidualAttentionBlock3D(nn.Module):\n", "    def __init__(self, in_channels, out_channels, stride=1):\n", "        super().__init__()\n", "        \n", "        self.conv1 = nn.Conv3d(in_channels, out_channels, 3, stride, 1, bias=False)\n", "        self.bn1 = nn.BatchNorm3d(out_channels, momentum=0.1)\n", "        self.conv2 = nn.Conv3d(out_channels, out_channels, 3, 1, 1, bias=False)\n", "        self.bn2 = nn.BatchNorm3d(out_channels, momentum=0.1)\n", "        \n", "        self.attention = SpatioTemporalAttention(out_channels)\n", "        \n", "        self.shortcut = nn.Sequential()\n", "        if stride != 1 or in_channels != out_channels:\n", "            self.shortcut = nn.Sequential(\n", "                nn.Conv3d(in_channels, out_channels, 1, stride, bias=False),\n", "                nn.BatchNorm3d(out_channels, momentum=0.1)\n", "            )\n", "        \n", "        self.dropout = nn.Dropout3d(0.1)\n", "    \n", "    def forward(self, x):\n", "        identity = x\n", "        \n", "        out = F.relu(self.bn1(self.conv1(x)))\n", "        out = self.dropout(out)\n", "        out = self.bn2(self.conv2(out))\n", "        out = self.attention(out)\n", "        \n", "        out += self.shortcut(identity)\n", "        return F.relu(out)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \ud83d\ude80 Step 3: Phase 2 \u5b66\u7fd2\u5b9f\u884c\uff0864\u30d5\u30ec\u30fc\u30e0\u5bfe\u5fdc\uff09\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Phase 3 architecture\n", "# \u5229\u7528\u3059\u308b\u30e2\u30c7\u30eb: src/gray_scott_autoencoder_phase3.py \u306e Conv3DAutoencoderPhase3 \u3092\u4f7f\u7528\u3057\u307e\u3059\u3002\n", "from src.gray_scott_autoencoder_phase3 import Conv3DAutoencoderPhase3\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Phase 2 \u30e1\u30a4\u30f3\u30e2\u30c7\u30eb\uff0864\u30d5\u30ec\u30fc\u30e0\u5bfe\u5fdc\uff09\n", "class Conv3DAutoencoderPhase2Last64(nn.Module):\n", "    def __init__(self, input_channels=1, fixed_frames=64, target_size=(64, 64), latent_dim=256):\n", "        super().__init__()\n", "        \n", "        self.latent_dim = latent_dim\n", "        self.fixed_frames = fixed_frames\n", "        self.target_size = target_size\n", "        \n", "        # \u521d\u671f\u7573\u307f\u8fbc\u307f\uff0864\u30d5\u30ec\u30fc\u30e0\u5bfe\u5fdc\uff09\n", "        self.initial_conv = nn.Sequential(\n", "            nn.Conv3d(input_channels, 32, (5, 7, 7), (2, 2, 2), (2, 3, 3)),\n", "            nn.BatchNorm3d(32, momentum=0.1),\n", "            nn.ReLU(inplace=True),\n", "            nn.Dropout3d(0.05)\n", "        )\n", "        \n", "        # \u6b8b\u5dee\u6ce8\u610f\u30d6\u30ed\u30c3\u30af\u7fa4\uff0864\u30d5\u30ec\u30fc\u30e0\u7528\u306b\u8abf\u6574\uff09\n", "        self.res_block1 = ResidualAttentionBlock3D(32, 64, stride=(2, 2, 2))\n", "        self.res_block2 = ResidualAttentionBlock3D(64, 64)\n", "        self.res_block3 = ResidualAttentionBlock3D(64, 128, stride=(2, 2, 2))\n", "        self.res_block4 = ResidualAttentionBlock3D(128, 128)\n", "        self.res_block5 = ResidualAttentionBlock3D(128, 256, stride=(2, 2, 2))\n", "        self.res_block6 = ResidualAttentionBlock3D(256, 256)\n", "        \n", "        # \u30b0\u30ed\u30fc\u30d0\u30eb\u30d7\u30fc\u30ea\u30f3\u30b0\n", "        self.global_pool = nn.AdaptiveAvgPool3d((2, 2, 2))\n", "        self.dropout_before_latent = nn.Dropout3d(0.3)\n", "        \n", "        # \u6f5c\u5728\u7a7a\u9593\u5c04\u5f71\n", "        self.to_latent = nn.Sequential(\n", "            nn.Flatten(),\n", "            nn.Linear(256 * 2 * 2 * 2, 512),\n", "            nn.ReLU(inplace=True),\n", "            nn.Dropout(0.4),\n", "            nn.Linear(512, latent_dim),\n", "            nn.BatchNorm1d(latent_dim)\n", "        )\n", "        \n", "        # \u5fa9\u5143\n", "        self.from_latent = nn.Sequential(\n", "            nn.Linear(latent_dim, 512),\n", "            nn.ReLU(inplace=True),\n", "            nn.Dropout(0.4),\n", "            nn.Linear(512, 256 * 2 * 2 * 2),\n", "            nn.ReLU(inplace=True)\n", "        )\n", "        \n", "        # \u30c7\u30b3\u30fc\u30c0\u30fc\uff0864\u30d5\u30ec\u30fc\u30e0\u5fa9\u5143\u7528\uff09\n", "        self.decoder = nn.Sequential(\n", "            nn.ConvTranspose3d(256, 128, (4, 4, 4), (2, 2, 2), (1, 1, 1)),\n", "            nn.BatchNorm3d(128, momentum=0.1),\n", "            nn.ReLU(inplace=True),\n", "            nn.Dropout3d(0.2),\n", "            \n", "            nn.ConvTranspose3d(128, 64, (4, 4, 4), (2, 2, 2), (1, 1, 1)),\n", "            nn.BatchNorm3d(64, momentum=0.1),\n", "            nn.ReLU(inplace=True),\n", "            nn.Dropout3d(0.15),\n", "            \n", "            nn.ConvTranspose3d(64, 32, (4, 4, 4), (2, 2, 2), (1, 1, 1)),\n", "            nn.BatchNorm3d(32, momentum=0.1),\n", "            nn.ReLU(inplace=True),\n", "            nn.Dropout3d(0.1),\n", "            \n", "            nn.ConvTranspose3d(32, input_channels, (6, 7, 7), (2, 2, 2), (2, 3, 3)),\n", "            nn.Sigmoid()\n", "        )\n", "    \n", "    def encode(self, x):\n", "        x = self.initial_conv(x)\n", "        x = self.res_block1(x)\n", "        x = self.res_block2(x)\n", "        x = self.res_block3(x)\n", "        x = self.res_block4(x)\n", "        x = self.res_block5(x)\n", "        x = self.res_block6(x)\n", "        x = self.global_pool(x)\n", "        x = self.dropout_before_latent(x)\n", "        return self.to_latent(x)\n", "    \n", "    def decode(self, latent):\n", "        x = self.from_latent(latent)\n", "        x = x.view(-1, 256, 2, 2, 2)\n", "        x = self.decoder(x)\n", "        target_h, target_w = self.target_size\n", "        return F.interpolate(x, size=(self.fixed_frames, target_h, target_w), \n", "                           mode='trilinear', align_corners=False)\n", "    \n", "    def forward(self, x):\n", "        latent = self.encode(x)\n", "        reconstructed = self.decode(latent)\n", "        return reconstructed, latent\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Phase 3 \u5b66\u7fd2\u30fb\u8a55\u4fa1\u5b9f\u884c\uff0864\u30d5\u30ec\u30fc\u30e0\u7248\uff09\n", "def run_phase3_training_last64():\n", "    # \u30d1\u30e9\u30e1\u30fc\u30bf\u8a2d\u5b9a\n", "    fixed_frames = 64  # \u5f8c\u534a64\u30d5\u30ec\u30fc\u30e0\n", "    target_size = (64, 64)\n", "    latent_dim = 512\n", "    num_epochs = 50\n", "    batch_size = 6 if torch.cuda.is_available() else 3  # 64\u30d5\u30ec\u30fc\u30e0\u306a\u306e\u3067\u5c11\u3057\u5c0f\u3055\u304f\n", "    learning_rate = 1e-3\n", "    weight_decay = 1e-4\n", "    n_clusters = 5\n", "    \n", "    print(\"\ud83d\udd04 Creating dataset (last 64 frames, with augmentation)...\")\n", "    dataset = GrayScottDatasetLast64Aug(GIF_FOLDER_PATH, fixed_frames, target_size, augment=True)\n", "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, \n", "                          num_workers=2, pin_memory=True)\n", "    \n", "    print(f\"\ud83d\udcca Dataset: {len(dataset)} samples, Batch size: {batch_size}, Frames: {fixed_frames}\")\n", "    \n", "    print(\"\ud83e\udde0 Creating Phase 3 model (64 frames)...\")\n", "    model = Conv3DAutoencoderPhase3(latent_dim=latent_dim, \n", "                                         fixed_frames=fixed_frames, \n", "                                         target_size=target_size).to(device)\n", "    \n", "    print(f\"\ud83d\udcca Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n", "    \n", "    # \u8a13\u7df4\n", "    print(\"\ud83c\udfaf Starting training with last 64 frames...\")\n", "    model.train()\n", "    criterion = nn.MSELoss()\n", "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n", "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=1e-6)\n", "    \n", "    losses = []\n", "    start_time = time.time()\n", "    \n", "    print(f\"\ud83d\ude80 Phase 3 GPU Training: ResNet + Attention (Last 64 Frames)\")\n", "    print(\"=\" * 80)\n", "    \n", "    for epoch in range(num_epochs):\n", "        epoch_start_time = time.time()\n", "        epoch_loss = 0.0\n", "        \n", "        for batch_idx, batch in enumerate(dataloader):\n", "            tensors = batch['tensor'].to(device, non_blocking=True)\n", "            \n", "            optimizer.zero_grad()\n", "            reconstructed, latent = model(tensors)\n", "            loss = criterion(reconstructed, tensors)\n", "            loss.backward()\n", "            \n", "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5)\n", "            optimizer.step()\n", "            epoch_loss += loss.item()\n", "        \n", "        scheduler.step()\n", "        \n", "        avg_loss = epoch_loss / len(dataloader)\n", "        losses.append(avg_loss)\n", "        current_lr = scheduler.get_last_lr()[0]\n", "        epoch_time = time.time() - epoch_start_time\n", "        \n", "        # \u9032\u6357\u8868\u793a\n", "        progress = ((epoch + 1) / num_epochs) * 100\n", "        if (epoch + 1) % 5 == 0 or epoch < 5:\n", "            print(f'Epoch [{epoch+1:2d}/{num_epochs}] '\n", "                  f'({progress:5.1f}%) | '\n", "                  f'Loss: {avg_loss:.6f} | '\n", "                  f'LR: {current_lr:.2e} | '\n", "                  f'Time: {epoch_time:.1f}s')\n", "    \n", "    total_time = time.time() - start_time\n", "    print(\"=\" * 80)\n", "    print(f\"\ud83c\udf89 Training completed in {total_time/60:.1f} minutes\")\n", "    \n", "    # \u5b66\u7fd2\u66f2\u7dda\u8868\u793a\n", "    plt.figure(figsize=(10, 6))\n", "    plt.plot(losses, linewidth=2, color='purple')\n", "    plt.title('Phase 3: GPU Training Loss (ResNet + Attention, Last 64 Frames)', fontsize=14)\n", "    plt.xlabel('Epoch')\n", "    plt.ylabel('Loss')\n", "    plt.grid(True, alpha=0.3)\n", "    plt.show()\n", "    \n", "    # \u6f5c\u5728\u30d9\u30af\u30c8\u30eb\u62bd\u51fa\n", "    print(\"\ud83d\udd0d Extracting latent vectors...\")\n", "    # Rebuild dataset without augmentation for evaluation/feature extraction\n", "    dataset_eval = GrayScottDatasetLast64Aug(GIF_FOLDER_PATH, fixed_frames, target_size, augment=False)\n", "    dataloader_eval = DataLoader(dataset_eval, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n", "\n", "    model.eval()\n", "    latent_vectors = []\n", "    f_values = []\n", "    k_values = []\n", "    \n", "    with torch.no_grad():\n", "        for batch in dataloader_eval:\n", "            tensors = batch['tensor'].to(device)\n", "            _, latent = model(tensors)\n", "            latent_vectors.append(latent.cpu().numpy())\n", "            f_values.extend(batch['f_value'].numpy())\n", "            k_values.extend(batch['k_value'].numpy())\n", "    \n", "    latent_vectors = np.vstack(latent_vectors)\n", "    f_values = np.array(f_values)\n", "    k_values = np.array(k_values)\n", "    \n", "    # \u30af\u30e9\u30b9\u30bf\u30ea\u30f3\u30b0\n", "    print(\"\ufffd\ufffd Performing clustering with multiple strategies...\")\n", "from sklearn.decomposition import PCA as _PCA\n", "from sklearn.preprocessing import StandardScaler as _SS\n", "from sklearn.cluster import KMeans as _KMeans\n", "# Strategy A: PCA(whiten=True) -> KMeans(n_init=50)\n", "Xa = _PCA(n_components=min(64, latent_vectors.shape[1]), whiten=True, random_state=42).fit_transform(latent_vectors)\n", "labels_a = _KMeans(n_clusters=n_clusters, n_init=50, random_state=42).fit_predict(Xa)\n", "sil_a = silhouette_score(latent_vectors, labels_a)\n", "print(f\"[A] PCA(whiten)+KMeans(n_init=50): Silhouette={sil_a:.4f}\")\n", "\n", "# Strategy B: L2-normalize -> KMeans(n_init=50)  (cosine\u8fd1\u4f3c)\n", "Xb = latent_vectors / (np.linalg.norm(latent_vectors, axis=1, keepdims=True) + 1e-8)\n", "labels_b = _KMeans(n_clusters=n_clusters, n_init=50, random_state=42).fit_predict(Xb)\n", "sil_b = silhouette_score(latent_vectors, labels_b)\n", "print(f\"[B] L2-norm+KMeans(n_init=50): Silhouette={sil_b:.4f}\")\n", "\n", "# Strategy C: UMAP -> HDBSCAN\n", "try:\n", "    import umap\n", "    import hdbscan\n", "    U = umap.UMAP(n_neighbors=15, min_dist=0.1, n_components=10, random_state=42).fit_transform(latent_vectors)\n", "    labels_c = hdbscan.HDBSCAN(min_cluster_size=20).fit_predict(U)\n", "    # -1 \u306f\u30ce\u30a4\u30ba\n", "    valid = labels_c != -1\n", "    if valid.any() and len(set(labels_c[valid]))>1:\n", "        sil_c = silhouette_score(latent_vectors[valid], labels_c[valid])\n", "        print(f\"[C] UMAP+HDBSCAN: clusters={len(set(labels_c[valid]))}, noise={(~valid).sum()}, Silhouette(valid)={sil_c:.4f}\")\n", "    else:\n", "        print(f\"[C] UMAP+HDBSCAN: clusters={len(set(labels_c)) if len(set(labels_c))>1 else 0}, noise={(labels_c==-1).sum()} (silhouette N/A)\")\n", "except Exception as e:\n", "    print(f\"[C] UMAP+HDBSCAN unavailable: {e}\")\n", "\n", "# \u65e2\u5b9a\u306e\u51fa\u529b\u3092[A]\u306b\u8a2d\u5b9a\n", "cluster_labels = labels_a\n", "# Phase 1\u3068\u306e\u6bd4\u8f03\n", "    phase1_score = 0.565\n", "    improvement = ((silhouette_avg - phase1_score) / phase1_score) * 100\n", "    \n", "    print(f\"\ud83d\udcc8 Performance Comparison:\")\n", "    print(f\"   Phase 1 (30 frames): {phase1_score:.4f}\")\n", "    print(f\"   Phase 3 (last 64 frames): {silhouette_avg:.4f}\")\n", "    print(f\"   Improvement: {improvement:+.1f}%\")\n", "    \n", "    if improvement >= 15:\n", "        print(\"\ud83c\udf89 Phase 3 \u76ee\u6a19\u9054\u6210\uff01 (15%\u4ee5\u4e0a\u306e\u5411\u4e0a) - Last 64 frames strategy successful!\")\n", "    else:\n", "        print(f\"\u26a0\ufe0f  Phase 3 \u76ee\u6a19\u672a\u9054 ({improvement:.1f}% < 15%) - Consider further optimization\")\n", "    \n", "    return {\n", "        'model': model,\n", "        'losses': losses,\n", "        'silhouette_score': silhouette_avg,\n", "        'calinski_score': calinski_score,\n", "        'davies_bouldin': davies_bouldin,\n", "        'latent_vectors': latent_vectors,\n", "        'cluster_labels': cluster_labels,\n", "        'f_values': f_values,\n", "        'k_values': k_values,\n", "        'improvement': improvement,\n", "        'frames_used': 'last_64'\n", "    }\n", "\n", "# \u5b9f\u884c\n", "print(\"\ud83d\ude80 Starting Phase 3 training with last 64 frames...\")\n", "results = run_phase3_training_last64()\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \ud83d\udce5 Step 4: \u7d50\u679c\u4fdd\u5b58\u30fb\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# \u7d50\u679c\u4fdd\u5b58\u3068\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\uff08Last 64 frames\u7248\uff09\n", "import pickle\n", "from google.colab import files\n", "\n", "# \u7d50\u679c\u3092Google Drive\u306b\u4fdd\u5b58\n", "results_path = '/content/drive/MyDrive/GrayScottML/phase2_results_last64_gpu.pkl'\n", "model_path = '/content/drive/MyDrive/GrayScottML/phase2_model_last64_gpu.pth'\n", "\n", "# \u7d50\u679c\u4fdd\u5b58\n", "with open(results_path, 'wb') as f:\n", "    # \u30e2\u30c7\u30eb\u306f\u9664\u3044\u3066\u4fdd\u5b58\uff08\u30b5\u30a4\u30ba\u524a\u6e1b\uff09\n", "    save_results = {k: v for k, v in results.items() if k != 'model'}\n", "    pickle.dump(save_results, f)\n", "\n", "# \u30e2\u30c7\u30eb\u4fdd\u5b58\n", "torch.save(results['model'].state_dict(), model_path)\n", "\n", "print(f\"\ud83d\udcbe Results saved to Google Drive:\")\n", "print(f\"   \ud83d\udcca Results: {results_path}\")\n", "print(f\"   \ud83e\udde0 Model: {model_path}\")\n", "\n", "# \u30ed\u30fc\u30ab\u30eb\u306b\u3082\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u7528\u30d5\u30a1\u30a4\u30eb\u4f5c\u6210\n", "local_results_path = 'phase2_results_last64_gpu.pkl'\n", "local_model_path = 'phase2_model_last64_gpu.pth'\n", "\n", "with open(local_results_path, 'wb') as f:\n", "    save_results = {k: v for k, v in results.items() if k != 'model'}\n", "    pickle.dump(save_results, f)\n", "\n", "torch.save(results['model'].state_dict(), local_model_path)\n", "\n", "print(\"\\n\ud83d\udce5 Downloading files...\")\n", "files.download(local_results_path)\n", "files.download(local_model_path)\n", "\n", "print(\"\u2705 Download completed!\")\n", "print(f\"\ud83c\udfaf Final Results (Last 64 Frames):\")\n", "print(f\"   \u2b50 Silhouette Score: {results['silhouette_score']:.4f}\")\n", "print(f\"   \ud83d\udcc8 Improvement: {results['improvement']:+.1f}%\")\n", "print(f\"   \ud83c\udfac Strategy: Using last 64 frames for more stable patterns\")\n", "print(f\"   \ud83c\udfc6 Target: {'\u2705 ACHIEVED' if results['improvement'] >= 15 else '\u274c NOT ACHIEVED'}\")\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \ud83d\udcca Step 5: \u53ef\u8996\u5316\u30fb\u5206\u6790\uff08Optional\uff09\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# \u7d50\u679c\u306e\u8a73\u7d30\u53ef\u8996\u5316\uff08Last 64 frames\uff09\n", "def visualize_results_last64(results):\n", "    latent_vectors = results['latent_vectors']\n", "    cluster_labels = results['cluster_labels']\n", "    f_values = results['f_values']\n", "    k_values = results['k_values']\n", "    \n", "    # PCA\u3068t-SNE\u306b\u3088\u308b\u6b21\u5143\u524a\u6e1b\n", "    print(\"\ud83d\udd0d Performing dimensionality reduction...\")\n", "    pca = PCA(n_components=2, random_state=42)\n", "    pca_result = pca.fit_transform(latent_vectors)\n", "    \n", "    tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n", "    tsne_result = tsne.fit_transform(latent_vectors)\n", "    \n", "    # \u53ef\u8996\u5316\n", "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n", "    fig.suptitle('Phase 2 Results: Phase 3 (Last 64 Frames) Analysis', fontsize=16, fontweight='bold')\n", "    \n", "    # f-k\u7a7a\u9593\u3067\u306e\u30af\u30e9\u30b9\u30bf\u30ea\u30f3\u30b0\u7d50\u679c\n", "    scatter1 = axes[0, 0].scatter(f_values, k_values, c=cluster_labels, cmap='tab10', alpha=0.7, s=20)\n", "    axes[0, 0].set_xlabel('f parameter')\n", "    axes[0, 0].set_ylabel('k parameter')\n", "    axes[0, 0].set_title('Clustering Results in f-k Parameter Space')\n", "    axes[0, 0].invert_yaxis()\n", "    plt.colorbar(scatter1, ax=axes[0, 0], label='Cluster ID')\n", "    \n", "    # PCA\u7d50\u679c\n", "    scatter2 = axes[0, 1].scatter(pca_result[:, 0], pca_result[:, 1], c=cluster_labels, cmap='tab10', alpha=0.7, s=20)\n", "    axes[0, 1].set_title(f'PCA of Latent Space (Phase 3 (Last 64 Frames))')\n", "    axes[0, 1].set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} variance)')\n", "    axes[0, 1].set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} variance)')\n", "    plt.colorbar(scatter2, ax=axes[0, 1], label='Cluster ID')\n", "    \n", "    # t-SNE\u7d50\u679c\n", "    scatter3 = axes[1, 0].scatter(tsne_result[:, 0], tsne_result[:, 1], c=cluster_labels, cmap='tab10', alpha=0.7, s=20)\n", "    axes[1, 0].set_title('t-SNE of Latent Space (Phase 3 (Last 64 Frames))')\n", "    plt.colorbar(scatter3, ax=axes[1, 0], label='Cluster ID')\n", "    \n", "    # \u30af\u30e9\u30b9\u30bf\u30fc\u7d71\u8a08\n", "    axes[1, 1].axis('off')\n", "    n_clusters = len(np.unique(cluster_labels))\n", "    stats_text = f\"Phase 3 (Last 64 Frames) Analysis:\\\\n\\\\n\"\n", "    stats_text += f\"Silhouette Score: {results['silhouette_score']:.4f}\\\\n\"\n", "    stats_text += f\"Improvement: {results['improvement']:+.1f}%\\\\n\\\\n\"\n", "    \n", "    for i in range(n_clusters):\n", "        mask = cluster_labels == i\n", "        count = np.sum(mask)\n", "        f_mean = f_values[mask].mean()\n", "        k_mean = k_values[mask].mean()\n", "        stats_text += f\"Cluster {i}: {count} samples\\\\n\"\n", "        stats_text += f\"  f_avg: {f_mean:.4f}\\\\n\"\n", "        stats_text += f\"  k_avg: {k_mean:.4f}\\\\n\\\\n\"\n", "    \n", "    axes[1, 1].text(0.1, 0.9, stats_text, transform=axes[1, 1].transAxes, \n", "                    fontsize=10, verticalalignment='top', fontfamily='monospace')\n", "    \n", "    plt.tight_layout()\n", "    plt.show()\n", "    \n", "    print(\"\ud83d\udcca Visualization completed!\")\n", "    print(f\"\ud83c\udfac Strategy: Last 64 frames captured more stable, mature patterns\")\n", "    print(f\"\u2b50 Final Score: {results['silhouette_score']:.4f}\")\n", "\n", "# \u53ef\u8996\u5316\u5b9f\u884c\n", "print(\"\ud83c\udfa8 Creating visualizations...\")\n", "visualize_results_last64(results)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Google Drive\u30d5\u30a9\u30eb\u30c0\u78ba\u8a8d\u30fb\u4f5c\u6210\u652f\u63f4\n", "from google.colab import drive\n", "import os\n", "\n", "# Google Drive\u3092\u30de\u30a6\u30f3\u30c8\n", "drive.mount('/content/drive')\n", "\n", "# \u30d5\u30a9\u30eb\u30c0\u30d1\u30b9\u8a2d\u5b9a\uff08\u30de\u30a4\u30c9\u30e9\u30a4\u30d6\u5185\uff09\n", "base_path = '/content/drive/MyDrive'\n", "project_folder = os.path.join(base_path, 'GrayScottML')\n", "gif_folder = os.path.join(project_folder, 'gif')\n", "\n", "# \u6bb5\u968e\u7684\u306b\u30d5\u30a9\u30eb\u30c0\u4f5c\u6210\n", "try:\n", "    if not os.path.exists(project_folder):\n", "        os.makedirs(project_folder)\n", "        print(f\"\u2705 Created: {project_folder}\")\n", "    else:\n", "        print(f\"\u2705 Already exists: {project_folder}\")\n", "        \n", "    if not os.path.exists(gif_folder):\n", "        os.makedirs(gif_folder)\n", "        print(f\"\u2705 Created: {gif_folder}\")\n", "    else:\n", "        print(f\"\u2705 Already exists: {gif_folder}\")\n", "        \n", "    # \u30c6\u30b9\u30c8\u30d5\u30a1\u30a4\u30eb\u4f5c\u6210\uff08\u30d5\u30a9\u30eb\u30c0\u304c\u78ba\u5b9f\u306b\u5b58\u5728\u3059\u308b\u3053\u3068\u3092\u78ba\u8a8d\uff09\n", "    test_file = os.path.join(project_folder, 'test.txt')\n", "    with open(test_file, 'w') as f:\n", "        f.write('GrayScott ML Project - Folder created successfully!')\n", "    \n", "    print(\"\ud83c\udf89 Folder structure created successfully!\")\n", "    print(\"\ud83d\udcc1 Structure:\")\n", "    print(f\"   {project_folder}\")\n", "    print(f\"   \u2514\u2500\u2500 {gif_folder}\")\n", "    print(f\"   \u2514\u2500\u2500 test.txt\")\n", "    \n", "    # Google Drive\u5074\u3067\u78ba\u8a8d\u3059\u308b\u3088\u3046\u6848\u5185\n", "    print(\"\\n\ud83d\udca1 Please check your Google Drive:\")\n", "    print(\"   MyDrive > GrayScottML > gif (folder)\")\n", "    print(\"   MyDrive > GrayScottML > test.txt (file)\")\n", "    \n", "except Exception as e:\n", "    print(f\"\u274c Error creating folders: {e}\")\n", "    print(\"Please try creating folders manually in Google Drive web interface\")\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# \u30d1\u30b9\u78ba\u8a8d\u3068\u30c7\u30d0\u30c3\u30b0\n", "from google.colab import drive\n", "import os\n", "\n", "# Google Drive\u3092\u30de\u30a6\u30f3\u30c8\n", "drive.mount('/content/drive')\n", "\n", "# \u8907\u6570\u306e\u30d1\u30b9\u5019\u88dc\u3092\u78ba\u8a8d\n", "path_candidates = [\n", "    '/content/drive/MyDrive/GrayScottML/gif',           # \u30de\u30a4\u30c9\u30e9\u30a4\u30d6\u5185\n", "    '/content/drive/MyDrive/GrayScottML',               # \u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u30d5\u30a9\u30eb\u30c0\n", "    '/content/drive/GrayScottML/gif',                   # \u30eb\u30fc\u30c8\u76f4\u4e0b\uff08\u3082\u3057\u3042\u308c\u3070\uff09\n", "]\n", "\n", "print(\"\ud83d\udd0d Searching for GrayScottML folder...\")\n", "found_path = None\n", "\n", "for path in path_candidates:\n", "    if os.path.exists(path):\n", "        print(f\"\u2705 Found: {path}\")\n", "        if path.endswith('/gif'):\n", "            gif_count = len([f for f in os.listdir(path) if f.endswith('.gif')])\n", "            print(f\"   \ud83d\udcc1 GIF files: {gif_count}\")\n", "            if gif_count > 0:\n", "                found_path = path\n", "                break\n", "        else:\n", "            contents = os.listdir(path)\n", "            print(f\"   \ud83d\udcc1 Contents: {contents}\")\n", "            if 'gif' in contents:\n", "                gif_path = os.path.join(path, 'gif')\n", "                gif_count = len([f for f in os.listdir(gif_path) if f.endswith('.gif')])\n", "                print(f\"   \ud83d\udcc1 GIF files in gif/: {gif_count}\")\n", "                if gif_count > 0:\n", "                    found_path = gif_path\n", "                    break\n", "    else:\n", "        print(f\"\u274c Not found: {path}\")\n", "\n", "# \u30de\u30a4\u30c9\u30e9\u30a4\u30d6\u306e\u5185\u5bb9\u3092\u8868\u793a\n", "mydrive_path = '/content/drive/MyDrive'\n", "if os.path.exists(mydrive_path):\n", "    print(f\"\\n\ud83d\udcc2 Contents of MyDrive:\")\n", "    for item in sorted(os.listdir(mydrive_path)):\n", "        item_path = os.path.join(mydrive_path, item)\n", "        if os.path.isdir(item_path):\n", "            print(f\"   \ud83d\udcc1 {item}\")\n", "        else:\n", "            print(f\"   \ud83d\udcc4 {item}\")\n", "\n", "if found_path:\n", "    print(f\"\\n\ud83c\udf89 Ready to use: {found_path}\")\n", "    # \u30b0\u30ed\u30fc\u30d0\u30eb\u5909\u6570\u3068\u3057\u3066\u8a2d\u5b9a\n", "    GIF_FOLDER_PATH = found_path\n", "    print(f\"\ud83d\udd17 GIF_FOLDER_PATH = '{GIF_FOLDER_PATH}'\")\n", "else:\n", "    print(f\"\\n\u26a0\ufe0f GrayScottML folder not found. Please:\")\n", "    print(\"1. Create 'GrayScottML' folder in MyDrive\")\n", "    print(\"2. Create 'gif' subfolder inside GrayScottML\")\n", "    print(\"3. Upload 1500 GIF files to the gif folder\")\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}], "metadata": {"language_info": {"name": "python"}, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}}, "nbformat": 4, "nbformat_minor": 2}