{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# 🚀 Gray-Scott Phase 2: Last 64 Frames GPU版（Google Colab）\n",
        "\n",
        "**目標**: 後半64フレームのみを使用した学習でPhase 1 (0.565) → Phase 2 (0.65+) へのさらなる向上\n",
        "\n",
        "**主要改善点**:\n",
        "- ✅ 残差接続（ResNet）+ 時空間注意機構\n",
        "- ✅ GPU高速化（CPU比 5-10倍）\n",
        "- ✅ Google Drive連携\n",
        "- ✅ **後半64フレームのみを使用** - より安定した後期パターンに焦点\n",
        "\n",
        "**前提条件**: Google Driveの`マイドライブ/GrayScottML/gif/`に1500個のGIFファイルを配置\n",
        "\n",
        "**実行時間**: **GPU 3-5分** 🏃‍♂️💨\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 📋 Step 1: 環境セットアップ & Google Drive接続\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 環境セットアップ\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "import imageio.v2 as imageio\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "import time\n",
        "import pickle\n",
        "\n",
        "# GPU確認\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory/1e9:.1f} GB\")\n",
        "    device = torch.device('cuda')\n",
        "    # GPU最適化設定\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    torch.backends.cudnn.deterministic = False\n",
        "else:\n",
        "    print(\"⚠️ GPU not available. Please enable GPU in Runtime > Change runtime type\")\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "print(f\"🚀 Using device: {device}\")\n",
        "\n",
        "# パッケージインストール\n",
        "try:\n",
        "    import imageio\n",
        "    import seaborn\n",
        "    print(\"✅ All packages available\")\n",
        "except ImportError:\n",
        "    print(\"📦 Installing required packages...\")\n",
        "    !pip install imageio scikit-learn seaborn\n",
        "    import imageio\n",
        "    import seaborn\n",
        "    print(\"✅ Packages installed successfully\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Google Drive接続とデータパス確認\n",
        "from google.colab import drive\n",
        "\n",
        "# Google Driveをマウント\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# データパス設定\n",
        "GIF_FOLDER_PATH = '/content/drive/MyDrive/GrayScottML/gif'\n",
        "\n",
        "# データ確認\n",
        "if os.path.exists(GIF_FOLDER_PATH):\n",
        "    gif_files = [f for f in os.listdir(GIF_FOLDER_PATH) if f.endswith('.gif')]\n",
        "    gif_count = len(gif_files)\n",
        "    print(f\"✅ Google Drive connected successfully!\")\n",
        "    print(f\"📁 Path: {GIF_FOLDER_PATH}\")\n",
        "    print(f\"🎬 GIF files found: {gif_count}\")\n",
        "    \n",
        "    if gif_count >= 1000:\n",
        "        print(\"🎉 Ready for Phase 2 training with last 64 frames!\")\n",
        "    else:\n",
        "        print(f\"⚠️ Not enough files. Expected: 1500, Found: {gif_count}\")\n",
        "        print(\"Please upload more GIF files to Google Drive.\")\n",
        "else:\n",
        "    print(\"❌ Google Drive path not found!\")\n",
        "    print(f\"Expected path: {GIF_FOLDER_PATH}\")\n",
        "    print(\"Please ensure the following structure exists:\")\n",
        "    print(\"  MyDrive/\")\n",
        "    print(\"  └── GrayScottML/\")\n",
        "    print(\"      └── gif/\")\n",
        "    print(\"          ├── GrayScott-f0.0100-k0.0400-00.gif\")\n",
        "    print(\"          └── ... (1500 files)\")\n",
        "    \n",
        "    # マイドライブの内容を表示\n",
        "    mydrive_path = '/content/drive/MyDrive'\n",
        "    if os.path.exists(mydrive_path):\n",
        "        print(f\"\\n📂 Contents of MyDrive:\")\n",
        "        for item in sorted(os.listdir(mydrive_path))[:10]:\n",
        "            print(f\"   📁 {item}\")\n",
        "        print(\"   ... (showing first 10 items)\")\n",
        "    raise FileNotFoundError(\"Please set up the correct folder structure in Google Drive\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 🧠 Step 2: Phase 2 モデル実装（後半64フレーム対応）\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# データセットクラス（後半64フレーム専用）\n",
        "class GrayScottDatasetLast64(Dataset):\n",
        "    def __init__(self, gif_folder, fixed_frames=64, target_size=(64, 64), max_samples=None):\n",
        "        self.gif_folder = gif_folder\n",
        "        self.fixed_frames = fixed_frames\n",
        "        self.target_size = target_size\n",
        "        self.max_samples = max_samples\n",
        "        \n",
        "        self.gif_files = []\n",
        "        self.f_values = []\n",
        "        self.k_values = []\n",
        "        self.tensors = []\n",
        "        \n",
        "        self._load_data()\n",
        "    \n",
        "    def _parse_filename(self, filename):\n",
        "        pattern = r'GrayScott-f([0-9.]+)-k([0-9.]+)-\\d+\\.gif'\n",
        "        match = re.match(pattern, filename)\n",
        "        if match:\n",
        "            return float(match.group(1)), float(match.group(2))\n",
        "        return None, None\n",
        "    \n",
        "    def _load_gif_as_tensor(self, gif_path):\n",
        "        try:\n",
        "            gif = imageio.mimread(gif_path)\n",
        "            total_frames = len(gif)\n",
        "            \n",
        "            # 後半64フレームを抽出\n",
        "            if total_frames >= self.fixed_frames:\n",
        "                # 後半64フレームを取得\n",
        "                start_idx = total_frames - self.fixed_frames\n",
        "                selected_frames = gif[start_idx:]\n",
        "            else:\n",
        "                # フレーム数が64未満の場合は全フレームを使用\n",
        "                selected_frames = gif\n",
        "                print(f\"Warning: Only {total_frames} frames available, using all frames\")\n",
        "            \n",
        "            frames = []\n",
        "            for frame in selected_frames:\n",
        "                if len(frame.shape) == 3:\n",
        "                    frame = np.mean(frame, axis=2)\n",
        "                \n",
        "                pil_frame = Image.fromarray(frame.astype(np.uint8))\n",
        "                pil_frame = pil_frame.resize(self.target_size)\n",
        "                frame_array = np.array(pil_frame) / 255.0\n",
        "                frames.append(frame_array)\n",
        "            \n",
        "            # 64フレームになるようにパディング（必要に応じて）\n",
        "            while len(frames) < self.fixed_frames:\n",
        "                frames.append(frames[-1] if frames else np.zeros(self.target_size))\n",
        "            \n",
        "            # 正確に64フレームにする\n",
        "            frames = frames[:self.fixed_frames]\n",
        "            \n",
        "            tensor = torch.FloatTensor(np.array(frames))\n",
        "            return tensor.unsqueeze(0)  # チャンネル次元を追加\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {gif_path}: {e}\")\n",
        "            return None\n",
        "    \n",
        "    def _load_data(self):\n",
        "        gif_files = [f for f in os.listdir(self.gif_folder) if f.endswith('.gif')]\n",
        "        \n",
        "        if self.max_samples:\n",
        "            gif_files = gif_files[:self.max_samples]\n",
        "        \n",
        "        print(f\"Loading {len(gif_files)} GIF files (last 64 frames each)...\")\n",
        "        \n",
        "        for i, filename in enumerate(gif_files):\n",
        "            if i % 100 == 0:\n",
        "                print(f\"Progress: {i+1}/{len(gif_files)} ({(i+1)/len(gif_files)*100:.1f}%)\")\n",
        "            \n",
        "            f_val, k_val = self._parse_filename(filename)\n",
        "            if f_val is None or k_val is None:\n",
        "                continue\n",
        "            \n",
        "            gif_path = os.path.join(self.gif_folder, filename)\n",
        "            tensor = self._load_gif_as_tensor(gif_path)\n",
        "            \n",
        "            if tensor is not None:\n",
        "                self.gif_files.append(filename)\n",
        "                self.f_values.append(f_val)\n",
        "                self.k_values.append(k_val)\n",
        "                self.tensors.append(tensor)\n",
        "        \n",
        "        print(f\"✅ Successfully loaded {len(self.tensors)} samples with last 64 frames each\")\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.tensors)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            'tensor': self.tensors[idx],\n",
        "            'f_value': self.f_values[idx],\n",
        "            'k_value': self.k_values[idx],\n",
        "            'filename': self.gif_files[idx]\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 注意機構モジュール\n",
        "class SpatioTemporalAttention(nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super().__init__()\n",
        "        \n",
        "        # 空間注意\n",
        "        self.spatial_attention = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool3d((None, 1, 1)),\n",
        "            nn.Conv3d(channels, channels//4, 1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv3d(channels//4, channels, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        \n",
        "        # 時間注意\n",
        "        self.temporal_attention = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool3d((1, None, None)),\n",
        "            nn.Conv3d(channels, channels//4, 1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv3d(channels//4, channels, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        \n",
        "        # チャンネル注意\n",
        "        self.channel_attention = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool3d(1),\n",
        "            nn.Conv3d(channels, channels//4, 1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv3d(channels//4, channels, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "        \n",
        "        # 3つの注意機構を適用\n",
        "        x = x * self.spatial_attention(x)\n",
        "        x = x * self.temporal_attention(x)\n",
        "        x = x * self.channel_attention(x)\n",
        "        \n",
        "        return x + identity * 0.1\n",
        "\n",
        "# 残差注意ブロック\n",
        "class ResidualAttentionBlock3D(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.conv1 = nn.Conv3d(in_channels, out_channels, 3, stride, 1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm3d(out_channels, momentum=0.1)\n",
        "        self.conv2 = nn.Conv3d(out_channels, out_channels, 3, 1, 1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm3d(out_channels, momentum=0.1)\n",
        "        \n",
        "        self.attention = SpatioTemporalAttention(out_channels)\n",
        "        \n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv3d(in_channels, out_channels, 1, stride, bias=False),\n",
        "                nn.BatchNorm3d(out_channels, momentum=0.1)\n",
        "            )\n",
        "        \n",
        "        self.dropout = nn.Dropout3d(0.1)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "        \n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.dropout(out)\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out = self.attention(out)\n",
        "        \n",
        "        out += self.shortcut(identity)\n",
        "        return F.relu(out)\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 🚀 Step 3: Phase 2 学習実行（64フレーム対応）\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Phase 2 メインモデル（64フレーム対応）\n",
        "class Conv3DAutoencoderPhase2Last64(nn.Module):\n",
        "    def __init__(self, input_channels=1, fixed_frames=64, target_size=(64, 64), latent_dim=256):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.latent_dim = latent_dim\n",
        "        self.fixed_frames = fixed_frames\n",
        "        self.target_size = target_size\n",
        "        \n",
        "        # 初期畳み込み（64フレーム対応）\n",
        "        self.initial_conv = nn.Sequential(\n",
        "            nn.Conv3d(input_channels, 32, (5, 7, 7), (2, 2, 2), (2, 3, 3)),\n",
        "            nn.BatchNorm3d(32, momentum=0.1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout3d(0.05)\n",
        "        )\n",
        "        \n",
        "        # 残差注意ブロック群（64フレーム用に調整）\n",
        "        self.res_block1 = ResidualAttentionBlock3D(32, 64, stride=(2, 2, 2))\n",
        "        self.res_block2 = ResidualAttentionBlock3D(64, 64)\n",
        "        self.res_block3 = ResidualAttentionBlock3D(64, 128, stride=(2, 2, 2))\n",
        "        self.res_block4 = ResidualAttentionBlock3D(128, 128)\n",
        "        self.res_block5 = ResidualAttentionBlock3D(128, 256, stride=(2, 2, 2))\n",
        "        self.res_block6 = ResidualAttentionBlock3D(256, 256)\n",
        "        \n",
        "        # グローバルプーリング\n",
        "        self.global_pool = nn.AdaptiveAvgPool3d((2, 2, 2))\n",
        "        self.dropout_before_latent = nn.Dropout3d(0.3)\n",
        "        \n",
        "        # 潜在空間射影\n",
        "        self.to_latent = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(256 * 2 * 2 * 2, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Linear(512, latent_dim),\n",
        "            nn.BatchNorm1d(latent_dim)\n",
        "        )\n",
        "        \n",
        "        # 復元\n",
        "        self.from_latent = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Linear(512, 256 * 2 * 2 * 2),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        \n",
        "        # デコーダー（64フレーム復元用）\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose3d(256, 128, (4, 4, 4), (2, 2, 2), (1, 1, 1)),\n",
        "            nn.BatchNorm3d(128, momentum=0.1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout3d(0.2),\n",
        "            \n",
        "            nn.ConvTranspose3d(128, 64, (4, 4, 4), (2, 2, 2), (1, 1, 1)),\n",
        "            nn.BatchNorm3d(64, momentum=0.1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout3d(0.15),\n",
        "            \n",
        "            nn.ConvTranspose3d(64, 32, (4, 4, 4), (2, 2, 2), (1, 1, 1)),\n",
        "            nn.BatchNorm3d(32, momentum=0.1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout3d(0.1),\n",
        "            \n",
        "            nn.ConvTranspose3d(32, input_channels, (6, 7, 7), (2, 2, 2), (2, 3, 3)),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "    \n",
        "    def encode(self, x):\n",
        "        x = self.initial_conv(x)\n",
        "        x = self.res_block1(x)\n",
        "        x = self.res_block2(x)\n",
        "        x = self.res_block3(x)\n",
        "        x = self.res_block4(x)\n",
        "        x = self.res_block5(x)\n",
        "        x = self.res_block6(x)\n",
        "        x = self.global_pool(x)\n",
        "        x = self.dropout_before_latent(x)\n",
        "        return self.to_latent(x)\n",
        "    \n",
        "    def decode(self, latent):\n",
        "        x = self.from_latent(latent)\n",
        "        x = x.view(-1, 256, 2, 2, 2)\n",
        "        x = self.decoder(x)\n",
        "        target_h, target_w = self.target_size\n",
        "        return F.interpolate(x, size=(self.fixed_frames, target_h, target_w), \n",
        "                           mode='trilinear', align_corners=False)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        latent = self.encode(x)\n",
        "        reconstructed = self.decode(latent)\n",
        "        return reconstructed, latent\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Phase 2 学習・評価実行（64フレーム版）\n",
        "def run_phase2_training_last64():\n",
        "    # パラメータ設定\n",
        "    fixed_frames = 64  # 後半64フレーム\n",
        "    target_size = (64, 64)\n",
        "    latent_dim = 256\n",
        "    num_epochs = 50\n",
        "    batch_size = 6 if torch.cuda.is_available() else 3  # 64フレームなので少し小さく\n",
        "    learning_rate = 1e-3\n",
        "    weight_decay = 1e-4\n",
        "    n_clusters = 5\n",
        "    \n",
        "    print(\"🔄 Creating dataset (last 64 frames)...\")\n",
        "    dataset = GrayScottDatasetLast64(GIF_FOLDER_PATH, fixed_frames, target_size)\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, \n",
        "                          num_workers=2, pin_memory=True)\n",
        "    \n",
        "    print(f\"📊 Dataset: {len(dataset)} samples, Batch size: {batch_size}, Frames: {fixed_frames}\")\n",
        "    \n",
        "    print(\"🧠 Creating Phase 2 model (64 frames)...\")\n",
        "    model = Conv3DAutoencoderPhase2Last64(latent_dim=latent_dim, \n",
        "                                         fixed_frames=fixed_frames, \n",
        "                                         target_size=target_size).to(device)\n",
        "    \n",
        "    print(f\"📊 Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "    \n",
        "    # 訓練\n",
        "    print(\"🎯 Starting training with last 64 frames...\")\n",
        "    model.train()\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=1e-6)\n",
        "    \n",
        "    losses = []\n",
        "    start_time = time.time()\n",
        "    \n",
        "    print(f\"🚀 Phase 2 GPU Training: ResNet + Attention (Last 64 Frames)\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        epoch_start_time = time.time()\n",
        "        epoch_loss = 0.0\n",
        "        \n",
        "        for batch_idx, batch in enumerate(dataloader):\n",
        "            tensors = batch['tensor'].to(device, non_blocking=True)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            reconstructed, latent = model(tensors)\n",
        "            loss = criterion(reconstructed, tensors)\n",
        "            loss.backward()\n",
        "            \n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5)\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "        scheduler.step()\n",
        "        \n",
        "        avg_loss = epoch_loss / len(dataloader)\n",
        "        losses.append(avg_loss)\n",
        "        current_lr = scheduler.get_last_lr()[0]\n",
        "        epoch_time = time.time() - epoch_start_time\n",
        "        \n",
        "        # 進捗表示\n",
        "        progress = ((epoch + 1) / num_epochs) * 100\n",
        "        if (epoch + 1) % 5 == 0 or epoch < 5:\n",
        "            print(f'Epoch [{epoch+1:2d}/{num_epochs}] '\n",
        "                  f'({progress:5.1f}%) | '\n",
        "                  f'Loss: {avg_loss:.6f} | '\n",
        "                  f'LR: {current_lr:.2e} | '\n",
        "                  f'Time: {epoch_time:.1f}s')\n",
        "    \n",
        "    total_time = time.time() - start_time\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"🎉 Training completed in {total_time/60:.1f} minutes\")\n",
        "    \n",
        "    # 学習曲線表示\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(losses, linewidth=2, color='purple')\n",
        "    plt.title('Phase 2: GPU Training Loss (ResNet + Attention, Last 64 Frames)', fontsize=14)\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.show()\n",
        "    \n",
        "    # 潜在ベクトル抽出\n",
        "    print(\"🔍 Extracting latent vectors...\")\n",
        "    model.eval()\n",
        "    latent_vectors = []\n",
        "    f_values = []\n",
        "    k_values = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            tensors = batch['tensor'].to(device)\n",
        "            _, latent = model(tensors)\n",
        "            latent_vectors.append(latent.cpu().numpy())\n",
        "            f_values.extend(batch['f_value'].numpy())\n",
        "            k_values.extend(batch['k_value'].numpy())\n",
        "    \n",
        "    latent_vectors = np.vstack(latent_vectors)\n",
        "    f_values = np.array(f_values)\n",
        "    k_values = np.array(k_values)\n",
        "    \n",
        "    # クラスタリング\n",
        "    print(\"🎯 Performing clustering...\")\n",
        "    scaler = StandardScaler()\n",
        "    latent_scaled = scaler.fit_transform(latent_vectors)\n",
        "    \n",
        "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
        "    cluster_labels = kmeans.fit_predict(latent_scaled)\n",
        "    \n",
        "    # 性能評価\n",
        "    silhouette_avg = silhouette_score(latent_vectors, cluster_labels)\n",
        "    calinski_score = calinski_harabasz_score(latent_vectors, cluster_labels)\n",
        "    davies_bouldin = davies_bouldin_score(latent_vectors, cluster_labels)\n",
        "    \n",
        "    print(\"=\" * 80)\n",
        "    print(\"🏆 Phase 2 GPU Results Summary (Last 64 Frames):\")\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"🎯 Architecture: ResNet + SpatioTemporalAttention (GPU, Last 64 Frames)\")\n",
        "    print(f\"📊 Samples: {len(dataset)}\")\n",
        "    print(f\"🎬 Frames per sample: {fixed_frames} (last frames)\")\n",
        "    print(f\"🧠 Latent Dimension: {latent_dim}\")\n",
        "    print(f\"⚙️  Model Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "    print(f\"📉 Final Loss: {losses[-1]:.6f}\")\n",
        "    print(f\"🎯 Clusters: {n_clusters}\")\n",
        "    print(f\"⭐ Silhouette Score: {silhouette_avg:.4f}\")\n",
        "    print(f\"📊 Calinski-Harabasz: {calinski_score:.2f}\")\n",
        "    print(f\"📈 Davies-Bouldin: {davies_bouldin:.4f}\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    # Phase 1との比較\n",
        "    phase1_score = 0.565\n",
        "    improvement = ((silhouette_avg - phase1_score) / phase1_score) * 100\n",
        "    \n",
        "    print(f\"📈 Performance Comparison:\")\n",
        "    print(f\"   Phase 1 (30 frames): {phase1_score:.4f}\")\n",
        "    print(f\"   Phase 2 (last 64 frames): {silhouette_avg:.4f}\")\n",
        "    print(f\"   Improvement: {improvement:+.1f}%\")\n",
        "    \n",
        "    if improvement >= 15:\n",
        "        print(\"🎉 Phase 2 目標達成！ (15%以上の向上) - Last 64 frames strategy successful!\")\n",
        "    else:\n",
        "        print(f\"⚠️  Phase 2 目標未達 ({improvement:.1f}% < 15%) - Consider further optimization\")\n",
        "    \n",
        "    return {\n",
        "        'model': model,\n",
        "        'losses': losses,\n",
        "        'silhouette_score': silhouette_avg,\n",
        "        'calinski_score': calinski_score,\n",
        "        'davies_bouldin': davies_bouldin,\n",
        "        'latent_vectors': latent_vectors,\n",
        "        'cluster_labels': cluster_labels,\n",
        "        'f_values': f_values,\n",
        "        'k_values': k_values,\n",
        "        'improvement': improvement,\n",
        "        'frames_used': 'last_64'\n",
        "    }\n",
        "\n",
        "# 実行\n",
        "print(\"🚀 Starting Phase 2 training with last 64 frames...\")\n",
        "results = run_phase2_training_last64()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 📥 Step 4: 結果保存・ダウンロード\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 結果保存とダウンロード（Last 64 frames版）\n",
        "import pickle\n",
        "from google.colab import files\n",
        "\n",
        "# 結果をGoogle Driveに保存\n",
        "results_path = '/content/drive/MyDrive/GrayScottML/phase2_results_last64_gpu.pkl'\n",
        "model_path = '/content/drive/MyDrive/GrayScottML/phase2_model_last64_gpu.pth'\n",
        "\n",
        "# 結果保存\n",
        "with open(results_path, 'wb') as f:\n",
        "    # モデルは除いて保存（サイズ削減）\n",
        "    save_results = {k: v for k, v in results.items() if k != 'model'}\n",
        "    pickle.dump(save_results, f)\n",
        "\n",
        "# モデル保存\n",
        "torch.save(results['model'].state_dict(), model_path)\n",
        "\n",
        "print(f\"💾 Results saved to Google Drive:\")\n",
        "print(f\"   📊 Results: {results_path}\")\n",
        "print(f\"   🧠 Model: {model_path}\")\n",
        "\n",
        "# ローカルにもダウンロード用ファイル作成\n",
        "local_results_path = 'phase2_results_last64_gpu.pkl'\n",
        "local_model_path = 'phase2_model_last64_gpu.pth'\n",
        "\n",
        "with open(local_results_path, 'wb') as f:\n",
        "    save_results = {k: v for k, v in results.items() if k != 'model'}\n",
        "    pickle.dump(save_results, f)\n",
        "\n",
        "torch.save(results['model'].state_dict(), local_model_path)\n",
        "\n",
        "print(\"\\n📥 Downloading files...\")\n",
        "files.download(local_results_path)\n",
        "files.download(local_model_path)\n",
        "\n",
        "print(\"✅ Download completed!\")\n",
        "print(f\"🎯 Final Results (Last 64 Frames):\")\n",
        "print(f\"   ⭐ Silhouette Score: {results['silhouette_score']:.4f}\")\n",
        "print(f\"   📈 Improvement: {results['improvement']:+.1f}%\")\n",
        "print(f\"   🎬 Strategy: Using last 64 frames for more stable patterns\")\n",
        "print(f\"   🏆 Target: {'✅ ACHIEVED' if results['improvement'] >= 15 else '❌ NOT ACHIEVED'}\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 📊 Step 5: 可視化・分析（Optional）\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 結果の詳細可視化（Last 64 frames）\n",
        "def visualize_results_last64(results):\n",
        "    latent_vectors = results['latent_vectors']\n",
        "    cluster_labels = results['cluster_labels']\n",
        "    f_values = results['f_values']\n",
        "    k_values = results['k_values']\n",
        "    \n",
        "    # PCAとt-SNEによる次元削減\n",
        "    print(\"🔍 Performing dimensionality reduction...\")\n",
        "    pca = PCA(n_components=2, random_state=42)\n",
        "    pca_result = pca.fit_transform(latent_vectors)\n",
        "    \n",
        "    tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
        "    tsne_result = tsne.fit_transform(latent_vectors)\n",
        "    \n",
        "    # 可視化\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "    fig.suptitle('Phase 2 Results: Last 64 Frames Analysis', fontsize=16, fontweight='bold')\n",
        "    \n",
        "    # f-k空間でのクラスタリング結果\n",
        "    scatter1 = axes[0, 0].scatter(f_values, k_values, c=cluster_labels, cmap='tab10', alpha=0.7, s=20)\n",
        "    axes[0, 0].set_xlabel('f parameter')\n",
        "    axes[0, 0].set_ylabel('k parameter')\n",
        "    axes[0, 0].set_title('Clustering Results in f-k Parameter Space')\n",
        "    axes[0, 0].invert_yaxis()\n",
        "    plt.colorbar(scatter1, ax=axes[0, 0], label='Cluster ID')\n",
        "    \n",
        "    # PCA結果\n",
        "    scatter2 = axes[0, 1].scatter(pca_result[:, 0], pca_result[:, 1], c=cluster_labels, cmap='tab10', alpha=0.7, s=20)\n",
        "    axes[0, 1].set_title(f'PCA of Latent Space (Last 64 Frames)')\n",
        "    axes[0, 1].set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} variance)')\n",
        "    axes[0, 1].set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} variance)')\n",
        "    plt.colorbar(scatter2, ax=axes[0, 1], label='Cluster ID')\n",
        "    \n",
        "    # t-SNE結果\n",
        "    scatter3 = axes[1, 0].scatter(tsne_result[:, 0], tsne_result[:, 1], c=cluster_labels, cmap='tab10', alpha=0.7, s=20)\n",
        "    axes[1, 0].set_title('t-SNE of Latent Space (Last 64 Frames)')\n",
        "    plt.colorbar(scatter3, ax=axes[1, 0], label='Cluster ID')\n",
        "    \n",
        "    # クラスター統計\n",
        "    axes[1, 1].axis('off')\n",
        "    n_clusters = len(np.unique(cluster_labels))\n",
        "    stats_text = f\"Last 64 Frames Analysis:\\\\n\\\\n\"\n",
        "    stats_text += f\"Silhouette Score: {results['silhouette_score']:.4f}\\\\n\"\n",
        "    stats_text += f\"Improvement: {results['improvement']:+.1f}%\\\\n\\\\n\"\n",
        "    \n",
        "    for i in range(n_clusters):\n",
        "        mask = cluster_labels == i\n",
        "        count = np.sum(mask)\n",
        "        f_mean = f_values[mask].mean()\n",
        "        k_mean = k_values[mask].mean()\n",
        "        stats_text += f\"Cluster {i}: {count} samples\\\\n\"\n",
        "        stats_text += f\"  f_avg: {f_mean:.4f}\\\\n\"\n",
        "        stats_text += f\"  k_avg: {k_mean:.4f}\\\\n\\\\n\"\n",
        "    \n",
        "    axes[1, 1].text(0.1, 0.9, stats_text, transform=axes[1, 1].transAxes, \n",
        "                    fontsize=10, verticalalignment='top', fontfamily='monospace')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"📊 Visualization completed!\")\n",
        "    print(f\"🎬 Strategy: Last 64 frames captured more stable, mature patterns\")\n",
        "    print(f\"⭐ Final Score: {results['silhouette_score']:.4f}\")\n",
        "\n",
        "# 可視化実行\n",
        "print(\"🎨 Creating visualizations...\")\n",
        "visualize_results_last64(results)\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Google Driveフォルダ確認・作成支援\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Google Driveをマウント\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# フォルダパス設定（マイドライブ内）\n",
        "base_path = '/content/drive/MyDrive'\n",
        "project_folder = os.path.join(base_path, 'GrayScottML')\n",
        "gif_folder = os.path.join(project_folder, 'gif')\n",
        "\n",
        "# 段階的にフォルダ作成\n",
        "try:\n",
        "    if not os.path.exists(project_folder):\n",
        "        os.makedirs(project_folder)\n",
        "        print(f\"✅ Created: {project_folder}\")\n",
        "    else:\n",
        "        print(f\"✅ Already exists: {project_folder}\")\n",
        "        \n",
        "    if not os.path.exists(gif_folder):\n",
        "        os.makedirs(gif_folder)\n",
        "        print(f\"✅ Created: {gif_folder}\")\n",
        "    else:\n",
        "        print(f\"✅ Already exists: {gif_folder}\")\n",
        "        \n",
        "    # テストファイル作成（フォルダが確実に存在することを確認）\n",
        "    test_file = os.path.join(project_folder, 'test.txt')\n",
        "    with open(test_file, 'w') as f:\n",
        "        f.write('GrayScott ML Project - Folder created successfully!')\n",
        "    \n",
        "    print(\"🎉 Folder structure created successfully!\")\n",
        "    print(\"📁 Structure:\")\n",
        "    print(f\"   {project_folder}\")\n",
        "    print(f\"   └── {gif_folder}\")\n",
        "    print(f\"   └── test.txt\")\n",
        "    \n",
        "    # Google Drive側で確認するよう案内\n",
        "    print(\"\\n💡 Please check your Google Drive:\")\n",
        "    print(\"   MyDrive > GrayScottML > gif (folder)\")\n",
        "    print(\"   MyDrive > GrayScottML > test.txt (file)\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"❌ Error creating folders: {e}\")\n",
        "    print(\"Please try creating folders manually in Google Drive web interface\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# パス確認とデバッグ\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Google Driveをマウント\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 複数のパス候補を確認\n",
        "path_candidates = [\n",
        "    '/content/drive/MyDrive/GrayScottML/gif',           # マイドライブ内\n",
        "    '/content/drive/MyDrive/GrayScottML',               # プロジェクトフォルダ\n",
        "    '/content/drive/GrayScottML/gif',                   # ルート直下（もしあれば）\n",
        "]\n",
        "\n",
        "print(\"🔍 Searching for GrayScottML folder...\")\n",
        "found_path = None\n",
        "\n",
        "for path in path_candidates:\n",
        "    if os.path.exists(path):\n",
        "        print(f\"✅ Found: {path}\")\n",
        "        if path.endswith('/gif'):\n",
        "            gif_count = len([f for f in os.listdir(path) if f.endswith('.gif')])\n",
        "            print(f\"   📁 GIF files: {gif_count}\")\n",
        "            if gif_count > 0:\n",
        "                found_path = path\n",
        "                break\n",
        "        else:\n",
        "            contents = os.listdir(path)\n",
        "            print(f\"   📁 Contents: {contents}\")\n",
        "            if 'gif' in contents:\n",
        "                gif_path = os.path.join(path, 'gif')\n",
        "                gif_count = len([f for f in os.listdir(gif_path) if f.endswith('.gif')])\n",
        "                print(f\"   📁 GIF files in gif/: {gif_count}\")\n",
        "                if gif_count > 0:\n",
        "                    found_path = gif_path\n",
        "                    break\n",
        "    else:\n",
        "        print(f\"❌ Not found: {path}\")\n",
        "\n",
        "# マイドライブの内容を表示\n",
        "mydrive_path = '/content/drive/MyDrive'\n",
        "if os.path.exists(mydrive_path):\n",
        "    print(f\"\\n📂 Contents of MyDrive:\")\n",
        "    for item in sorted(os.listdir(mydrive_path)):\n",
        "        item_path = os.path.join(mydrive_path, item)\n",
        "        if os.path.isdir(item_path):\n",
        "            print(f\"   📁 {item}\")\n",
        "        else:\n",
        "            print(f\"   📄 {item}\")\n",
        "\n",
        "if found_path:\n",
        "    print(f\"\\n🎉 Ready to use: {found_path}\")\n",
        "    # グローバル変数として設定\n",
        "    GIF_FOLDER_PATH = found_path\n",
        "    print(f\"🔗 GIF_FOLDER_PATH = '{GIF_FOLDER_PATH}'\")\n",
        "else:\n",
        "    print(f\"\\n⚠️ GrayScottML folder not found. Please:\")\n",
        "    print(\"1. Create 'GrayScottML' folder in MyDrive\")\n",
        "    print(\"2. Create 'gif' subfolder inside GrayScottML\")\n",
        "    print(\"3. Upload 1500 GIF files to the gif folder\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
