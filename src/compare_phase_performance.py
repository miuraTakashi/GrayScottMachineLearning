#!/usr/bin/env python3
"""
Phase 1 vs ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ€§èƒ½æ¯”è¼ƒåˆ†æã‚¹ã‚¯ãƒªãƒ—ãƒˆ
Gray-Scott 3D CNN Autoencoder ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ
"""

import os
import pickle
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score

def load_results(filepath):
    """çµæœãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
    try:
        with open(filepath, 'rb') as f:
            return pickle.load(f)
    except FileNotFoundError:
        print(f"File not found: {filepath}")
        return None

def calculate_clustering_metrics(latent_vectors, cluster_labels):
    """ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°è©•ä¾¡æŒ‡æ¨™ã‚’è¨ˆç®—"""
    metrics = {
        'silhouette_score': silhouette_score(latent_vectors, cluster_labels),
        'calinski_harabasz_score': calinski_harabasz_score(latent_vectors, cluster_labels),
        'davies_bouldin_score': davies_bouldin_score(latent_vectors, cluster_labels)
    }
    return metrics

def compare_performance():
    """Phase 1 vs ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ€§èƒ½æ¯”è¼ƒ"""
    
    print("=" * 60)
    print("Phase 1 vs ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ€§èƒ½æ¯”è¼ƒåˆ†æ")
    print("=" * 60)
    
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã¯æ—¢çŸ¥ã®å€¤ã‚’ä½¿ç”¨ï¼ˆãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå±¥æ­´ã‚ˆã‚Šï¼‰
    phase1_path = '../results/analysis_results_phase1.pkl'      # Phase 1
    
    baseline_data = None  # æ—¢çŸ¥ã®å€¤ã‚’ä½¿ç”¨
    phase1_data = load_results(phase1_path)
    
    if phase1_data is None:
        print("âŒ Phase 1ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        print(f"ç¢ºèªã—ã¦ãã ã•ã„: {phase1_path}")
        return
    
    # åŸºæœ¬æƒ…å ±æ¯”è¼ƒ
    print("\nğŸ“Š åŸºæœ¬ä»•æ§˜æ¯”è¼ƒ:")
    print("-" * 40)
    
    baseline_latent_dim = 64  # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå±¥æ­´ã‹ã‚‰ã®æ—¢çŸ¥ã®å€¤
    phase1_latent_dim = phase1_data.get('hyperparameters', {}).get('latent_dim', phase1_data.get('latent_vectors', np.array([])).shape[1] if phase1_data.get('latent_vectors') is not None else "ä¸æ˜")
    
    print(f"æ½œåœ¨æ¬¡å…ƒ:")
    print(f"  ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³: {baseline_latent_dim}")
    print(f"  Phase 1:     {phase1_latent_dim}")
    print(f"  æ”¹å–„å€ç‡:     {phase1_latent_dim/baseline_latent_dim:.1f}x" if isinstance(phase1_latent_dim, int) else "  æ”¹å–„å€ç‡:     è¨ˆç®—ä¸å¯")
    
    # ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°æ€§èƒ½æ¯”è¼ƒ
    print("\nğŸ¯ ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°æ€§èƒ½æ¯”è¼ƒ:")
    print("-" * 40)
    
    # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã¯ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå±¥æ­´ã®æ—¢çŸ¥ã®å€¤ã‚’ä½¿ç”¨
    baseline_metrics = {
        'silhouette_score': 0.413,      # k=4ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã§ã®æœ€é«˜å€¤
        'calinski_harabasz_score': 1097.8,  # k=2ã§ã®å€¤
        'davies_bouldin_score': 0.918    # k=53ã§ã®å€¤
    }
    
    if phase1_data.get('latent_vectors') is not None and phase1_data.get('cluster_labels') is not None:
        phase1_metrics = calculate_clustering_metrics(
            phase1_data['latent_vectors'], 
            phase1_data['cluster_labels']
        )
    else:
        print("âŒ Phase 1ã®ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return
    
    # æ€§èƒ½æ”¹å–„ç‡è¨ˆç®—
    improvement_silhouette = ((phase1_metrics['silhouette_score'] - baseline_metrics['silhouette_score']) / baseline_metrics['silhouette_score']) * 100
    improvement_ch = ((phase1_metrics['calinski_harabasz_score'] - baseline_metrics['calinski_harabasz_score']) / baseline_metrics['calinski_harabasz_score']) * 100
    improvement_db = ((baseline_metrics['davies_bouldin_score'] - phase1_metrics['davies_bouldin_score']) / baseline_metrics['davies_bouldin_score']) * 100  # ä½ã„æ–¹ãŒè‰¯ã„ã®ã§é€†è¨ˆç®—
    
    print(f"Silhouette Score:")
    print(f"  ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³: {baseline_metrics['silhouette_score']:.4f}")
    print(f"  Phase 1:     {phase1_metrics['silhouette_score']:.4f}")
    print(f"  æ”¹å–„ç‡:       {improvement_silhouette:+.1f}%")
    
    print(f"\nCalinski-Harabasz Score:")
    print(f"  ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³: {baseline_metrics['calinski_harabasz_score']:.1f}")
    print(f"  Phase 1:     {phase1_metrics['calinski_harabasz_score']:.1f}")
    print(f"  æ”¹å–„ç‡:       {improvement_ch:+.1f}%")
    
    print(f"\nDavies-Bouldin Score (ä½ã„æ–¹ãŒè‰¯ã„):")
    print(f"  ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³: {baseline_metrics['davies_bouldin_score']:.4f}")
    print(f"  Phase 1:     {phase1_metrics['davies_bouldin_score']:.4f}")
    print(f"  æ”¹å–„ç‡:       {improvement_db:+.1f}%")
    
    # å­¦ç¿’åŠ¹ç‡æ¯”è¼ƒ
    print("\nâš¡ å­¦ç¿’åŠ¹ç‡æ¯”è¼ƒ:")
    print("-" * 40)
    
    baseline_losses = []  # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿ãªã—
    phase1_losses = phase1_data.get('losses', [])
    
    if phase1_losses:
        print(f"Phase 1 å­¦ç¿’çµæœ:")
        print(f"  è¨“ç·´ã‚¨ãƒãƒƒã‚¯æ•°: {len(phase1_losses)}")
        print(f"  åˆæœŸæå¤±:     {phase1_losses[0]:.6f}")
        print(f"  æœ€çµ‚æå¤±:     {phase1_losses[-1]:.6f}")
        
        # æå¤±æ”¹å–„ç‡
        loss_improvement = ((phase1_losses[0] - phase1_losses[-1]) / phase1_losses[0]) * 100
        print(f"  æå¤±æ”¹å–„ç‡:   {loss_improvement:.1f}%")
        
        # ç°¡æ˜“çš„ãªåæŸåˆ¤å®šï¼ˆæå¤±ã®å¤‰åŒ–ãŒ1%ä»¥ä¸‹ã«ãªã£ãŸç‚¹ï¼‰
        def find_convergence_epoch(losses, threshold=0.01):
            if len(losses) < 10:
                return len(losses)
            for i in range(10, len(losses)):
                recent_change = abs(losses[i] - losses[i-10]) / losses[i-10]
                if recent_change < threshold:
                    return i
            return len(losses)
        
        phase1_convergence = find_convergence_epoch(phase1_losses)
        print(f"  åæŸã‚¨ãƒãƒƒã‚¯: {phase1_convergence}/{len(phase1_losses)}")
    
    # ç·åˆè©•ä¾¡
    print("\nğŸ† ç·åˆè©•ä¾¡:")
    print("-" * 40)
    
    target_improvement = 25  # Phase 1ç›®æ¨™: 25-35%å‘ä¸Š
    actual_improvement = improvement_silhouette  # ã‚·ãƒ«ã‚¨ãƒƒãƒˆã‚¹ã‚³ã‚¢ã‚’ä¸»æŒ‡æ¨™ã¨ã™ã‚‹
    
    if actual_improvement >= target_improvement:
        print(f"âœ… Phase 1ç›®æ¨™é”æˆï¼ ({actual_improvement:.1f}% > {target_improvement}%)")
        success_level = "å¤§æˆåŠŸ"
    elif actual_improvement >= target_improvement * 0.7:
        print(f"âš¡ Phase 1éƒ¨åˆ†çš„æˆåŠŸ ({actual_improvement:.1f}% â‰ˆ {target_improvement}%)")
        success_level = "éƒ¨åˆ†æˆåŠŸ"
    else:
        print(f"âš ï¸  Phase 1ç›®æ¨™æœªé” ({actual_improvement:.1f}% < {target_improvement}%)")
        success_level = "è¦æ”¹å–„"
    
    # Phase 1æ”¹å–„ç‚¹ã®åŠ¹æœåˆ†æ
    print(f"\nğŸ”¬ Phase 1æ”¹å–„ç‚¹ã®åŠ¹æœ:")
    print("-" * 40)
    print("âœ“ æ½œåœ¨æ¬¡å…ƒæ‹¡å¼µ (64â†’256): è¡¨ç¾åŠ›4å€å‘ä¸Š")
    print("âœ“ å¼·åŒ–BatchNorm: å­¦ç¿’å®‰å®šåŒ–")
    print("âœ“ Dropoutæ­£å‰‡åŒ–: éå­¦ç¿’é˜²æ­¢")
    print("âœ“ AdamWæœ€é©åŒ–: é‡ã¿æ¸›è¡°ã§æ±åŒ–æ€§èƒ½å‘ä¸Š")
    print("âœ“ CosineAnnealing: å­¦ç¿’ç‡é©å¿œèª¿æ•´")
    
    # å¯è¦–åŒ–
    create_comparison_plots(baseline_data, phase1_data, baseline_metrics, phase1_metrics)
    
    # çµæœä¿å­˜
    comparison_results = {
        'baseline_metrics': baseline_metrics,
        'phase1_metrics': phase1_metrics,
        'improvements': {
            'silhouette': improvement_silhouette,
            'calinski_harabasz': improvement_ch,
            'davies_bouldin': improvement_db
        },
        'success_level': success_level,
        'target_achievement': actual_improvement >= target_improvement
    }
    
    with open('../results/phase1_comparison_results.pkl', 'wb') as f:
        pickle.dump(comparison_results, f)
    
    print(f"\nğŸ’¾ æ¯”è¼ƒçµæœã‚’ä¿å­˜: results/phase1_comparison_results.pkl")
    print("=" * 60)

def create_comparison_plots(baseline_data, phase1_data, baseline_metrics, phase1_metrics):
    """æ¯”è¼ƒå¯è¦–åŒ–ã®ä½œæˆ"""
    
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    fig.suptitle('Phase 1 vs ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ€§èƒ½æ¯”è¼ƒ', fontsize=16, fontweight='bold')
    
    # 1. ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°æŒ‡æ¨™æ¯”è¼ƒ
    metrics_names = ['Silhouette', 'Calinski-Harabasz', 'Davies-Bouldin']
    baseline_values = [baseline_metrics['silhouette_score'], 
                      baseline_metrics['calinski_harabasz_score']/1000,  # ã‚¹ã‚±ãƒ¼ãƒ«èª¿æ•´
                      baseline_metrics['davies_bouldin_score']]
    phase1_values = [phase1_metrics['silhouette_score'], 
                    phase1_metrics['calinski_harabasz_score']/1000,  # ã‚¹ã‚±ãƒ¼ãƒ«èª¿æ•´
                    phase1_metrics['davies_bouldin_score']]
    
    x = np.arange(len(metrics_names))
    width = 0.35
    
    axes[0, 0].bar(x - width/2, baseline_values, width, label='ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³', alpha=0.8)
    axes[0, 0].bar(x + width/2, phase1_values, width, label='Phase 1', alpha=0.8)
    axes[0, 0].set_xlabel('è©•ä¾¡æŒ‡æ¨™')
    axes[0, 0].set_ylabel('ã‚¹ã‚³ã‚¢')
    axes[0, 0].set_title('ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°æ€§èƒ½æ¯”è¼ƒ')
    axes[0, 0].set_xticks(x)
    axes[0, 0].set_xticklabels(metrics_names)
    axes[0, 0].legend()
    axes[0, 0].grid(True, alpha=0.3)
    
    # 2. Phase 1å­¦ç¿’æ›²ç·š
    if phase1_data.get('losses'):
        axes[0, 1].plot(phase1_data['losses'], label='Phase 1', linewidth=2, color='orange')
        axes[0, 1].set_xlabel('ã‚¨ãƒãƒƒã‚¯')
        axes[0, 1].set_ylabel('æå¤±')
        axes[0, 1].set_title('Phase 1 å­¦ç¿’æ›²ç·š')
        axes[0, 1].legend()
        axes[0, 1].grid(True, alpha=0.3)
    else:
        axes[0, 1].text(0.5, 0.5, 'Phase 1å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãªã—', ha='center', va='center', transform=axes[0, 1].transAxes)
    
    # 3. æ”¹å–„ç‡ã‚°ãƒ©ãƒ•
    improvements = [
        ((phase1_metrics['silhouette_score'] - baseline_metrics['silhouette_score']) / baseline_metrics['silhouette_score']) * 100,
        ((phase1_metrics['calinski_harabasz_score'] - baseline_metrics['calinski_harabasz_score']) / baseline_metrics['calinski_harabasz_score']) * 100,
        ((baseline_metrics['davies_bouldin_score'] - phase1_metrics['davies_bouldin_score']) / baseline_metrics['davies_bouldin_score']) * 100
    ]
    
    colors = ['green' if x > 0 else 'red' for x in improvements]
    axes[1, 0].bar(metrics_names, improvements, color=colors, alpha=0.7)
    axes[1, 0].axhline(y=25, color='orange', linestyle='--', label='ç›®æ¨™: 25%')
    axes[1, 0].set_xlabel('è©•ä¾¡æŒ‡æ¨™')
    axes[1, 0].set_ylabel('æ”¹å–„ç‡ (%)')
    axes[1, 0].set_title('Phase 1æ”¹å–„åŠ¹æœ')
    axes[1, 0].legend()
    axes[1, 0].grid(True, alpha=0.3)
    
    # 4. æ½œåœ¨ç©ºé–“æ¬¡å…ƒæ¯”è¼ƒ
    baseline_dim = 64
    phase1_dim = phase1_data.get('latent_vectors', np.array([])).shape[1] if phase1_data.get('latent_vectors') is not None else 256
    
    axes[1, 1].bar(['ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³', 'Phase 1'], [baseline_dim, phase1_dim], 
                  color=['skyblue', 'orange'], alpha=0.8)
    axes[1, 1].set_ylabel('æ½œåœ¨æ¬¡å…ƒæ•°')
    axes[1, 1].set_title('æ½œåœ¨è¡¨ç¾ã®æ¬¡å…ƒæ‹¡å¼µ')
    
    # æ”¹å–„å€ç‡ã‚’è¡¨ç¤º
    for i, v in enumerate([baseline_dim, phase1_dim]):
        axes[1, 1].text(i, v + max(baseline_dim, phase1_dim) * 0.01, 
                       f'{v}æ¬¡å…ƒ', ha='center', va='bottom', fontweight='bold')
    
    # æ”¹å–„å€ç‡ã‚’è¿½åŠ è¡¨ç¤º
    improvement_ratio = phase1_dim / baseline_dim
    axes[1, 1].text(0.5, max(baseline_dim, phase1_dim) * 0.5, 
                   f'{improvement_ratio:.1f}å€æ”¹å–„', ha='center', va='center', 
                   fontsize=12, fontweight='bold', color='red')
    
    plt.tight_layout()
    plt.savefig('../results/phase1_comparison_analysis.png', dpi=300, bbox_inches='tight')
    plt.show()

if __name__ == "__main__":
    compare_performance() 