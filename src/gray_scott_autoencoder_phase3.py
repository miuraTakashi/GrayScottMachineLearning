#!/usr/bin/env python3
"""
Gray-Scott 3D CNN Autoencoder Phase 3
ãƒãƒ«ãƒã‚¹ã‚±ãƒ¼ãƒ«ç‰¹å¾´èåˆã«ã‚ˆã‚‹é«˜åº¦ãªç‰¹å¾´å­¦ç¿’

Phase 2ã®æˆæœ: Silhouette Score 0.4671 (ResNet+Attention)
Phase 3ç›®æ¨™: 0.4671 â†’ 0.55+ (+15-20% è¿½åŠ å‘ä¸Š)

ä¸»è¦æ”¹å–„ç‚¹:
1. ãƒãƒ«ãƒã‚¹ã‚±ãƒ¼ãƒ«ç‰¹å¾´èåˆ (Multi-Scale Feature Fusion)
2. é«˜åº¦ãªãƒ‡ãƒ¼ã‚¿æ‹¡å¼µæˆ¦ç•¥ (Advanced Data Augmentation)
3. æ”¹å–„ã•ã‚ŒãŸè¨“ç·´ãƒ«ãƒ¼ãƒ— (Enhanced Training Loop)
"""

import os
import re
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib.patches import Patch
from PIL import Image
import imageio.v2 as imageio
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import torch.nn.functional as F
import time
import pickle
from typing import List, Tuple, Dict, Optional

# GPUè¨­å®š
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"ğŸš€ Phase 3 Using device: {device}")

# ================================
# 1. é«˜åº¦ãªãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã‚·ã‚¹ãƒ†ãƒ 
# ================================

class GrayScottAugmentation:
    """Gray-Scottå°‚ç”¨ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, 
                 temporal_shift_prob=0.3,
                 spatial_flip_prob=0.5,
                 noise_prob=0.2,
                 intensity_prob=0.3,
                 temporal_crop_prob=0.2):
        self.temporal_shift_prob = temporal_shift_prob
        self.spatial_flip_prob = spatial_flip_prob
        self.noise_prob = noise_prob
        self.intensity_prob = intensity_prob
        self.temporal_crop_prob = temporal_crop_prob
    
    def temporal_shift(self, tensor, max_shift=3):
        """æ™‚é–“è»¸ã‚·ãƒ•ãƒˆ"""
        if np.random.random() < self.temporal_shift_prob:
            shift = np.random.randint(-max_shift, max_shift + 1)
            if shift != 0:
                tensor = torch.roll(tensor, shift, dims=1)  # æ™‚é–“è»¸ã§ã‚·ãƒ•ãƒˆ
        return tensor
    
    def spatial_flip(self, tensor):
        """ç©ºé–“è»¸åè»¢"""
        if np.random.random() < self.spatial_flip_prob:
            # æ°´å¹³åè»¢
            if np.random.random() < 0.5:
                tensor = torch.flip(tensor, dims=[3])  # widthè»¸
            # å‚ç›´åè»¢
            if np.random.random() < 0.5:
                tensor = torch.flip(tensor, dims=[2])  # heightè»¸
        return tensor
    
    def add_noise(self, tensor, noise_std=0.02):
        """ã‚¬ã‚¦ã‚·ã‚¢ãƒ³ãƒã‚¤ã‚ºè¿½åŠ """
        if np.random.random() < self.noise_prob:
            noise = torch.randn_like(tensor) * noise_std
            tensor = torch.clamp(tensor + noise, 0, 1)
        return tensor
    
    def intensity_transform(self, tensor, gamma_range=(0.8, 1.2)):
        """å¼·åº¦å¤‰æ›ï¼ˆã‚¬ãƒ³ãƒè£œæ­£ï¼‰"""
        if np.random.random() < self.intensity_prob:
            gamma = np.random.uniform(*gamma_range)
            tensor = torch.pow(tensor, gamma)
        return tensor
    
    def temporal_crop(self, tensor, crop_ratio=0.1):
        """æ™‚é–“è»¸ã‚¯ãƒ­ãƒƒãƒ—"""
        if np.random.random() < self.temporal_crop_prob:
            T = tensor.shape[1]
            crop_size = int(T * crop_ratio)
            start_idx = np.random.randint(0, crop_size + 1)
            end_idx = T - np.random.randint(0, crop_size + 1)
            
            # ã‚¯ãƒ­ãƒƒãƒ—ã—ãŸéƒ¨åˆ†ã‚’è£œé–“ã§åŸ‹ã‚ã‚‹
            cropped = tensor[:, start_idx:end_idx]
            tensor = F.interpolate(cropped.unsqueeze(0), size=(T, tensor.shape[2], tensor.shape[3]), 
                                 mode='trilinear', align_corners=False).squeeze(0)
        return tensor
    
    def __call__(self, tensor):
        """å…¨ã¦ã®æ‹¡å¼µã‚’é©ç”¨"""
        tensor = self.temporal_shift(tensor)
        tensor = self.spatial_flip(tensor)
        tensor = self.add_noise(tensor)
        tensor = self.intensity_transform(tensor)
        tensor = self.temporal_crop(tensor)
        return tensor

# ================================
# 2. ãƒãƒ«ãƒã‚¹ã‚±ãƒ¼ãƒ«ç‰¹å¾´èåˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
# ================================

class MultiScaleFeatureFusion(nn.Module):
    """ãƒãƒ«ãƒã‚¹ã‚±ãƒ¼ãƒ«ç‰¹å¾´èåˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«"""
    
    def __init__(self, in_channels, out_channels):
        super(MultiScaleFeatureFusion, self).__init__()
        
        # ç•°ãªã‚‹ã‚«ãƒ¼ãƒãƒ«ã‚µã‚¤ã‚ºã§ã®ä¸¦åˆ—å‡¦ç†
        self.scale1 = nn.Sequential(
            nn.Conv3d(in_channels, out_channels//4, kernel_size=(1, 1, 1), padding=0),
            nn.BatchNorm3d(out_channels//4),
            nn.ReLU(inplace=True)
        )
        
        self.scale2 = nn.Sequential(
            nn.Conv3d(in_channels, out_channels//4, kernel_size=(3, 3, 3), padding=1),
            nn.BatchNorm3d(out_channels//4),
            nn.ReLU(inplace=True)
        )
        
        self.scale3 = nn.Sequential(
            nn.Conv3d(in_channels, out_channels//4, kernel_size=(5, 5, 5), padding=2),
            nn.BatchNorm3d(out_channels//4),
            nn.ReLU(inplace=True)
        )
        
        # ãƒ—ãƒ¼ãƒªãƒ³ã‚°åˆ†å²
        self.pool_branch = nn.Sequential(
            nn.AvgPool3d(kernel_size=3, stride=1, padding=1),
            nn.Conv3d(in_channels, out_channels//4, kernel_size=(1, 1, 1), padding=0),
            nn.BatchNorm3d(out_channels//4),
            nn.ReLU(inplace=True)
        )
        
        # ç‰¹å¾´èåˆ
        self.fusion = nn.Sequential(
            nn.Conv3d(out_channels, out_channels, kernel_size=(1, 1, 1)),
            nn.BatchNorm3d(out_channels),
            nn.ReLU(inplace=True)
        )
        
        # æ³¨æ„æ©Ÿæ§‹ã«ã‚ˆã‚‹é‡ã¿ä»˜ã‘
        self.attention = nn.Sequential(
            nn.AdaptiveAvgPool3d(1),
            nn.Conv3d(out_channels, out_channels//8, kernel_size=1),
            nn.ReLU(inplace=True),
            nn.Conv3d(out_channels//8, out_channels, kernel_size=1),
            nn.Sigmoid()
        )
    
    def forward(self, x):
        # å„ã‚¹ã‚±ãƒ¼ãƒ«ã§ã®ç‰¹å¾´æŠ½å‡º
        feat1 = self.scale1(x)  # 1x1x1 - ç‚¹ç‰¹å¾´
        feat2 = self.scale2(x)  # 3x3x3 - å±€æ‰€ç‰¹å¾´
        feat3 = self.scale3(x)  # 5x5x5 - åºƒåŸŸç‰¹å¾´
        feat4 = self.pool_branch(x)  # ãƒ—ãƒ¼ãƒªãƒ³ã‚°ç‰¹å¾´
        
        # ç‰¹å¾´ã‚’çµåˆ
        fused = torch.cat([feat1, feat2, feat3, feat4], dim=1)
        
        # èåˆå‡¦ç†
        fused = self.fusion(fused)
        
        # æ³¨æ„æ©Ÿæ§‹ã«ã‚ˆã‚‹é‡ã¿ä»˜ã‘
        attention_weights = self.attention(fused)
        fused = fused * attention_weights
        
        return fused

# ================================
# 3. æ”¹è‰¯ã•ã‚ŒãŸæ™‚ç©ºé–“æ³¨æ„æ©Ÿæ§‹
# ================================

class EnhancedSpatioTemporalAttention(nn.Module):
    """æ”¹è‰¯ã•ã‚ŒãŸæ™‚ç©ºé–“æ³¨æ„æ©Ÿæ§‹"""
    
    def __init__(self, channels):
        super(EnhancedSpatioTemporalAttention, self).__init__()
        
        # åˆ†é›¢å¯èƒ½ãªæ³¨æ„æ©Ÿæ§‹
        self.temporal_attention = nn.Sequential(
            nn.AdaptiveAvgPool3d((None, 1, 1)),
            nn.Conv3d(channels, channels//8, kernel_size=(3, 1, 1), padding=(1, 0, 0)),
            nn.ReLU(inplace=True),
            nn.Conv3d(channels//8, channels, kernel_size=(1, 1, 1)),
            nn.Sigmoid()
        )
        
        self.spatial_attention = nn.Sequential(
            nn.AdaptiveAvgPool3d((1, None, None)),
            nn.Conv3d(channels, channels//8, kernel_size=(1, 3, 3), padding=(0, 1, 1)),
            nn.ReLU(inplace=True),
            nn.Conv3d(channels//8, channels, kernel_size=(1, 1, 1)),
            nn.Sigmoid()
        )
        
        # èåˆå±¤
        self.fusion = nn.Sequential(
            nn.Conv3d(channels, channels, kernel_size=1),
            nn.BatchNorm3d(channels),
            nn.ReLU(inplace=True)
        )
    
    def forward(self, x):
        B, C, T, H, W = x.shape
        identity = x
        
        # æ™‚ç©ºé–“æ³¨æ„
        temp_att = self.temporal_attention(x)
        spat_att = self.spatial_attention(x)
        
        # æ³¨æ„æ©Ÿæ§‹ã‚’é©ç”¨
        x_att = x * temp_att * spat_att
        
        # èåˆã¨æ®‹å·®æ¥ç¶š
        x_fused = self.fusion(x_att)
        
        return x_fused + identity * 0.2

# ================================
# 4. Phase 3 ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£
# ================================

class ResidualMultiScaleBlock3D(nn.Module):
    """æ®‹å·®ãƒãƒ«ãƒã‚¹ã‚±ãƒ¼ãƒ«ãƒ–ãƒ­ãƒƒã‚¯"""
    
    def __init__(self, in_channels, out_channels, stride=1):
        super(ResidualMultiScaleBlock3D, self).__init__()
        
        # ãƒãƒ«ãƒã‚¹ã‚±ãƒ¼ãƒ«ç‰¹å¾´èåˆ
        self.multiscale = MultiScaleFeatureFusion(in_channels, out_channels)
        
        # æ”¹è‰¯ã•ã‚ŒãŸæ³¨æ„æ©Ÿæ§‹
        self.attention = EnhancedSpatioTemporalAttention(out_channels)
        
        # ã‚·ãƒ§ãƒ¼ãƒˆã‚«ãƒƒãƒˆæ¥ç¶š
        self.shortcut = nn.Sequential()
        if stride != 1 or in_channels != out_channels:
            self.shortcut = nn.Sequential(
                nn.Conv3d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),
                nn.BatchNorm3d(out_channels)
            )
        
        # æœ€çµ‚å‡¦ç†
        self.final_conv = nn.Sequential(
            nn.Conv3d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False),
            nn.BatchNorm3d(out_channels)
        )
        
        self.dropout = nn.Dropout3d(0.1)
        
    def forward(self, x):
        identity = x
        
        # ãƒãƒ«ãƒã‚¹ã‚±ãƒ¼ãƒ«ç‰¹å¾´æŠ½å‡º
        out = self.multiscale(x)
        
        # æ³¨æ„æ©Ÿæ§‹
        out = self.attention(out)
        
        # æœ€çµ‚ç•³ã¿è¾¼ã¿
        out = self.final_conv(out)
        out = self.dropout(out)
        
        # æ®‹å·®æ¥ç¶š
        out += self.shortcut(identity)
        
        return F.relu(out)

class Conv3DAutoencoderPhase3(nn.Module):
    """Phase 3: ãƒãƒ«ãƒã‚¹ã‚±ãƒ¼ãƒ«ç‰¹å¾´èåˆ Autoencoder"""
    
    def __init__(self, input_channels=1, fixed_frames=30, target_size=(64, 64), latent_dim=512):
        super(Conv3DAutoencoderPhase3, self).__init__()
        
        self.latent_dim = latent_dim
        self.fixed_frames = fixed_frames
        self.target_size = target_size
        
        # åˆæœŸç•³ã¿è¾¼ã¿
        self.initial_conv = nn.Sequential(
            nn.Conv3d(input_channels, 64, kernel_size=(3, 7, 7), stride=(1, 2, 2), padding=(1, 3, 3)),
            nn.BatchNorm3d(64),
            nn.ReLU(inplace=True),
            nn.Dropout3d(0.05)
        )
        
        # ãƒãƒ«ãƒã‚¹ã‚±ãƒ¼ãƒ«æ®‹å·®ãƒ–ãƒ­ãƒƒã‚¯ç¾¤
        self.res_block1 = ResidualMultiScaleBlock3D(64, 128, stride=(2, 2, 2))
        self.res_block2 = ResidualMultiScaleBlock3D(128, 128)
        self.res_block3 = ResidualMultiScaleBlock3D(128, 256, stride=(2, 2, 2))
        self.res_block4 = ResidualMultiScaleBlock3D(256, 256)
        self.res_block5 = ResidualMultiScaleBlock3D(256, 512, stride=(2, 2, 2))
        self.res_block6 = ResidualMultiScaleBlock3D(512, 512)
        
        # ã‚°ãƒ­ãƒ¼ãƒãƒ«ç‰¹å¾´æŠ½å‡º
        self.global_pool = nn.AdaptiveAvgPool3d((2, 2, 2))
        self.dropout_before_latent = nn.Dropout3d(0.3)
        
        # æ½œåœ¨ç©ºé–“å°„å½±ï¼ˆæ‹¡å¼µï¼‰
        self.to_latent = nn.Sequential(
            nn.Flatten(),
            nn.Linear(512 * 2 * 2 * 2, 1024),
            nn.BatchNorm1d(1024),
            nn.ReLU(inplace=True),
            nn.Dropout(0.4),
            nn.Linear(1024, latent_dim),
            nn.BatchNorm1d(latent_dim)
        )
        
        # å¾©å…ƒãƒ‘ã‚¹
        self.from_latent = nn.Sequential(
            nn.Linear(latent_dim, 1024),
            nn.BatchNorm1d(1024),
            nn.ReLU(inplace=True),
            nn.Dropout(0.4),
            nn.Linear(1024, 512 * 2 * 2 * 2),
            nn.ReLU(inplace=True)
        )
        
        # ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼ï¼ˆãƒãƒ«ãƒã‚¹ã‚±ãƒ¼ãƒ«å¯¾å¿œï¼‰
        self.decoder = nn.Sequential(
            nn.ConvTranspose3d(512, 256, kernel_size=(3, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1)),
            nn.BatchNorm3d(256),
            nn.ReLU(inplace=True),
            nn.Dropout3d(0.2),
            
            nn.ConvTranspose3d(256, 128, kernel_size=(3, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1)),
            nn.BatchNorm3d(128),
            nn.ReLU(inplace=True),
            nn.Dropout3d(0.15),
            
            nn.ConvTranspose3d(128, 64, kernel_size=(3, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1)),
            nn.BatchNorm3d(64),
            nn.ReLU(inplace=True),
            nn.Dropout3d(0.1),
            
            nn.ConvTranspose3d(64, input_channels, kernel_size=(3, 7, 7), stride=(1, 2, 2), padding=(1, 3, 3)),
            nn.Sigmoid()
        )
    
    def encode(self, x):
        """ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰å‡¦ç†"""
        x = self.initial_conv(x)
        x = self.res_block1(x)
        x = self.res_block2(x)
        x = self.res_block3(x)
        x = self.res_block4(x)
        x = self.res_block5(x)
        x = self.res_block6(x)
        x = self.global_pool(x)
        x = self.dropout_before_latent(x)
        return self.to_latent(x)
    
    def decode(self, latent):
        """ãƒ‡ã‚³ãƒ¼ãƒ‰å‡¦ç†"""
        x = self.from_latent(latent)
        x = x.view(-1, 512, 2, 2, 2)
        x = self.decoder(x)
        
        # ç›®æ¨™ã‚µã‚¤ã‚ºã«èª¿æ•´
        target_h, target_w = self.target_size
        x = F.interpolate(x, size=(self.fixed_frames, target_h, target_w), 
                         mode='trilinear', align_corners=False)
        return x
    
    def forward(self, x):
        latent = self.encode(x)
        reconstructed = self.decode(latent)
        return reconstructed, latent

# ================================
# 5. æ”¹è‰¯ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆæ‹¡å¼µå¯¾å¿œï¼‰
# ================================

class GrayScottDatasetPhase3(Dataset):
    """Phase 3å¯¾å¿œãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆæ‹¡å¼µæ©Ÿèƒ½ä»˜ãï¼‰"""
    
    def __init__(self, gif_folder, fixed_frames=30, target_size=(64, 64), 
                 use_augmentation=True, max_samples=None):
        self.gif_folder = gif_folder
        self.fixed_frames = fixed_frames
        self.target_size = target_size
        self.use_augmentation = use_augmentation
        self.max_samples = max_samples
        
        # ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µå™¨
        self.augmentation = GrayScottAugmentation() if use_augmentation else None
        
        self.gif_files = []
        self.f_values = []
        self.k_values = []
        self.tensors = []
        
        self._load_data()
    
    def _parse_filename(self, filename):
        """ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰f, kãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æŠ½å‡º"""
        pattern = r'GrayScott-f([0-9.]+)-k([0-9.]+)-\d+\.gif'
        match = re.match(pattern, filename)
        if match:
            return float(match.group(1)), float(match.group(2))
        return None, None
    
    def _load_gif_as_tensor(self, gif_path):
        """GIFã‚’3Dãƒ†ãƒ³ã‚½ãƒ«ã«å¤‰æ›"""
        try:
            gif = imageio.mimread(gif_path)
            frames = []
            
            for frame in gif[:self.fixed_frames]:
                if len(frame.shape) == 3:
                    frame = np.mean(frame, axis=2)
                
                pil_frame = Image.fromarray(frame.astype(np.uint8))
                pil_frame = pil_frame.resize(self.target_size)
                frame_array = np.array(pil_frame) / 255.0
                frames.append(frame_array)
            
            while len(frames) < self.fixed_frames:
                frames.append(frames[-1] if frames else np.zeros(self.target_size))
            
            tensor = torch.FloatTensor(np.array(frames[:self.fixed_frames]))
            return tensor.unsqueeze(0)
            
        except Exception as e:
            print(f"Error loading {gif_path}: {e}")
            return None
    
    def _load_data(self):
        """å…¨GIFãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
        gif_files = [f for f in os.listdir(self.gif_folder) if f.endswith('.gif')]
        
        if self.max_samples:
            gif_files = gif_files[:self.max_samples]
        
        print(f"Loading {len(gif_files)} GIF files for Phase 3...")
        
        for i, filename in enumerate(gif_files):
            if i % 100 == 0:
                print(f"Progress: {i+1}/{len(gif_files)} ({(i+1)/len(gif_files)*100:.1f}%)")
            
            f_val, k_val = self._parse_filename(filename)
            if f_val is None or k_val is None:
                continue
            
            gif_path = os.path.join(self.gif_folder, filename)
            tensor = self._load_gif_as_tensor(gif_path)
            
            if tensor is not None:
                self.gif_files.append(filename)
                self.f_values.append(f_val)
                self.k_values.append(k_val)
                self.tensors.append(tensor)
        
        print(f"âœ… Successfully loaded {len(self.tensors)} samples for Phase 3")
    
    def __len__(self):
        return len(self.tensors)
    
    def __getitem__(self, idx):
        tensor = self.tensors[idx].clone()
        
        # ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µé©ç”¨
        if self.use_augmentation and self.augmentation is not None:
            tensor = self.augmentation(tensor)
        
        return {
            'tensor': tensor,
            'f_value': self.f_values[idx],
            'k_value': self.k_values[idx],
            'filename': self.gif_files[idx]
        }

# ================================
# 6. æ”¹è‰¯ã•ã‚ŒãŸè¨“ç·´ã‚·ã‚¹ãƒ†ãƒ 
# ================================

def train_autoencoder_phase3(model, dataloader, num_epochs=60, learning_rate=1e-3, 
                           weight_decay=1e-4, warmup_epochs=5):
    """Phase 3 æ”¹è‰¯è¨“ç·´ã‚·ã‚¹ãƒ†ãƒ """
    
    print("ğŸ¯ Starting Phase 3 Training...")
    print(f"ğŸ“Š Model parameters: {sum(p.numel() for p in model.parameters()):,}")
    
    # æå¤±é–¢æ•°ï¼ˆãƒãƒ«ãƒã‚¿ã‚¹ã‚¯ï¼‰
    mse_loss = nn.MSELoss()
    l1_loss = nn.L1Loss()
    
    # ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãƒ¼ï¼ˆAdamW + ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ï¼‰
    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay, 
                           betas=(0.9, 0.999), eps=1e-8)
    
    # å­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ï¼ˆã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ— + ã‚³ã‚µã‚¤ãƒ³ã‚¢ãƒ‹ãƒ¼ãƒªãƒ³ã‚°ï¼‰
    def lr_lambda(epoch):
        if epoch < warmup_epochs:
            return epoch / warmup_epochs
        else:
            return 0.5 * (1 + np.cos(np.pi * (epoch - warmup_epochs) / (num_epochs - warmup_epochs)))
    
    scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)
    
    # è¨“ç·´ãƒ«ãƒ¼ãƒ—
    model.train()
    losses = []
    start_time = time.time()
    
    print("="*80)
    print("ğŸš€ Phase 3 Multi-Scale Feature Fusion Training")
    print("="*80)
    
    for epoch in range(num_epochs):
        epoch_start_time = time.time()
        epoch_loss = 0.0
        
        for batch_idx, batch in enumerate(dataloader):
            tensors = batch['tensor'].to(device)
            
            optimizer.zero_grad()
            
            # ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒ‘ã‚¹
            reconstructed, latent = model(tensors)
            
            # ãƒãƒ«ãƒã‚¿ã‚¹ã‚¯æå¤±
            loss_mse = mse_loss(reconstructed, tensors)
            loss_l1 = l1_loss(reconstructed, tensors)
            
            # æ½œåœ¨ç©ºé–“æ­£å‰‡åŒ–
            latent_reg = torch.mean(torch.norm(latent, dim=1))
            
            # ç·åˆæå¤±
            total_loss = loss_mse + 0.1 * loss_l1 + 0.001 * latent_reg
            
            # ãƒãƒƒã‚¯ãƒ¯ãƒ¼ãƒ‰ãƒ‘ã‚¹
            total_loss.backward()
            
            # å‹¾é…ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            
            optimizer.step()
            epoch_loss += total_loss.item()
        
        scheduler.step()
        
        avg_loss = epoch_loss / len(dataloader)
        losses.append(avg_loss)
        current_lr = scheduler.get_last_lr()[0]
        epoch_time = time.time() - epoch_start_time
        
        # é€²æ—è¡¨ç¤º
        progress = ((epoch + 1) / num_epochs) * 100
        if (epoch + 1) % 5 == 0 or epoch < 5:
            print(f'Epoch [{epoch+1:2d}/{num_epochs}] '
                  f'({progress:5.1f}%) | '
                  f'Loss: {avg_loss:.6f} | '
                  f'LR: {current_lr:.2e} | '
                  f'Time: {epoch_time:.1f}s')
    
    total_time = time.time() - start_time
    print("="*80)
    print(f"ğŸ‰ Phase 3 Training completed in {total_time/60:.1f} minutes")
    
    return losses

def extract_latent_vectors_phase3(model, dataloader):
    """Phase 3 æ½œåœ¨ãƒ™ã‚¯ãƒˆãƒ«æŠ½å‡º"""
    print("ğŸ” Extracting latent vectors (Phase 3)...")
    
    model.eval()
    latent_vectors = []
    f_values = []
    k_values = []
    
    with torch.no_grad():
        for batch in dataloader:
            tensors = batch['tensor'].to(device)
            _, latent = model(tensors)
            latent_vectors.append(latent.cpu().numpy())
            f_values.extend(batch['f_value'].numpy())
            k_values.extend(batch['k_value'].numpy())
    
    latent_vectors = np.vstack(latent_vectors)
    f_values = np.array(f_values)
    k_values = np.array(k_values)
    
    print(f"âœ… Extracted {len(latent_vectors)} latent vectors (dim: {latent_vectors.shape[1]})")
    
    return latent_vectors, f_values, k_values

def perform_clustering_phase3(latent_vectors, n_clusters=6):
    """Phase 3 ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°"""
    print(f"ğŸ¯ Performing clustering (k={n_clusters})...")
    
    # æ¨™æº–åŒ–
    scaler = StandardScaler()
    latent_scaled = scaler.fit_transform(latent_vectors)
    
    # ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°
    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
    cluster_labels = kmeans.fit_predict(latent_scaled)
    
    # æ€§èƒ½è©•ä¾¡
    silhouette_avg = silhouette_score(latent_vectors, cluster_labels)
    calinski_score = calinski_harabasz_score(latent_vectors, cluster_labels)
    davies_bouldin = davies_bouldin_score(latent_vectors, cluster_labels)
    
    print(f"ğŸ“Š Clustering Results:")
    print(f"   â­ Silhouette Score: {silhouette_avg:.4f}")
    print(f"   ğŸ“Š Calinski-Harabasz: {calinski_score:.2f}")
    print(f"   ğŸ“ˆ Davies-Bouldin: {davies_bouldin:.4f}")
    
    return cluster_labels, silhouette_avg, calinski_score, davies_bouldin

def main():
    """Phase 3 ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    
    print("="*80)
    print("ğŸŒ Gray-Scott Phase 3: Multi-Scale Feature Fusion")
    print("="*80)
    
    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š
    gif_folder = 'data/gif'
    fixed_frames = 30
    target_size = (64, 64)
    latent_dim = 512  # Phase 2ã‹ã‚‰æ‹¡å¼µ
    num_epochs = 60
    batch_size = 4  # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡è€ƒæ…®
    learning_rate = 1e-3
    weight_decay = 1e-4
    n_clusters = 6
    
    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ
    print("ğŸ“Š Creating Phase 3 dataset with augmentation...")
    dataset = GrayScottDatasetPhase3(gif_folder, fixed_frames, target_size, 
                                   use_augmentation=True)
    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, 
                          num_workers=2, pin_memory=True)
    
    print(f"ğŸ“Š Dataset: {len(dataset)} samples, Batch size: {batch_size}")
    
    # ãƒ¢ãƒ‡ãƒ«ä½œæˆ
    print("ğŸ§  Creating Phase 3 Multi-Scale model...")
    model = Conv3DAutoencoderPhase3(latent_dim=latent_dim, 
                                  fixed_frames=fixed_frames, 
                                  target_size=target_size).to(device)
    
    # è¨“ç·´å®Ÿè¡Œ
    losses = train_autoencoder_phase3(model, dataloader, num_epochs, 
                                    learning_rate, weight_decay)
    
    # æ½œåœ¨ãƒ™ã‚¯ãƒˆãƒ«æŠ½å‡º
    latent_vectors, f_values, k_values = extract_latent_vectors_phase3(model, dataloader)
    
    # ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°
    cluster_labels, silhouette_avg, calinski_score, davies_bouldin = \
        perform_clustering_phase3(latent_vectors, n_clusters)
    
    # çµæœä¿å­˜
    results = {
        'model_state_dict': model.state_dict(),
        'losses': losses,
        'latent_vectors': latent_vectors,
        'cluster_labels': cluster_labels,
        'f_values': f_values,
        'k_values': k_values,
        'silhouette_score': silhouette_avg,
        'calinski_score': calinski_score,
        'davies_bouldin': davies_bouldin,
        'hyperparameters': {
            'latent_dim': latent_dim,
            'num_epochs': num_epochs,
            'batch_size': batch_size,
            'learning_rate': learning_rate,
            'weight_decay': weight_decay,
            'n_clusters': n_clusters
        }
    }
    
    # çµæœä¿å­˜
    results_path = 'results/phase3_results.pkl'
    with open(results_path, 'wb') as f:
        pickle.dump(results, f)
    
    print(f"ğŸ’¾ Results saved to: {results_path}")
    
    # æ€§èƒ½æ¯”è¼ƒ
    print("="*80)
    print("ğŸ† Phase 3 Results Summary:")
    print("="*80)
    print(f"ğŸ¯ Architecture: Multi-Scale Feature Fusion + Enhanced Attention")
    print(f"ğŸ“Š Samples: {len(dataset)}")
    print(f"ğŸ§  Latent Dimension: {latent_dim}")
    print(f"âš™ï¸  Model Parameters: {sum(p.numel() for p in model.parameters()):,}")
    print(f"ğŸ“‰ Final Loss: {losses[-1]:.6f}")
    print(f"ğŸ¯ Clusters: {n_clusters}")
    print(f"â­ Silhouette Score: {silhouette_avg:.4f}")
    print(f"ğŸ“Š Calinski-Harabasz: {calinski_score:.2f}")
    print(f"ğŸ“ˆ Davies-Bouldin: {davies_bouldin:.4f}")
    print("="*80)
    
    # Phaseæ¯”è¼ƒ
    phase2_score = 0.4671
    improvement = ((silhouette_avg - phase2_score) / phase2_score) * 100
    
    print(f"ğŸ“ˆ Performance Comparison:")
    print(f"   Phase 2: {phase2_score:.4f}")
    print(f"   Phase 3: {silhouette_avg:.4f}")
    print(f"   Improvement: {improvement:+.1f}%")
    
    if improvement >= 10:
        print("ğŸ‰ Phase 3 ç›®æ¨™é”æˆï¼ (10%ä»¥ä¸Šã®å‘ä¸Š)")
    else:
        print(f"âš ï¸  Phase 3 ç›®æ¨™æœªé” ({improvement:.1f}% < 10%)")
    
    return results

if __name__ == "__main__":
    main()
