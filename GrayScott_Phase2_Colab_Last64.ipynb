{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# ğŸš€ Gray-Scott Phase 2: Last 64 Frames GPUç‰ˆï¼ˆGoogle Colabï¼‰\n",
        "\n",
        "**ç›®æ¨™**: å¾ŒåŠ64ãƒ•ãƒ¬ãƒ¼ãƒ ã®ã¿ã‚’ä½¿ç”¨ã—ãŸå­¦ç¿’ã§Phase 1 (0.565) â†’ Phase 2 (0.65+) ã¸ã®ã•ã‚‰ãªã‚‹å‘ä¸Š\n",
        "\n",
        "**ä¸»è¦æ”¹å–„ç‚¹**:\n",
        "- âœ… æ®‹å·®æ¥ç¶šï¼ˆResNetï¼‰+ æ™‚ç©ºé–“æ³¨æ„æ©Ÿæ§‹\n",
        "- âœ… GPUé«˜é€ŸåŒ–ï¼ˆCPUæ¯” 5-10å€ï¼‰\n",
        "- âœ… Google Driveé€£æº\n",
        "- âœ… **å¾ŒåŠ64ãƒ•ãƒ¬ãƒ¼ãƒ ã®ã¿ã‚’ä½¿ç”¨** - ã‚ˆã‚Šå®‰å®šã—ãŸå¾ŒæœŸãƒ‘ã‚¿ãƒ¼ãƒ³ã«ç„¦ç‚¹\n",
        "\n",
        "**å‰ææ¡ä»¶**: Google Driveã®`ãƒã‚¤ãƒ‰ãƒ©ã‚¤ãƒ–/GrayScottML/gif/`ã«1500å€‹ã®GIFãƒ•ã‚¡ã‚¤ãƒ«ã‚’é…ç½®\n",
        "\n",
        "**å®Ÿè¡Œæ™‚é–“**: **GPU 3-5åˆ†** ğŸƒâ€â™‚ï¸ğŸ’¨\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ğŸ“‹ Step 1: ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ— & Google Driveæ¥ç¶š\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "import imageio.v2 as imageio\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "import time\n",
        "import pickle\n",
        "\n",
        "# GPUç¢ºèª\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory/1e9:.1f} GB\")\n",
        "    device = torch.device('cuda')\n",
        "    # GPUæœ€é©åŒ–è¨­å®š\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    torch.backends.cudnn.deterministic = False\n",
        "else:\n",
        "    print(\"âš ï¸ GPU not available. Please enable GPU in Runtime > Change runtime type\")\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "print(f\"ğŸš€ Using device: {device}\")\n",
        "\n",
        "# ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n",
        "try:\n",
        "    import imageio\n",
        "    import seaborn\n",
        "    print(\"âœ… All packages available\")\n",
        "except ImportError:\n",
        "    print(\"ğŸ“¦ Installing required packages...\")\n",
        "    !pip install imageio scikit-learn seaborn\n",
        "    import imageio\n",
        "    import seaborn\n",
        "    print(\"âœ… Packages installed successfully\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Google Driveæ¥ç¶šã¨ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹ç¢ºèª\n",
        "from google.colab import drive\n",
        "\n",
        "# Google Driveã‚’ãƒã‚¦ãƒ³ãƒˆ\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹è¨­å®š\n",
        "GIF_FOLDER_PATH = '/content/drive/MyDrive/GrayScottML/gif'\n",
        "\n",
        "# ãƒ‡ãƒ¼ã‚¿ç¢ºèª\n",
        "if os.path.exists(GIF_FOLDER_PATH):\n",
        "    gif_files = [f for f in os.listdir(GIF_FOLDER_PATH) if f.endswith('.gif')]\n",
        "    gif_count = len(gif_files)\n",
        "    print(f\"âœ… Google Drive connected successfully!\")\n",
        "    print(f\"ğŸ“ Path: {GIF_FOLDER_PATH}\")\n",
        "    print(f\"ğŸ¬ GIF files found: {gif_count}\")\n",
        "    \n",
        "    if gif_count >= 1000:\n",
        "        print(\"ğŸ‰ Ready for Phase 2 training with last 64 frames!\")\n",
        "    else:\n",
        "        print(f\"âš ï¸ Not enough files. Expected: 1500, Found: {gif_count}\")\n",
        "        print(\"Please upload more GIF files to Google Drive.\")\n",
        "else:\n",
        "    print(\"âŒ Google Drive path not found!\")\n",
        "    print(f\"Expected path: {GIF_FOLDER_PATH}\")\n",
        "    print(\"Please ensure the following structure exists:\")\n",
        "    print(\"  MyDrive/\")\n",
        "    print(\"  â””â”€â”€ GrayScottML/\")\n",
        "    print(\"      â””â”€â”€ gif/\")\n",
        "    print(\"          â”œâ”€â”€ GrayScott-f0.0100-k0.0400-00.gif\")\n",
        "    print(\"          â””â”€â”€ ... (1500 files)\")\n",
        "    \n",
        "    # ãƒã‚¤ãƒ‰ãƒ©ã‚¤ãƒ–ã®å†…å®¹ã‚’è¡¨ç¤º\n",
        "    mydrive_path = '/content/drive/MyDrive'\n",
        "    if os.path.exists(mydrive_path):\n",
        "        print(f\"\\nğŸ“‚ Contents of MyDrive:\")\n",
        "        for item in sorted(os.listdir(mydrive_path))[:10]:\n",
        "            print(f\"   ğŸ“ {item}\")\n",
        "        print(\"   ... (showing first 10 items)\")\n",
        "    raise FileNotFoundError(\"Please set up the correct folder structure in Google Drive\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ğŸ§  Step 2: Phase 2 ãƒ¢ãƒ‡ãƒ«å®Ÿè£…ï¼ˆå¾ŒåŠ64ãƒ•ãƒ¬ãƒ¼ãƒ å¯¾å¿œï¼‰\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚¯ãƒ©ã‚¹ï¼ˆå¾ŒåŠ64ãƒ•ãƒ¬ãƒ¼ãƒ å°‚ç”¨ï¼‰\n",
        "class GrayScottDatasetLast64(Dataset):\n",
        "    def __init__(self, gif_folder, fixed_frames=64, target_size=(64, 64), max_samples=None):\n",
        "        self.gif_folder = gif_folder\n",
        "        self.fixed_frames = fixed_frames\n",
        "        self.target_size = target_size\n",
        "        self.max_samples = max_samples\n",
        "        \n",
        "        self.gif_files = []\n",
        "        self.f_values = []\n",
        "        self.k_values = []\n",
        "        self.tensors = []\n",
        "        \n",
        "        self._load_data()\n",
        "    \n",
        "    def _parse_filename(self, filename):\n",
        "        pattern = r'GrayScott-f([0-9.]+)-k([0-9.]+)-\\d+\\.gif'\n",
        "        match = re.match(pattern, filename)\n",
        "        if match:\n",
        "            return float(match.group(1)), float(match.group(2))\n",
        "        return None, None\n",
        "    \n",
        "    def _load_gif_as_tensor(self, gif_path):\n",
        "        try:\n",
        "            gif = imageio.mimread(gif_path)\n",
        "            total_frames = len(gif)\n",
        "            \n",
        "            # å¾ŒåŠ64ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’æŠ½å‡º\n",
        "            if total_frames >= self.fixed_frames:\n",
        "                # å¾ŒåŠ64ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å–å¾—\n",
        "                start_idx = total_frames - self.fixed_frames\n",
        "                selected_frames = gif[start_idx:]\n",
        "            else:\n",
        "                # ãƒ•ãƒ¬ãƒ¼ãƒ æ•°ãŒ64æœªæº€ã®å ´åˆã¯å…¨ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä½¿ç”¨\n",
        "                selected_frames = gif\n",
        "                print(f\"Warning: Only {total_frames} frames available, using all frames\")\n",
        "            \n",
        "            frames = []\n",
        "            for frame in selected_frames:\n",
        "                if len(frame.shape) == 3:\n",
        "                    frame = np.mean(frame, axis=2)\n",
        "                \n",
        "                pil_frame = Image.fromarray(frame.astype(np.uint8))\n",
        "                pil_frame = pil_frame.resize(self.target_size)\n",
        "                frame_array = np.array(pil_frame) / 255.0\n",
        "                frames.append(frame_array)\n",
        "            \n",
        "            # 64ãƒ•ãƒ¬ãƒ¼ãƒ ã«ãªã‚‹ã‚ˆã†ã«ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰\n",
        "            while len(frames) < self.fixed_frames:\n",
        "                frames.append(frames[-1] if frames else np.zeros(self.target_size))\n",
        "            \n",
        "            # æ­£ç¢ºã«64ãƒ•ãƒ¬ãƒ¼ãƒ ã«ã™ã‚‹\n",
        "            frames = frames[:self.fixed_frames]\n",
        "            \n",
        "            tensor = torch.FloatTensor(np.array(frames))\n",
        "            return tensor.unsqueeze(0)  # ãƒãƒ£ãƒ³ãƒãƒ«æ¬¡å…ƒã‚’è¿½åŠ \n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {gif_path}: {e}\")\n",
        "            return None\n",
        "    \n",
        "    def _load_data(self):\n",
        "        gif_files = [f for f in os.listdir(self.gif_folder) if f.endswith('.gif')]\n",
        "        \n",
        "        if self.max_samples:\n",
        "            gif_files = gif_files[:self.max_samples]\n",
        "        \n",
        "        print(f\"Loading {len(gif_files)} GIF files (last 64 frames each)...\")\n",
        "        \n",
        "        for i, filename in enumerate(gif_files):\n",
        "            if i % 100 == 0:\n",
        "                print(f\"Progress: {i+1}/{len(gif_files)} ({(i+1)/len(gif_files)*100:.1f}%)\")\n",
        "            \n",
        "            f_val, k_val = self._parse_filename(filename)\n",
        "            if f_val is None or k_val is None:\n",
        "                continue\n",
        "            \n",
        "            gif_path = os.path.join(self.gif_folder, filename)\n",
        "            tensor = self._load_gif_as_tensor(gif_path)\n",
        "            \n",
        "            if tensor is not None:\n",
        "                self.gif_files.append(filename)\n",
        "                self.f_values.append(f_val)\n",
        "                self.k_values.append(k_val)\n",
        "                self.tensors.append(tensor)\n",
        "        \n",
        "        print(f\"âœ… Successfully loaded {len(self.tensors)} samples with last 64 frames each\")\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.tensors)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            'tensor': self.tensors[idx],\n",
        "            'f_value': self.f_values[idx],\n",
        "            'k_value': self.k_values[idx],\n",
        "            'filename': self.gif_files[idx]\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# æ³¨æ„æ©Ÿæ§‹ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«\n",
        "class SpatioTemporalAttention(nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super().__init__()\n",
        "        \n",
        "        # ç©ºé–“æ³¨æ„\n",
        "        self.spatial_attention = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool3d((None, 1, 1)),\n",
        "            nn.Conv3d(channels, channels//4, 1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv3d(channels//4, channels, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        \n",
        "        # æ™‚é–“æ³¨æ„\n",
        "        self.temporal_attention = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool3d((1, None, None)),\n",
        "            nn.Conv3d(channels, channels//4, 1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv3d(channels//4, channels, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        \n",
        "        # ãƒãƒ£ãƒ³ãƒãƒ«æ³¨æ„\n",
        "        self.channel_attention = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool3d(1),\n",
        "            nn.Conv3d(channels, channels//4, 1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv3d(channels//4, channels, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "        \n",
        "        # 3ã¤ã®æ³¨æ„æ©Ÿæ§‹ã‚’é©ç”¨\n",
        "        x = x * self.spatial_attention(x)\n",
        "        x = x * self.temporal_attention(x)\n",
        "        x = x * self.channel_attention(x)\n",
        "        \n",
        "        return x + identity * 0.1\n",
        "\n",
        "# æ®‹å·®æ³¨æ„ãƒ–ãƒ­ãƒƒã‚¯\n",
        "class ResidualAttentionBlock3D(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.conv1 = nn.Conv3d(in_channels, out_channels, 3, stride, 1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm3d(out_channels, momentum=0.1)\n",
        "        self.conv2 = nn.Conv3d(out_channels, out_channels, 3, 1, 1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm3d(out_channels, momentum=0.1)\n",
        "        \n",
        "        self.attention = SpatioTemporalAttention(out_channels)\n",
        "        \n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv3d(in_channels, out_channels, 1, stride, bias=False),\n",
        "                nn.BatchNorm3d(out_channels, momentum=0.1)\n",
        "            )\n",
        "        \n",
        "        self.dropout = nn.Dropout3d(0.1)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "        \n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.dropout(out)\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out = self.attention(out)\n",
        "        \n",
        "        out += self.shortcut(identity)\n",
        "        return F.relu(out)\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ğŸš€ Step 3: Phase 2 å­¦ç¿’å®Ÿè¡Œï¼ˆ64ãƒ•ãƒ¬ãƒ¼ãƒ å¯¾å¿œï¼‰\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Phase 2 ãƒ¡ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«ï¼ˆ64ãƒ•ãƒ¬ãƒ¼ãƒ å¯¾å¿œï¼‰\n",
        "class Conv3DAutoencoderPhase2Last64(nn.Module):\n",
        "    def __init__(self, input_channels=1, fixed_frames=64, target_size=(64, 64), latent_dim=256):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.latent_dim = latent_dim\n",
        "        self.fixed_frames = fixed_frames\n",
        "        self.target_size = target_size\n",
        "        \n",
        "        # åˆæœŸç•³ã¿è¾¼ã¿ï¼ˆ64ãƒ•ãƒ¬ãƒ¼ãƒ å¯¾å¿œï¼‰\n",
        "        self.initial_conv = nn.Sequential(\n",
        "            nn.Conv3d(input_channels, 32, (5, 7, 7), (2, 2, 2), (2, 3, 3)),\n",
        "            nn.BatchNorm3d(32, momentum=0.1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout3d(0.05)\n",
        "        )\n",
        "        \n",
        "        # æ®‹å·®æ³¨æ„ãƒ–ãƒ­ãƒƒã‚¯ç¾¤ï¼ˆ64ãƒ•ãƒ¬ãƒ¼ãƒ ç”¨ã«èª¿æ•´ï¼‰\n",
        "        self.res_block1 = ResidualAttentionBlock3D(32, 64, stride=(2, 2, 2))\n",
        "        self.res_block2 = ResidualAttentionBlock3D(64, 64)\n",
        "        self.res_block3 = ResidualAttentionBlock3D(64, 128, stride=(2, 2, 2))\n",
        "        self.res_block4 = ResidualAttentionBlock3D(128, 128)\n",
        "        self.res_block5 = ResidualAttentionBlock3D(128, 256, stride=(2, 2, 2))\n",
        "        self.res_block6 = ResidualAttentionBlock3D(256, 256)\n",
        "        \n",
        "        # ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ—ãƒ¼ãƒªãƒ³ã‚°\n",
        "        self.global_pool = nn.AdaptiveAvgPool3d((2, 2, 2))\n",
        "        self.dropout_before_latent = nn.Dropout3d(0.3)\n",
        "        \n",
        "        # æ½œåœ¨ç©ºé–“å°„å½±\n",
        "        self.to_latent = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(256 * 2 * 2 * 2, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Linear(512, latent_dim),\n",
        "            nn.BatchNorm1d(latent_dim)\n",
        "        )\n",
        "        \n",
        "        # å¾©å…ƒ\n",
        "        self.from_latent = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Linear(512, 256 * 2 * 2 * 2),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        \n",
        "        # ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼ï¼ˆ64ãƒ•ãƒ¬ãƒ¼ãƒ å¾©å…ƒç”¨ï¼‰\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose3d(256, 128, (4, 4, 4), (2, 2, 2), (1, 1, 1)),\n",
        "            nn.BatchNorm3d(128, momentum=0.1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout3d(0.2),\n",
        "            \n",
        "            nn.ConvTranspose3d(128, 64, (4, 4, 4), (2, 2, 2), (1, 1, 1)),\n",
        "            nn.BatchNorm3d(64, momentum=0.1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout3d(0.15),\n",
        "            \n",
        "            nn.ConvTranspose3d(64, 32, (4, 4, 4), (2, 2, 2), (1, 1, 1)),\n",
        "            nn.BatchNorm3d(32, momentum=0.1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout3d(0.1),\n",
        "            \n",
        "            nn.ConvTranspose3d(32, input_channels, (6, 7, 7), (2, 2, 2), (2, 3, 3)),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "    \n",
        "    def encode(self, x):\n",
        "        x = self.initial_conv(x)\n",
        "        x = self.res_block1(x)\n",
        "        x = self.res_block2(x)\n",
        "        x = self.res_block3(x)\n",
        "        x = self.res_block4(x)\n",
        "        x = self.res_block5(x)\n",
        "        x = self.res_block6(x)\n",
        "        x = self.global_pool(x)\n",
        "        x = self.dropout_before_latent(x)\n",
        "        return self.to_latent(x)\n",
        "    \n",
        "    def decode(self, latent):\n",
        "        x = self.from_latent(latent)\n",
        "        x = x.view(-1, 256, 2, 2, 2)\n",
        "        x = self.decoder(x)\n",
        "        target_h, target_w = self.target_size\n",
        "        return F.interpolate(x, size=(self.fixed_frames, target_h, target_w), \n",
        "                           mode='trilinear', align_corners=False)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        latent = self.encode(x)\n",
        "        reconstructed = self.decode(latent)\n",
        "        return reconstructed, latent\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Phase 2 å­¦ç¿’ãƒ»è©•ä¾¡å®Ÿè¡Œï¼ˆ64ãƒ•ãƒ¬ãƒ¼ãƒ ç‰ˆï¼‰\n",
        "def run_phase2_training_last64():\n",
        "    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š\n",
        "    fixed_frames = 64  # å¾ŒåŠ64ãƒ•ãƒ¬ãƒ¼ãƒ \n",
        "    target_size = (64, 64)\n",
        "    latent_dim = 256\n",
        "    num_epochs = 50\n",
        "    batch_size = 6 if torch.cuda.is_available() else 3  # 64ãƒ•ãƒ¬ãƒ¼ãƒ ãªã®ã§å°‘ã—å°ã•ã\n",
        "    learning_rate = 1e-3\n",
        "    weight_decay = 1e-4\n",
        "    n_clusters = 5\n",
        "    \n",
        "    print(\"ğŸ”„ Creating dataset (last 64 frames)...\")\n",
        "    dataset = GrayScottDatasetLast64(GIF_FOLDER_PATH, fixed_frames, target_size)\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, \n",
        "                          num_workers=2, pin_memory=True)\n",
        "    \n",
        "    print(f\"ğŸ“Š Dataset: {len(dataset)} samples, Batch size: {batch_size}, Frames: {fixed_frames}\")\n",
        "    \n",
        "    print(\"ğŸ§  Creating Phase 2 model (64 frames)...\")\n",
        "    model = Conv3DAutoencoderPhase2Last64(latent_dim=latent_dim, \n",
        "                                         fixed_frames=fixed_frames, \n",
        "                                         target_size=target_size).to(device)\n",
        "    \n",
        "    print(f\"ğŸ“Š Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "    \n",
        "    # è¨“ç·´\n",
        "    print(\"ğŸ¯ Starting training with last 64 frames...\")\n",
        "    model.train()\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=1e-6)\n",
        "    \n",
        "    losses = []\n",
        "    start_time = time.time()\n",
        "    \n",
        "    print(f\"ğŸš€ Phase 2 GPU Training: ResNet + Attention (Last 64 Frames)\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        epoch_start_time = time.time()\n",
        "        epoch_loss = 0.0\n",
        "        \n",
        "        for batch_idx, batch in enumerate(dataloader):\n",
        "            tensors = batch['tensor'].to(device, non_blocking=True)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            reconstructed, latent = model(tensors)\n",
        "            loss = criterion(reconstructed, tensors)\n",
        "            loss.backward()\n",
        "            \n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5)\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "        \n",
        "        scheduler.step()\n",
        "        \n",
        "        avg_loss = epoch_loss / len(dataloader)\n",
        "        losses.append(avg_loss)\n",
        "        current_lr = scheduler.get_last_lr()[0]\n",
        "        epoch_time = time.time() - epoch_start_time\n",
        "        \n",
        "        # é€²æ—è¡¨ç¤º\n",
        "        progress = ((epoch + 1) / num_epochs) * 100\n",
        "        if (epoch + 1) % 5 == 0 or epoch < 5:\n",
        "            print(f'Epoch [{epoch+1:2d}/{num_epochs}] '\n",
        "                  f'({progress:5.1f}%) | '\n",
        "                  f'Loss: {avg_loss:.6f} | '\n",
        "                  f'LR: {current_lr:.2e} | '\n",
        "                  f'Time: {epoch_time:.1f}s')\n",
        "    \n",
        "    total_time = time.time() - start_time\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"ğŸ‰ Training completed in {total_time/60:.1f} minutes\")\n",
        "    \n",
        "    # å­¦ç¿’æ›²ç·šè¡¨ç¤º\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(losses, linewidth=2, color='purple')\n",
        "    plt.title('Phase 2: GPU Training Loss (ResNet + Attention, Last 64 Frames)', fontsize=14)\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.show()\n",
        "    \n",
        "    # æ½œåœ¨ãƒ™ã‚¯ãƒˆãƒ«æŠ½å‡º\n",
        "    print(\"ğŸ” Extracting latent vectors...\")\n",
        "    model.eval()\n",
        "    latent_vectors = []\n",
        "    f_values = []\n",
        "    k_values = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            tensors = batch['tensor'].to(device)\n",
        "            _, latent = model(tensors)\n",
        "            latent_vectors.append(latent.cpu().numpy())\n",
        "            f_values.extend(batch['f_value'].numpy())\n",
        "            k_values.extend(batch['k_value'].numpy())\n",
        "    \n",
        "    latent_vectors = np.vstack(latent_vectors)\n",
        "    f_values = np.array(f_values)\n",
        "    k_values = np.array(k_values)\n",
        "    \n",
        "    # ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°\n",
        "    print(\"ğŸ¯ Performing clustering...\")\n",
        "    scaler = StandardScaler()\n",
        "    latent_scaled = scaler.fit_transform(latent_vectors)\n",
        "    \n",
        "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
        "    cluster_labels = kmeans.fit_predict(latent_scaled)\n",
        "    \n",
        "    # æ€§èƒ½è©•ä¾¡\n",
        "    silhouette_avg = silhouette_score(latent_vectors, cluster_labels)\n",
        "    calinski_score = calinski_harabasz_score(latent_vectors, cluster_labels)\n",
        "    davies_bouldin = davies_bouldin_score(latent_vectors, cluster_labels)\n",
        "    \n",
        "    print(\"=\" * 80)\n",
        "    print(\"ğŸ† Phase 2 GPU Results Summary (Last 64 Frames):\")\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"ğŸ¯ Architecture: ResNet + SpatioTemporalAttention (GPU, Last 64 Frames)\")\n",
        "    print(f\"ğŸ“Š Samples: {len(dataset)}\")\n",
        "    print(f\"ğŸ¬ Frames per sample: {fixed_frames} (last frames)\")\n",
        "    print(f\"ğŸ§  Latent Dimension: {latent_dim}\")\n",
        "    print(f\"âš™ï¸  Model Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "    print(f\"ğŸ“‰ Final Loss: {losses[-1]:.6f}\")\n",
        "    print(f\"ğŸ¯ Clusters: {n_clusters}\")\n",
        "    print(f\"â­ Silhouette Score: {silhouette_avg:.4f}\")\n",
        "    print(f\"ğŸ“Š Calinski-Harabasz: {calinski_score:.2f}\")\n",
        "    print(f\"ğŸ“ˆ Davies-Bouldin: {davies_bouldin:.4f}\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    # Phase 1ã¨ã®æ¯”è¼ƒ\n",
        "    phase1_score = 0.565\n",
        "    improvement = ((silhouette_avg - phase1_score) / phase1_score) * 100\n",
        "    \n",
        "    print(f\"ğŸ“ˆ Performance Comparison:\")\n",
        "    print(f\"   Phase 1 (30 frames): {phase1_score:.4f}\")\n",
        "    print(f\"   Phase 2 (last 64 frames): {silhouette_avg:.4f}\")\n",
        "    print(f\"   Improvement: {improvement:+.1f}%\")\n",
        "    \n",
        "    if improvement >= 15:\n",
        "        print(\"ğŸ‰ Phase 2 ç›®æ¨™é”æˆï¼ (15%ä»¥ä¸Šã®å‘ä¸Š) - Last 64 frames strategy successful!\")\n",
        "    else:\n",
        "        print(f\"âš ï¸  Phase 2 ç›®æ¨™æœªé” ({improvement:.1f}% < 15%) - Consider further optimization\")\n",
        "    \n",
        "    return {\n",
        "        'model': model,\n",
        "        'losses': losses,\n",
        "        'silhouette_score': silhouette_avg,\n",
        "        'calinski_score': calinski_score,\n",
        "        'davies_bouldin': davies_bouldin,\n",
        "        'latent_vectors': latent_vectors,\n",
        "        'cluster_labels': cluster_labels,\n",
        "        'f_values': f_values,\n",
        "        'k_values': k_values,\n",
        "        'improvement': improvement,\n",
        "        'frames_used': 'last_64'\n",
        "    }\n",
        "\n",
        "# å®Ÿè¡Œ\n",
        "print(\"ğŸš€ Starting Phase 2 training with last 64 frames...\")\n",
        "results = run_phase2_training_last64()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ğŸ“¥ Step 4: çµæœä¿å­˜ãƒ»ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# çµæœä¿å­˜ã¨ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆLast 64 framesç‰ˆï¼‰\n",
        "import pickle\n",
        "from google.colab import files\n",
        "\n",
        "# çµæœã‚’Google Driveã«ä¿å­˜\n",
        "results_path = '/content/drive/MyDrive/GrayScottML/phase2_results_last64_gpu.pkl'\n",
        "model_path = '/content/drive/MyDrive/GrayScottML/phase2_model_last64_gpu.pth'\n",
        "\n",
        "# çµæœä¿å­˜\n",
        "with open(results_path, 'wb') as f:\n",
        "    # ãƒ¢ãƒ‡ãƒ«ã¯é™¤ã„ã¦ä¿å­˜ï¼ˆã‚µã‚¤ã‚ºå‰Šæ¸›ï¼‰\n",
        "    save_results = {k: v for k, v in results.items() if k != 'model'}\n",
        "    pickle.dump(save_results, f)\n",
        "\n",
        "# ãƒ¢ãƒ‡ãƒ«ä¿å­˜\n",
        "torch.save(results['model'].state_dict(), model_path)\n",
        "\n",
        "print(f\"ğŸ’¾ Results saved to Google Drive:\")\n",
        "print(f\"   ğŸ“Š Results: {results_path}\")\n",
        "print(f\"   ğŸ§  Model: {model_path}\")\n",
        "\n",
        "# ãƒ­ãƒ¼ã‚«ãƒ«ã«ã‚‚ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ç”¨ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ\n",
        "local_results_path = 'phase2_results_last64_gpu.pkl'\n",
        "local_model_path = 'phase2_model_last64_gpu.pth'\n",
        "\n",
        "with open(local_results_path, 'wb') as f:\n",
        "    save_results = {k: v for k, v in results.items() if k != 'model'}\n",
        "    pickle.dump(save_results, f)\n",
        "\n",
        "torch.save(results['model'].state_dict(), local_model_path)\n",
        "\n",
        "print(\"\\nğŸ“¥ Downloading files...\")\n",
        "files.download(local_results_path)\n",
        "files.download(local_model_path)\n",
        "\n",
        "print(\"âœ… Download completed!\")\n",
        "print(f\"ğŸ¯ Final Results (Last 64 Frames):\")\n",
        "print(f\"   â­ Silhouette Score: {results['silhouette_score']:.4f}\")\n",
        "print(f\"   ğŸ“ˆ Improvement: {results['improvement']:+.1f}%\")\n",
        "print(f\"   ğŸ¬ Strategy: Using last 64 frames for more stable patterns\")\n",
        "print(f\"   ğŸ† Target: {'âœ… ACHIEVED' if results['improvement'] >= 15 else 'âŒ NOT ACHIEVED'}\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ğŸ“Š Step 5: å¯è¦–åŒ–ãƒ»åˆ†æï¼ˆOptionalï¼‰\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# çµæœã®è©³ç´°å¯è¦–åŒ–ï¼ˆLast 64 framesï¼‰\n",
        "def visualize_results_last64(results):\n",
        "    latent_vectors = results['latent_vectors']\n",
        "    cluster_labels = results['cluster_labels']\n",
        "    f_values = results['f_values']\n",
        "    k_values = results['k_values']\n",
        "    \n",
        "    # PCAã¨t-SNEã«ã‚ˆã‚‹æ¬¡å…ƒå‰Šæ¸›\n",
        "    print(\"ğŸ” Performing dimensionality reduction...\")\n",
        "    pca = PCA(n_components=2, random_state=42)\n",
        "    pca_result = pca.fit_transform(latent_vectors)\n",
        "    \n",
        "    tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
        "    tsne_result = tsne.fit_transform(latent_vectors)\n",
        "    \n",
        "    # å¯è¦–åŒ–\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "    fig.suptitle('Phase 2 Results: Last 64 Frames Analysis', fontsize=16, fontweight='bold')\n",
        "    \n",
        "    # f-kç©ºé–“ã§ã®ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°çµæœ\n",
        "    scatter1 = axes[0, 0].scatter(f_values, k_values, c=cluster_labels, cmap='tab10', alpha=0.7, s=20)\n",
        "    axes[0, 0].set_xlabel('f parameter')\n",
        "    axes[0, 0].set_ylabel('k parameter')\n",
        "    axes[0, 0].set_title('Clustering Results in f-k Parameter Space')\n",
        "    axes[0, 0].invert_yaxis()\n",
        "    plt.colorbar(scatter1, ax=axes[0, 0], label='Cluster ID')\n",
        "    \n",
        "    # PCAçµæœ\n",
        "    scatter2 = axes[0, 1].scatter(pca_result[:, 0], pca_result[:, 1], c=cluster_labels, cmap='tab10', alpha=0.7, s=20)\n",
        "    axes[0, 1].set_title(f'PCA of Latent Space (Last 64 Frames)')\n",
        "    axes[0, 1].set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} variance)')\n",
        "    axes[0, 1].set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} variance)')\n",
        "    plt.colorbar(scatter2, ax=axes[0, 1], label='Cluster ID')\n",
        "    \n",
        "    # t-SNEçµæœ\n",
        "    scatter3 = axes[1, 0].scatter(tsne_result[:, 0], tsne_result[:, 1], c=cluster_labels, cmap='tab10', alpha=0.7, s=20)\n",
        "    axes[1, 0].set_title('t-SNE of Latent Space (Last 64 Frames)')\n",
        "    plt.colorbar(scatter3, ax=axes[1, 0], label='Cluster ID')\n",
        "    \n",
        "    # ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼çµ±è¨ˆ\n",
        "    axes[1, 1].axis('off')\n",
        "    n_clusters = len(np.unique(cluster_labels))\n",
        "    stats_text = f\"Last 64 Frames Analysis:\\\\n\\\\n\"\n",
        "    stats_text += f\"Silhouette Score: {results['silhouette_score']:.4f}\\\\n\"\n",
        "    stats_text += f\"Improvement: {results['improvement']:+.1f}%\\\\n\\\\n\"\n",
        "    \n",
        "    for i in range(n_clusters):\n",
        "        mask = cluster_labels == i\n",
        "        count = np.sum(mask)\n",
        "        f_mean = f_values[mask].mean()\n",
        "        k_mean = k_values[mask].mean()\n",
        "        stats_text += f\"Cluster {i}: {count} samples\\\\n\"\n",
        "        stats_text += f\"  f_avg: {f_mean:.4f}\\\\n\"\n",
        "        stats_text += f\"  k_avg: {k_mean:.4f}\\\\n\\\\n\"\n",
        "    \n",
        "    axes[1, 1].text(0.1, 0.9, stats_text, transform=axes[1, 1].transAxes, \n",
        "                    fontsize=10, verticalalignment='top', fontfamily='monospace')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"ğŸ“Š Visualization completed!\")\n",
        "    print(f\"ğŸ¬ Strategy: Last 64 frames captured more stable, mature patterns\")\n",
        "    print(f\"â­ Final Score: {results['silhouette_score']:.4f}\")\n",
        "\n",
        "# å¯è¦–åŒ–å®Ÿè¡Œ\n",
        "print(\"ğŸ¨ Creating visualizations...\")\n",
        "visualize_results_last64(results)\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Google Driveãƒ•ã‚©ãƒ«ãƒ€ç¢ºèªãƒ»ä½œæˆæ”¯æ´\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Google Driveã‚’ãƒã‚¦ãƒ³ãƒˆ\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ãƒ•ã‚©ãƒ«ãƒ€ãƒ‘ã‚¹è¨­å®šï¼ˆãƒã‚¤ãƒ‰ãƒ©ã‚¤ãƒ–å†…ï¼‰\n",
        "base_path = '/content/drive/MyDrive'\n",
        "project_folder = os.path.join(base_path, 'GrayScottML')\n",
        "gif_folder = os.path.join(project_folder, 'gif')\n",
        "\n",
        "# æ®µéšçš„ã«ãƒ•ã‚©ãƒ«ãƒ€ä½œæˆ\n",
        "try:\n",
        "    if not os.path.exists(project_folder):\n",
        "        os.makedirs(project_folder)\n",
        "        print(f\"âœ… Created: {project_folder}\")\n",
        "    else:\n",
        "        print(f\"âœ… Already exists: {project_folder}\")\n",
        "        \n",
        "    if not os.path.exists(gif_folder):\n",
        "        os.makedirs(gif_folder)\n",
        "        print(f\"âœ… Created: {gif_folder}\")\n",
        "    else:\n",
        "        print(f\"âœ… Already exists: {gif_folder}\")\n",
        "        \n",
        "    # ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆï¼ˆãƒ•ã‚©ãƒ«ãƒ€ãŒç¢ºå®Ÿã«å­˜åœ¨ã™ã‚‹ã“ã¨ã‚’ç¢ºèªï¼‰\n",
        "    test_file = os.path.join(project_folder, 'test.txt')\n",
        "    with open(test_file, 'w') as f:\n",
        "        f.write('GrayScott ML Project - Folder created successfully!')\n",
        "    \n",
        "    print(\"ğŸ‰ Folder structure created successfully!\")\n",
        "    print(\"ğŸ“ Structure:\")\n",
        "    print(f\"   {project_folder}\")\n",
        "    print(f\"   â””â”€â”€ {gif_folder}\")\n",
        "    print(f\"   â””â”€â”€ test.txt\")\n",
        "    \n",
        "    # Google Driveå´ã§ç¢ºèªã™ã‚‹ã‚ˆã†æ¡ˆå†…\n",
        "    print(\"\\nğŸ’¡ Please check your Google Drive:\")\n",
        "    print(\"   MyDrive > GrayScottML > gif (folder)\")\n",
        "    print(\"   MyDrive > GrayScottML > test.txt (file)\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"âŒ Error creating folders: {e}\")\n",
        "    print(\"Please try creating folders manually in Google Drive web interface\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ãƒ‘ã‚¹ç¢ºèªã¨ãƒ‡ãƒãƒƒã‚°\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Google Driveã‚’ãƒã‚¦ãƒ³ãƒˆ\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# è¤‡æ•°ã®ãƒ‘ã‚¹å€™è£œã‚’ç¢ºèª\n",
        "path_candidates = [\n",
        "    '/content/drive/MyDrive/GrayScottML/gif',           # ãƒã‚¤ãƒ‰ãƒ©ã‚¤ãƒ–å†…\n",
        "    '/content/drive/MyDrive/GrayScottML',               # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ•ã‚©ãƒ«ãƒ€\n",
        "    '/content/drive/GrayScottML/gif',                   # ãƒ«ãƒ¼ãƒˆç›´ä¸‹ï¼ˆã‚‚ã—ã‚ã‚Œã°ï¼‰\n",
        "]\n",
        "\n",
        "print(\"ğŸ” Searching for GrayScottML folder...\")\n",
        "found_path = None\n",
        "\n",
        "for path in path_candidates:\n",
        "    if os.path.exists(path):\n",
        "        print(f\"âœ… Found: {path}\")\n",
        "        if path.endswith('/gif'):\n",
        "            gif_count = len([f for f in os.listdir(path) if f.endswith('.gif')])\n",
        "            print(f\"   ğŸ“ GIF files: {gif_count}\")\n",
        "            if gif_count > 0:\n",
        "                found_path = path\n",
        "                break\n",
        "        else:\n",
        "            contents = os.listdir(path)\n",
        "            print(f\"   ğŸ“ Contents: {contents}\")\n",
        "            if 'gif' in contents:\n",
        "                gif_path = os.path.join(path, 'gif')\n",
        "                gif_count = len([f for f in os.listdir(gif_path) if f.endswith('.gif')])\n",
        "                print(f\"   ğŸ“ GIF files in gif/: {gif_count}\")\n",
        "                if gif_count > 0:\n",
        "                    found_path = gif_path\n",
        "                    break\n",
        "    else:\n",
        "        print(f\"âŒ Not found: {path}\")\n",
        "\n",
        "# ãƒã‚¤ãƒ‰ãƒ©ã‚¤ãƒ–ã®å†…å®¹ã‚’è¡¨ç¤º\n",
        "mydrive_path = '/content/drive/MyDrive'\n",
        "if os.path.exists(mydrive_path):\n",
        "    print(f\"\\nğŸ“‚ Contents of MyDrive:\")\n",
        "    for item in sorted(os.listdir(mydrive_path)):\n",
        "        item_path = os.path.join(mydrive_path, item)\n",
        "        if os.path.isdir(item_path):\n",
        "            print(f\"   ğŸ“ {item}\")\n",
        "        else:\n",
        "            print(f\"   ğŸ“„ {item}\")\n",
        "\n",
        "if found_path:\n",
        "    print(f\"\\nğŸ‰ Ready to use: {found_path}\")\n",
        "    # ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã¨ã—ã¦è¨­å®š\n",
        "    GIF_FOLDER_PATH = found_path\n",
        "    print(f\"ğŸ”— GIF_FOLDER_PATH = '{GIF_FOLDER_PATH}'\")\n",
        "else:\n",
        "    print(f\"\\nâš ï¸ GrayScottML folder not found. Please:\")\n",
        "    print(\"1. Create 'GrayScottML' folder in MyDrive\")\n",
        "    print(\"2. Create 'gif' subfolder inside GrayScottML\")\n",
        "    print(\"3. Upload 1500 GIF files to the gif folder\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
