{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸš€ Gray-Scott Phase 4: Last 64 Frames GPUç‰ˆï¼ˆGoogle Colabï¼‰\n",
    "\n",
    "**ç›®æ¨™**: å¾ŒåŠ64ãƒ•ãƒ¬ãƒ¼ãƒ ã®ã¿ã‚’ä½¿ç”¨ã—ãŸå­¦ç¿’ã§Phase 1 (0.565) â†’ Phase 4 (0.65+) ã¸ã®ã•ã‚‰ãªã‚‹å‘ä¸Š\n",
    "\n",
    "**ä¸»è¦æ”¹å–„ç‚¹**:\n",
    "- âœ… æ®‹å·®æ¥ç¶šï¼ˆResNetï¼‰+ æ™‚ç©ºé–“æ³¨æ„æ©Ÿæ§‹\n",
    "- âœ… GPUé«˜é€ŸåŒ–ï¼ˆCPUæ¯” 5-10å€ï¼‰\n",
    "- âœ… Google Driveé€£æº\n",
    "- âœ… **å¾ŒåŠ64ãƒ•ãƒ¬ãƒ¼ãƒ ã®ã¿ã‚’ä½¿ç”¨** - ã‚ˆã‚Šå®‰å®šã—ãŸå¾ŒæœŸãƒ‘ã‚¿ãƒ¼ãƒ³ã«ç„¦ç‚¹\n",
    "\n",
    "**å‰ææ¡ä»¶**: Google Driveã®`ãƒã‚¤ãƒ‰ãƒ©ã‚¤ãƒ–/GrayScottML/gif/`ã«1500å€‹ã®GIFãƒ•ã‚¡ã‚¤ãƒ«ã‚’é…ç½®\n",
    "\n",
    "**å®Ÿè¡Œæ™‚é–“**: **GPU 3-5åˆ†** ğŸƒâ€â™‚ï¸ğŸ’¨\n",
    "\n",
    "## æ›´æ–°å±¥æ­´\n",
    "- 2025-08-11: Data augmentationï¼ˆå¹³è¡Œç§»å‹•ãƒ»90/180/270åº¦å›è»¢ãƒ»æ°´å¹³/å‚ç›´åè»¢ï¼‰ã‚’å°å…¥ã€‚\n",
    "  - å­¦ç¿’: GrayScottDatasetLast64Aug(augment=True) ã§ã‚ªãƒ³ã‚¶ãƒ•ãƒ©ã‚¤é©ç”¨\n",
    "  - è©•ä¾¡/æ½œåœ¨ãƒ™ã‚¯ãƒˆãƒ«æŠ½å‡º: augment=False ã§ãƒ‡ãƒ¼ã‚¿åˆ†å¸ƒã‚’å›ºå®š\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“‹ Step 1: ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ— & Google Driveæ¥ç¶š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick run mode: use only first N GIF files\n",
    "QUICK_RUN = True\n",
    "max_samples = 20 if QUICK_RUN else None\n",
    "print('Quick run max_samples =', max_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedded Phase 4 model code (no external src import needed)\n",
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Gray-Scott 3D CNN Autoencoder - Phase 4: å¯¾æ¯”å­¦ç¿’ãƒ»è©•ä¾¡æ”¹å–„\n",
    "ç›®æ¨™: Phase 3 (0.5144) â†’ Phase 4 (0.55+) ã¸ã®æ›´ãªã‚‹å‘ä¸Š\n",
    "\n",
    "ä¸»è¦æ”¹å–„ç‚¹:\n",
    "- å¯¾æ¯”å­¦ç¿’ï¼ˆContrastive Learningï¼‰\n",
    "- éšå±¤çš„ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°åˆ†æ\n",
    "- åŒ…æ‹¬çš„è©•ä¾¡æŒ‡æ¨™\n",
    "- æ”¹å–„ã•ã‚ŒãŸè¨“ç·´ãƒ«ãƒ¼ãƒ—\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import imageio.v2 as imageio\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import pickle\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# GPUè¨­å®š\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"ğŸš€ Phase 4 Using device: {device}\")\n",
    "\n",
    "# ================================\n",
    "# 1. å¯¾æ¯”å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ \n",
    "# ================================\n",
    "\n",
    "class ContrastiveLoss(nn.Module):\n",
    "    \"\"\"f-kãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿é¡ä¼¼æ€§ã«åŸºã¥ãå¯¾æ¯”å­¦ç¿’æå¤±\"\"\"\n",
    "    \n",
    "    def __init__(self, temperature=0.5, margin=1.0):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        self.margin = margin\n",
    "        self.cosine_similarity = nn.CosineSimilarity(dim=2)\n",
    "    \n",
    "    def forward(self, features, f_params, k_params):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            features: (batch_size, feature_dim) - æ½œåœ¨è¡¨ç¾\n",
    "            f_params: (batch_size,) - fãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿\n",
    "            k_params: (batch_size,) - kãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿\n",
    "        \"\"\"\n",
    "        batch_size = features.size(0)\n",
    "        \n",
    "        # f-kãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç©ºé–“ã§ã®é¡ä¼¼æ€§è¨ˆç®—\n",
    "        f_diff = torch.abs(f_params.unsqueeze(1) - f_params.unsqueeze(0))\n",
    "        k_diff = torch.abs(k_params.unsqueeze(1) - k_params.unsqueeze(0))\n",
    "        \n",
    "        # æ­£è¦åŒ–ã•ã‚ŒãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è·é›¢\n",
    "        param_distance = torch.sqrt(f_diff**2 + k_diff**2)\n",
    "        \n",
    "        # é¡ä¼¼æ€§é–¾å€¤ï¼ˆè¿‘ã„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯é¡ä¼¼ã€é ã„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯éé¡ä¼¼ï¼‰\n",
    "        similarity_threshold = 0.01  # f-kç©ºé–“ã§ã®é–¾å€¤\n",
    "        positive_mask = param_distance < similarity_threshold\n",
    "        negative_mask = param_distance > similarity_threshold * 3\n",
    "        \n",
    "        # ç‰¹å¾´é‡ã®é¡ä¼¼æ€§è¨ˆç®—\n",
    "        features_norm = F.normalize(features, p=2, dim=1)\n",
    "        similarity_matrix = torch.mm(features_norm, features_norm.t()) / self.temperature\n",
    "        \n",
    "        # å¯¾æ¯”å­¦ç¿’æå¤±\n",
    "        positive_loss = 0\n",
    "        negative_loss = 0\n",
    "        \n",
    "        if positive_mask.sum() > 0:\n",
    "            positive_sim = similarity_matrix[positive_mask]\n",
    "            positive_loss = -torch.log(torch.exp(positive_sim).sum() / torch.exp(similarity_matrix).sum())\n",
    "        \n",
    "        if negative_mask.sum() > 0:\n",
    "            negative_sim = similarity_matrix[negative_mask]\n",
    "            negative_loss = torch.log(torch.exp(negative_sim).sum() / torch.exp(similarity_matrix).sum())\n",
    "        \n",
    "        contrastive_loss = positive_loss + negative_loss\n",
    "        \n",
    "        return contrastive_loss\n",
    "\n",
    "class ProjectionHead(nn.Module):\n",
    "    \"\"\"å¯¾æ¯”å­¦ç¿’ç”¨å°„å½±ãƒ˜ãƒƒãƒ‰\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim=512, hidden_dim=256, output_dim=128):\n",
    "        super().__init__()\n",
    "        self.projection = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden_dim, output_dim),\n",
    "            nn.BatchNorm1d(output_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.projection(x)\n",
    "\n",
    "# ================================\n",
    "# 2. éšå±¤çš„ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°åˆ†æ\n",
    "# ================================\n",
    "\n",
    "class HierarchicalClusteringAnalysis:\n",
    "    \"\"\"éšå±¤çš„ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°åˆ†æã‚·ã‚¹ãƒ†ãƒ \"\"\"\n",
    "    \n",
    "    def __init__(self, method='ward', metric='euclidean'):\n",
    "        self.method = method\n",
    "        self.metric = metric\n",
    "        self.linkage_matrix = None\n",
    "        self.optimal_clusters = None\n",
    "    \n",
    "    def fit(self, features):\n",
    "        \"\"\"éšå±¤çš„ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°å®Ÿè¡Œ\"\"\"\n",
    "        # ç‰¹å¾´é‡ã®æ¨™æº–åŒ–\n",
    "        scaler = StandardScaler()\n",
    "        features_scaled = scaler.fit_transform(features)\n",
    "        \n",
    "        # éšå±¤çš„ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°\n",
    "        self.linkage_matrix = linkage(features_scaled, method=self.method, metric=self.metric)\n",
    "        \n",
    "        # æœ€é©ã‚¯ãƒ©ã‚¹ã‚¿æ•°ã®æ±ºå®š\n",
    "        self.optimal_clusters = self._find_optimal_clusters(features_scaled)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def _find_optimal_clusters(self, features, max_clusters=20):\n",
    "        \"\"\"æœ€é©ã‚¯ãƒ©ã‚¹ã‚¿æ•°ã®è‡ªå‹•æ±ºå®š\"\"\"\n",
    "        silhouette_scores = []\n",
    "        cluster_range = range(2, min(max_clusters + 1, len(features) // 2))\n",
    "        \n",
    "        for n_clusters in cluster_range:\n",
    "            cluster_labels = fcluster(self.linkage_matrix, n_clusters, criterion='maxclust')\n",
    "            \n",
    "            if len(np.unique(cluster_labels)) > 1:\n",
    "                silhouette_avg = silhouette_score(features, cluster_labels)\n",
    "                silhouette_scores.append(silhouette_avg)\n",
    "            else:\n",
    "                silhouette_scores.append(-1)\n",
    "        \n",
    "        if silhouette_scores:\n",
    "            optimal_idx = np.argmax(silhouette_scores)\n",
    "            optimal_n_clusters = cluster_range[optimal_idx]\n",
    "            return optimal_n_clusters\n",
    "        else:\n",
    "            return 2\n",
    "    \n",
    "    def get_cluster_labels(self, n_clusters=None):\n",
    "        \"\"\"ã‚¯ãƒ©ã‚¹ã‚¿ãƒ©ãƒ™ãƒ«ã®å–å¾—\"\"\"\n",
    "        if n_clusters is None:\n",
    "            n_clusters = self.optimal_clusters\n",
    "        \n",
    "        return fcluster(self.linkage_matrix, n_clusters, criterion='maxclust')\n",
    "    \n",
    "    def plot_dendrogram(self, figsize=(12, 8)):\n",
    "        \"\"\"ãƒ‡ãƒ³ãƒ‰ãƒ­ã‚°ãƒ©ãƒ å¯è¦–åŒ–\"\"\"\n",
    "        plt.figure(figsize=figsize)\n",
    "        dendrogram(self.linkage_matrix, truncate_mode='level', p=10)\n",
    "        plt.title('Hierarchical Clustering Dendrogram')\n",
    "        plt.xlabel('Sample Index')\n",
    "        plt.ylabel('Distance')\n",
    "        plt.show()\n",
    "\n",
    "# ================================\n",
    "# 3. åŒ…æ‹¬çš„è©•ä¾¡æŒ‡æ¨™\n",
    "# ================================\n",
    "\n",
    "class ComprehensiveEvaluationMetrics:\n",
    "    \"\"\"åŒ…æ‹¬çš„è©•ä¾¡æŒ‡æ¨™ã‚·ã‚¹ãƒ†ãƒ \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.metrics = {}\n",
    "    \n",
    "    def calculate_all_metrics(self, features, labels, f_params=None, k_params=None):\n",
    "        \"\"\"å…¨ã¦ã®è©•ä¾¡æŒ‡æ¨™ã‚’è¨ˆç®—\"\"\"\n",
    "        \n",
    "        # åŸºæœ¬ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°æŒ‡æ¨™\n",
    "        self.metrics['silhouette_score'] = silhouette_score(features, labels)\n",
    "        self.metrics['calinski_harabasz_score'] = calinski_harabasz_score(features, labels)\n",
    "        self.metrics['davies_bouldin_score'] = davies_bouldin_score(features, labels)\n",
    "        \n",
    "        # è¿‘å‚ä¸€è‡´åº¦æŒ‡æ¨™\n",
    "        self.metrics['neighborhood_agreement'] = self._calculate_neighborhood_agreement(features, labels)\n",
    "        \n",
    "        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç©ºé–“åˆ†é›¢åº¦è©•ä¾¡\n",
    "        if f_params is not None and k_params is not None:\n",
    "            self.metrics['parameter_separation'] = self._calculate_parameter_separation(\n",
    "                features, labels, f_params, k_params\n",
    "            )\n",
    "        \n",
    "        # ã‚¯ãƒ©ã‚¹ã‚¿å†…åˆ†æ•£ãƒ»ã‚¯ãƒ©ã‚¹ã‚¿é–“åˆ†æ•£\n",
    "        self.metrics['within_cluster_variance'] = self._calculate_within_cluster_variance(features, labels)\n",
    "        self.metrics['between_cluster_variance'] = self._calculate_between_cluster_variance(features, labels)\n",
    "        \n",
    "        # å®‰å®šæ€§æŒ‡æ¨™\n",
    "        self.metrics['cluster_stability'] = self._calculate_cluster_stability(features, labels)\n",
    "        \n",
    "        return self.metrics\n",
    "    \n",
    "    def _calculate_neighborhood_agreement(self, features, labels, k=10):\n",
    "        \"\"\"è¿‘å‚ä¸€è‡´åº¦ã®è¨ˆç®—\"\"\"\n",
    "        from sklearn.neighbors import NearestNeighbors\n",
    "        \n",
    "        nbrs = NearestNeighbors(n_neighbors=k+1).fit(features)\n",
    "        distances, indices = nbrs.kneighbors(features)\n",
    "        \n",
    "        agreements = []\n",
    "        for i in range(len(features)):\n",
    "            neighbor_labels = labels[indices[i][1:]]  # è‡ªåˆ†ä»¥å¤–ã®è¿‘å‚\n",
    "            same_cluster = np.sum(neighbor_labels == labels[i])\n",
    "            agreement = same_cluster / k\n",
    "            agreements.append(agreement)\n",
    "        \n",
    "        return np.mean(agreements)\n",
    "    \n",
    "    def _calculate_parameter_separation(self, features, labels, f_params, k_params):\n",
    "        \"\"\"ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç©ºé–“åˆ†é›¢åº¦ã®è¨ˆç®—\"\"\"\n",
    "        unique_labels = np.unique(labels)\n",
    "        separations = []\n",
    "        \n",
    "        for label in unique_labels:\n",
    "            mask = labels == label\n",
    "            if np.sum(mask) > 1:\n",
    "                cluster_f = f_params[mask]\n",
    "                cluster_k = k_params[mask]\n",
    "                \n",
    "                # ã‚¯ãƒ©ã‚¹ã‚¿å†…ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åˆ†æ•£\n",
    "                f_var = np.var(cluster_f)\n",
    "                k_var = np.var(cluster_k)\n",
    "                cluster_variance = f_var + k_var\n",
    "                \n",
    "                separations.append(cluster_variance)\n",
    "        \n",
    "        return np.mean(separations) if separations else 0\n",
    "    \n",
    "    def _calculate_within_cluster_variance(self, features, labels):\n",
    "        \"\"\"ã‚¯ãƒ©ã‚¹ã‚¿å†…åˆ†æ•£ã®è¨ˆç®—\"\"\"\n",
    "        unique_labels = np.unique(labels)\n",
    "        within_variances = []\n",
    "        \n",
    "        for label in unique_labels:\n",
    "            mask = labels == label\n",
    "            if np.sum(mask) > 1:\n",
    "                cluster_features = features[mask]\n",
    "                centroid = np.mean(cluster_features, axis=0)\n",
    "                variance = np.mean(np.sum((cluster_features - centroid)**2, axis=1))\n",
    "                within_variances.append(variance)\n",
    "        \n",
    "        return np.mean(within_variances) if within_variances else 0\n",
    "    \n",
    "    def _calculate_between_cluster_variance(self, features, labels):\n",
    "        \"\"\"ã‚¯ãƒ©ã‚¹ã‚¿é–“åˆ†æ•£ã®è¨ˆç®—\"\"\"\n",
    "        unique_labels = np.unique(labels)\n",
    "        centroids = []\n",
    "        \n",
    "        for label in unique_labels:\n",
    "            mask = labels == label\n",
    "            centroid = np.mean(features[mask], axis=0)\n",
    "            centroids.append(centroid)\n",
    "        \n",
    "        centroids = np.array(centroids)\n",
    "        overall_centroid = np.mean(centroids, axis=0)\n",
    "        \n",
    "        between_variance = np.mean(np.sum((centroids - overall_centroid)**2, axis=1))\n",
    "        return between_variance\n",
    "    \n",
    "    def _calculate_cluster_stability(self, features, labels, n_bootstrap=10):\n",
    "        \"\"\"ã‚¯ãƒ©ã‚¹ã‚¿å®‰å®šæ€§ã®è¨ˆç®—\"\"\"\n",
    "        from sklearn.utils import resample\n",
    "        \n",
    "        original_labels = labels\n",
    "        stability_scores = []\n",
    "        \n",
    "        for _ in range(n_bootstrap):\n",
    "            # ãƒ–ãƒ¼ãƒˆã‚¹ãƒˆãƒ©ãƒƒãƒ—ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°\n",
    "            bootstrap_indices = resample(range(len(features)), n_samples=len(features))\n",
    "            bootstrap_features = features[bootstrap_indices]\n",
    "            bootstrap_labels = labels[bootstrap_indices]\n",
    "            \n",
    "            # ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°å®Ÿè¡Œ\n",
    "            kmeans = KMeans(n_clusters=len(np.unique(original_labels)), random_state=42)\n",
    "            new_labels = kmeans.fit_predict(bootstrap_features)\n",
    "            \n",
    "            # ãƒ©ãƒ™ãƒ«ä¸€è‡´åº¦è¨ˆç®—ï¼ˆãƒãƒ³ã‚¬ãƒªã‚¢ãƒ³ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ç°¡æ˜“ç‰ˆï¼‰\n",
    "            agreement = self._calculate_label_agreement(bootstrap_labels, new_labels)\n",
    "            stability_scores.append(agreement)\n",
    "        \n",
    "        return np.mean(stability_scores)\n",
    "    \n",
    "    def _calculate_label_agreement(self, labels1, labels2):\n",
    "        \"\"\"ãƒ©ãƒ™ãƒ«ä¸€è‡´åº¦ã®è¨ˆç®—\"\"\"\n",
    "        from scipy.optimize import linear_sum_assignment\n",
    "        \n",
    "        unique_labels1 = np.unique(labels1)\n",
    "        unique_labels2 = np.unique(labels2)\n",
    "        \n",
    "        # æ··åŒè¡Œåˆ—ä½œæˆ\n",
    "        confusion_matrix = np.zeros((len(unique_labels1), len(unique_labels2)))\n",
    "        \n",
    "        for i, label1 in enumerate(unique_labels1):\n",
    "            for j, label2 in enumerate(unique_labels2):\n",
    "                confusion_matrix[i, j] = np.sum((labels1 == label1) & (labels2 == label2))\n",
    "        \n",
    "        # ãƒãƒ³ã‚¬ãƒªã‚¢ãƒ³ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã§æœ€é©å‰²ã‚Šå½“ã¦\n",
    "        row_ind, col_ind = linear_sum_assignment(-confusion_matrix)\n",
    "        \n",
    "        # ä¸€è‡´åº¦è¨ˆç®—\n",
    "        agreement = confusion_matrix[row_ind, col_ind].sum() / len(labels1)\n",
    "        return agreement\n",
    "    \n",
    "    def print_metrics(self):\n",
    "        \"\"\"è©•ä¾¡æŒ‡æ¨™ã®è¡¨ç¤º\"\"\"\n",
    "        print(\"\\nğŸ¯ Phase 4 åŒ…æ‹¬çš„è©•ä¾¡æŒ‡æ¨™\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        # åŸºæœ¬æŒ‡æ¨™\n",
    "        print(f\"Silhouette Score: {self.metrics.get('silhouette_score', 0):.4f}\")\n",
    "        print(f\"Calinski-Harabasz: {self.metrics.get('calinski_harabasz_score', 0):.2f}\")\n",
    "        print(f\"Davies-Bouldin: {self.metrics.get('davies_bouldin_score', 0):.4f}\")\n",
    "        \n",
    "        # é«˜åº¦ãªæŒ‡æ¨™\n",
    "        print(f\"Neighborhood Agreement: {self.metrics.get('neighborhood_agreement', 0):.4f}\")\n",
    "        print(f\"Parameter Separation: {self.metrics.get('parameter_separation', 0):.4f}\")\n",
    "        print(f\"Within Cluster Variance: {self.metrics.get('within_cluster_variance', 0):.4f}\")\n",
    "        print(f\"Between Cluster Variance: {self.metrics.get('between_cluster_variance', 0):.4f}\")\n",
    "        print(f\"Cluster Stability: {self.metrics.get('cluster_stability', 0):.4f}\")\n",
    "\n",
    "# ================================\n",
    "# 4. Phase 3ãƒ™ãƒ¼ã‚¹ã®ãƒ¢ãƒ‡ãƒ«æ‹¡å¼µ\n",
    "# ================================\n",
    "\n",
    "class GrayScottAugmentation:\n",
    "    \"\"\"Gray-Scottå°‚ç”¨ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã‚¯ãƒ©ã‚¹ï¼ˆPhase 3ã‹ã‚‰ç¶™æ‰¿ï¼‰\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 temporal_shift_prob=0.3,\n",
    "                 spatial_flip_prob=0.5,\n",
    "                 noise_prob=0.2,\n",
    "                 intensity_prob=0.3,\n",
    "                 temporal_crop_prob=0.2):\n",
    "        self.temporal_shift_prob = temporal_shift_prob\n",
    "        self.spatial_flip_prob = spatial_flip_prob\n",
    "        self.noise_prob = noise_prob\n",
    "        self.intensity_prob = intensity_prob\n",
    "        self.temporal_crop_prob = temporal_crop_prob\n",
    "    \n",
    "    def temporal_shift(self, tensor, max_shift=3):\n",
    "        \"\"\"æ™‚é–“è»¸ã‚·ãƒ•ãƒˆ\"\"\"\n",
    "        if np.random.random() < self.temporal_shift_prob:\n",
    "            shift = np.random.randint(-max_shift, max_shift + 1)\n",
    "            if shift != 0:\n",
    "                tensor = torch.roll(tensor, shift, dims=1)\n",
    "        return tensor\n",
    "    \n",
    "    def spatial_flip(self, tensor):\n",
    "        \"\"\"ç©ºé–“è»¸åè»¢\"\"\"\n",
    "        if np.random.random() < self.spatial_flip_prob:\n",
    "            if np.random.random() < 0.5:\n",
    "                tensor = torch.flip(tensor, dims=[3])\n",
    "            if np.random.random() < 0.5:\n",
    "                tensor = torch.flip(tensor, dims=[2])\n",
    "        return tensor\n",
    "    \n",
    "    def add_noise(self, tensor, noise_std=0.02):\n",
    "        \"\"\"ã‚¬ã‚¦ã‚·ã‚¢ãƒ³ãƒã‚¤ã‚ºè¿½åŠ \"\"\"\n",
    "        if np.random.random() < self.noise_prob:\n",
    "            noise = torch.randn_like(tensor) * noise_std\n",
    "            tensor = torch.clamp(tensor + noise, 0, 1)\n",
    "        return tensor\n",
    "    \n",
    "    def intensity_transform(self, tensor, gamma_range=(0.8, 1.2)):\n",
    "        \"\"\"å¼·åº¦å¤‰æ›\"\"\"\n",
    "        if np.random.random() < self.intensity_prob:\n",
    "            gamma = np.random.uniform(*gamma_range)\n",
    "            tensor = torch.pow(tensor, gamma)\n",
    "        return tensor\n",
    "    \n",
    "    def temporal_crop(self, tensor, crop_ratio=0.1):\n",
    "        \"\"\"æ™‚é–“è»¸ã‚¯ãƒ­ãƒƒãƒ—\"\"\"\n",
    "        if np.random.random() < self.temporal_crop_prob:\n",
    "            T = tensor.shape[1]\n",
    "            crop_size = int(T * crop_ratio)\n",
    "            start_idx = np.random.randint(0, crop_size + 1)\n",
    "            end_idx = T - np.random.randint(0, crop_size + 1)\n",
    "            \n",
    "            cropped = tensor[:, start_idx:end_idx]\n",
    "            tensor = F.interpolate(cropped.unsqueeze(0), size=(T, tensor.shape[2], tensor.shape[3]), \n",
    "                                 mode='trilinear', align_corners=False).squeeze(0)\n",
    "        return tensor\n",
    "    \n",
    "    def __call__(self, tensor):\n",
    "        \"\"\"å…¨ã¦ã®æ‹¡å¼µã‚’é©ç”¨\"\"\"\n",
    "        tensor = self.temporal_shift(tensor)\n",
    "        tensor = self.spatial_flip(tensor)\n",
    "        tensor = self.add_noise(tensor)\n",
    "        tensor = self.intensity_transform(tensor)\n",
    "        tensor = self.temporal_crop(tensor)\n",
    "        return tensor\n",
    "\n",
    "class MultiScaleFeatureFusion(nn.Module):\n",
    "    \"\"\"ãƒãƒ«ãƒã‚¹ã‚±ãƒ¼ãƒ«ç‰¹å¾´èåˆï¼ˆPhase 3ã‹ã‚‰ç¶™æ‰¿ï¼‰\"\"\"\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 4ã¤ã®ç•°ãªã‚‹ã‚¹ã‚±ãƒ¼ãƒ«ã§ã®ç‰¹å¾´æŠ½å‡º\n",
    "        self.scale1 = nn.Conv3d(in_channels, out_channels // 4, kernel_size=1, padding=0)  # Point-wise\n",
    "        self.scale2 = nn.Conv3d(in_channels, out_channels // 4, kernel_size=3, padding=1)  # Local\n",
    "        self.scale3 = nn.Conv3d(in_channels, out_channels // 4, kernel_size=5, padding=2)  # Global\n",
    "        \n",
    "        # ãƒ—ãƒ¼ãƒªãƒ³ã‚°ãƒ™ãƒ¼ã‚¹ã®ç‰¹å¾´\n",
    "        self.pool = nn.AdaptiveAvgPool3d(1)\n",
    "        self.scale4 = nn.Conv3d(in_channels, out_channels // 4, kernel_size=1)\n",
    "        \n",
    "        self.bn = nn.BatchNorm3d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # å„ã‚¹ã‚±ãƒ¼ãƒ«ã§ç‰¹å¾´æŠ½å‡º\n",
    "        feat1 = self.scale1(x)\n",
    "        feat2 = self.scale2(x)\n",
    "        feat3 = self.scale3(x)\n",
    "        \n",
    "        # ãƒ—ãƒ¼ãƒªãƒ³ã‚°ç‰¹å¾´\n",
    "        pooled = self.pool(x)\n",
    "        feat4 = self.scale4(pooled)\n",
    "        feat4 = feat4.expand_as(feat1)\n",
    "        \n",
    "        # ç‰¹å¾´èåˆ\n",
    "        fused = torch.cat([feat1, feat2, feat3, feat4], dim=1)\n",
    "        fused = self.bn(fused)\n",
    "        fused = self.relu(fused)\n",
    "        \n",
    "        return fused\n",
    "\n",
    "class EnhancedSpatioTemporalAttention(nn.Module):\n",
    "    \"\"\"æ”¹è‰¯æ™‚ç©ºé–“æ³¨æ„æ©Ÿæ§‹ï¼ˆPhase 3ã‹ã‚‰ç¶™æ‰¿ï¼‰\"\"\"\n",
    "    \n",
    "    def __init__(self, in_channels, reduction=16):\n",
    "        super().__init__()\n",
    "        \n",
    "        # æ™‚é–“æ³¨æ„\n",
    "        self.temporal_attention = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool3d((None, 1, 1)),\n",
    "            nn.Conv3d(in_channels, in_channels // reduction, kernel_size=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(in_channels // reduction, in_channels, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # ç©ºé–“æ³¨æ„\n",
    "        self.spatial_attention = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool3d((1, None, None)),\n",
    "            nn.Conv3d(in_channels, in_channels // reduction, kernel_size=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(in_channels // reduction, in_channels, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # ãƒãƒ£ãƒãƒ«æ³¨æ„\n",
    "        self.channel_attention = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool3d(1),\n",
    "            nn.Conv3d(in_channels, in_channels // reduction, kernel_size=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(in_channels // reduction, in_channels, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # å„æ³¨æ„æ©Ÿæ§‹ã‚’é©ç”¨\n",
    "        temp_att = self.temporal_attention(x)\n",
    "        spat_att = self.spatial_attention(x)\n",
    "        chan_att = self.channel_attention(x)\n",
    "        \n",
    "        # æ³¨æ„é‡ã¿ã‚’é©ç”¨\n",
    "        x = x * temp_att * spat_att * chan_att\n",
    "        \n",
    "        return x\n",
    "\n",
    "class ResidualMultiScaleBlock3D(nn.Module):\n",
    "    \"\"\"æ®‹å·®ãƒãƒ«ãƒã‚¹ã‚±ãƒ¼ãƒ«ãƒ–ãƒ­ãƒƒã‚¯ï¼ˆPhase 3ã‹ã‚‰ç¶™æ‰¿ï¼‰\"\"\"\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.multi_scale = MultiScaleFeatureFusion(in_channels, out_channels)\n",
    "        self.attention = EnhancedSpatioTemporalAttention(out_channels)\n",
    "        \n",
    "        # æ®‹å·®æ¥ç¶šç”¨\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv3d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm3d(out_channels)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        residual = self.shortcut(x)\n",
    "        \n",
    "        out = self.multi_scale(x)\n",
    "        out = self.attention(out)\n",
    "        \n",
    "        out += residual\n",
    "        return out\n",
    "\n",
    "class Conv3DAutoencoderPhase4(nn.Module):\n",
    "    \"\"\"Phase 4: å¯¾æ¯”å­¦ç¿’çµ±åˆã‚ªãƒ¼ãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼\"\"\"\n",
    "    \n",
    "    def __init__(self, latent_dim=512, input_shape=(20, 64, 64)):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.latent_dim = latent_dim\n",
    "        self.input_shape = input_shape\n",
    "        \n",
    "        # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼\n",
    "        self.encoder = nn.Sequential(\n",
    "            # å…¥åŠ›: (1, 20, 64, 64)\n",
    "            ResidualMultiScaleBlock3D(1, 32),\n",
    "            nn.MaxPool3d(2),  # (32, 10, 32, 32)\n",
    "            \n",
    "            ResidualMultiScaleBlock3D(32, 64),\n",
    "            nn.MaxPool3d(2),  # (64, 5, 16, 16)\n",
    "            \n",
    "            ResidualMultiScaleBlock3D(64, 128),\n",
    "            nn.MaxPool3d(2),  # (128, 2, 8, 8)\n",
    "            \n",
    "            ResidualMultiScaleBlock3D(128, 256),\n",
    "            nn.AdaptiveAvgPool3d(1),  # (256, 1, 1, 1)\n",
    "        )\n",
    "        \n",
    "        # æ½œåœ¨ç©ºé–“\n",
    "        self.fc_encoder = nn.Sequential(\n",
    "            nn.Linear(256, latent_dim),\n",
    "            nn.BatchNorm1d(latent_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        \n",
    "        # å¯¾æ¯”å­¦ç¿’ç”¨å°„å½±ãƒ˜ãƒƒãƒ‰\n",
    "        self.projection_head = ProjectionHead(latent_dim, 256, 128)\n",
    "        \n",
    "        # ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼\n",
    "        self.fc_decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        \n",
    "        # ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼ã‚’å€‹åˆ¥ã®ãƒ¬ã‚¤ãƒ¤ãƒ¼ã¨ã—ã¦å®šç¾©ï¼ˆã‚µã‚¤ã‚ºèª¿æ•´ä»˜ãï¼‰\n",
    "        self.decoder_conv1 = nn.ConvTranspose3d(256, 128, kernel_size=(3, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1))\n",
    "        self.decoder_bn1 = nn.BatchNorm3d(128)\n",
    "        \n",
    "        self.decoder_conv2 = nn.ConvTranspose3d(128, 64, kernel_size=(3, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1))\n",
    "        self.decoder_bn2 = nn.BatchNorm3d(64)\n",
    "        \n",
    "        self.decoder_conv3 = nn.ConvTranspose3d(64, 32, kernel_size=(3, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1))\n",
    "        self.decoder_bn3 = nn.BatchNorm3d(32)\n",
    "        \n",
    "        self.decoder_conv4 = nn.ConvTranspose3d(32, 1, kernel_size=(3, 4, 4), stride=(2, 2, 2), padding=(1, 1, 1))\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def encode(self, x):\n",
    "        \"\"\"ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰\"\"\"\n",
    "        x = self.encoder(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        latent = self.fc_encoder(x)\n",
    "        return latent\n",
    "    \n",
    "    def decode(self, latent):\n",
    "        \"\"\"ãƒ‡ã‚³ãƒ¼ãƒ‰ï¼ˆã‚µã‚¤ã‚ºèª¿æ•´ä»˜ãï¼‰\"\"\"\n",
    "        x = self.fc_decoder(latent)\n",
    "        x = x.view(x.size(0), 256, 1, 1, 1)\n",
    "        \n",
    "        # æ®µéšçš„ã«ãƒ‡ã‚³ãƒ¼ãƒ‰ï¼ˆå„ã‚¹ãƒ†ãƒƒãƒ—ã§ã‚µã‚¤ã‚ºã‚’èª¿æ•´ï¼‰\n",
    "        # (256, 1, 1, 1) -> (128, 2, 8, 8)\n",
    "        x = self.decoder_conv1(x)\n",
    "        x = self.decoder_bn1(x)\n",
    "        x = self.relu(x)\n",
    "        # ã‚µã‚¤ã‚ºèª¿æ•´\n",
    "        x = F.interpolate(x, size=(2, 8, 8), mode='trilinear', align_corners=False)\n",
    "        \n",
    "        # (128, 2, 8, 8) -> (64, 5, 16, 16)\n",
    "        x = self.decoder_conv2(x)\n",
    "        x = self.decoder_bn2(x)\n",
    "        x = self.relu(x)\n",
    "        # ã‚µã‚¤ã‚ºèª¿æ•´\n",
    "        x = F.interpolate(x, size=(5, 16, 16), mode='trilinear', align_corners=False)\n",
    "        \n",
    "        # (64, 5, 16, 16) -> (32, 10, 32, 32)\n",
    "        x = self.decoder_conv3(x)\n",
    "        x = self.decoder_bn3(x)\n",
    "        x = self.relu(x)\n",
    "        # ã‚µã‚¤ã‚ºèª¿æ•´\n",
    "        x = F.interpolate(x, size=(10, 32, 32), mode='trilinear', align_corners=False)\n",
    "        \n",
    "        # (32, 10, 32, 32) -> (1, 20, 64, 64)\n",
    "        x = self.decoder_conv4(x)\n",
    "        # æœ€çµ‚ã‚µã‚¤ã‚ºèª¿æ•´\n",
    "        x = F.interpolate(x, size=(20, 64, 64), mode='trilinear', align_corners=False)\n",
    "        x = self.sigmoid(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒ‘ã‚¹\"\"\"\n",
    "        latent = self.encode(x)\n",
    "        reconstructed = self.decode(latent)\n",
    "        projection = self.projection_head(latent)\n",
    "        \n",
    "        return reconstructed, latent, projection\n",
    "\n",
    "# ================================\n",
    "# 5. ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚¯ãƒ©ã‚¹\n",
    "# ================================\n",
    "\n",
    "class GrayScottDataset(Dataset):\n",
    "    \"\"\"Gray-Scott ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆPhase 3ã‹ã‚‰ç¶™æ‰¿ãƒ»æ‹¡å¼µï¼‰\"\"\"\n",
    "    \n",
    "    def __init__(self, gif_folder, augmentation=None, max_samples=None):\n",
    "        self.gif_folder = gif_folder\n",
    "        self.augmentation = augmentation\n",
    "        \n",
    "        # GIFãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆå–å¾—\n",
    "        self.gif_files = [f for f in os.listdir(gif_folder) if f.endswith('.gif')]\n",
    "        \n",
    "        if max_samples:\n",
    "            self.gif_files = self.gif_files[:max_samples]\n",
    "        \n",
    "        # f-kãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æŠ½å‡º\n",
    "        self.f_params = []\n",
    "        self.k_params = []\n",
    "        \n",
    "        for gif_file in self.gif_files:\n",
    "            f_val, k_val = self.extract_parameters(gif_file)\n",
    "            self.f_params.append(f_val)\n",
    "            self.k_params.append(k_val)\n",
    "        \n",
    "        self.f_params = np.array(self.f_params)\n",
    "        self.k_params = np.array(self.k_params)\n",
    "        \n",
    "        print(f\"ğŸ“Š Dataset loaded: {len(self.gif_files)} samples\")\n",
    "        print(f\"f range: {self.f_params.min():.4f} - {self.f_params.max():.4f}\")\n",
    "        print(f\"k range: {self.k_params.min():.4f} - {self.k_params.max():.4f}\")\n",
    "    \n",
    "    def extract_parameters(self, filename):\n",
    "        \"\"\"ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰f-kãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æŠ½å‡º\"\"\"\n",
    "        pattern = r'f([\\d.]+)-k([\\d.]+)'\n",
    "        match = re.search(pattern, filename)\n",
    "        \n",
    "        if match:\n",
    "            f_val = float(match.group(1))\n",
    "            k_val = float(match.group(2))\n",
    "            return f_val, k_val\n",
    "        else:\n",
    "            return 0.0, 0.0\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.gif_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        gif_path = os.path.join(self.gif_folder, self.gif_files[idx])\n",
    "        \n",
    "        # GIFèª­ã¿è¾¼ã¿\n",
    "        gif = imageio.mimread(gif_path)\n",
    "        \n",
    "        # æœ€åˆã®20ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å–å¾—\n",
    "        frames = gif[:20] if len(gif) >= 20 else gif\n",
    "        \n",
    "        # ãƒ†ãƒ³ã‚½ãƒ«ã«å¤‰æ›\n",
    "        tensor = torch.FloatTensor(frames).unsqueeze(0)  # (1, T, H, W)\n",
    "        tensor = tensor / 255.0  # æ­£è¦åŒ–\n",
    "        \n",
    "        # ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µ\n",
    "        if self.augmentation:\n",
    "            tensor = self.augmentation(tensor)\n",
    "        \n",
    "        return tensor, self.f_params[idx], self.k_params[idx], idx\n",
    "\n",
    "# ================================\n",
    "# 6. æ”¹å–„ã•ã‚ŒãŸè¨“ç·´ãƒ«ãƒ¼ãƒ—\n",
    "# ================================\n",
    "\n",
    "def train_phase4_model(model, dataloader, num_epochs=30, learning_rate=1e-4):\n",
    "    \"\"\"Phase 4ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´\"\"\"\n",
    "    \n",
    "    # æœ€é©åŒ–å™¨\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "    \n",
    "    # æå¤±é–¢æ•°\n",
    "    reconstruction_loss = nn.MSELoss()\n",
    "    contrastive_loss = ContrastiveLoss(temperature=0.5)\n",
    "    \n",
    "    # è¨“ç·´ãƒ«ãƒ¼ãƒ—\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    \n",
    "    print(\"ğŸš€ Phase 4 Training Started\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0.0\n",
    "        epoch_recon_loss = 0.0\n",
    "        epoch_contrastive_loss = 0.0\n",
    "        \n",
    "        for batch_idx, (data, f_params, k_params, _) in enumerate(dataloader):\n",
    "            data = data.to(device)\n",
    "            f_params = f_params.to(device)\n",
    "            k_params = k_params.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒ‘ã‚¹\n",
    "            reconstructed, latent, projection = model(data)\n",
    "            \n",
    "            # æå¤±è¨ˆç®—\n",
    "            recon_loss = reconstruction_loss(reconstructed, data)\n",
    "            contrast_loss = contrastive_loss(projection, f_params, k_params)\n",
    "            \n",
    "            # ç·æå¤±ï¼ˆé‡ã¿ä»˜ãï¼‰\n",
    "            total_loss = recon_loss + 0.1 * contrast_loss\n",
    "            \n",
    "            # ãƒãƒƒã‚¯ãƒ—ãƒ­ãƒ‘ã‚²ãƒ¼ã‚·ãƒ§ãƒ³\n",
    "            total_loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += total_loss.item()\n",
    "            epoch_recon_loss += recon_loss.item()\n",
    "            epoch_contrastive_loss += contrast_loss.item()\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        avg_loss = epoch_loss / len(dataloader)\n",
    "        avg_recon_loss = epoch_recon_loss / len(dataloader)\n",
    "        avg_contrast_loss = epoch_contrastive_loss / len(dataloader)\n",
    "        \n",
    "        train_losses.append(avg_loss)\n",
    "        \n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "            print(f\"  Total Loss: {avg_loss:.6f}\")\n",
    "            print(f\"  Reconstruction: {avg_recon_loss:.6f}\")\n",
    "            print(f\"  Contrastive: {avg_contrast_loss:.6f}\")\n",
    "            print(f\"  LR: {scheduler.get_last_lr()[0]:.6f}\")\n",
    "    \n",
    "    print(\"âœ… Phase 4 Training Completed!\")\n",
    "    return train_losses\n",
    "\n",
    "# ================================\n",
    "# 7. ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°\n",
    "# ================================\n",
    "\n",
    "def main():\n",
    "    \"\"\"Phase 4ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ\"\"\"\n",
    "    \n",
    "    # ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚©ãƒ«ãƒ€è¨­å®š\n",
    "    GIF_FOLDER = \"path/to/gif/folder\"  # å®Ÿéš›ã®ãƒ‘ã‚¹ã«å¤‰æ›´\n",
    "    \n",
    "    if not os.path.exists(GIF_FOLDER):\n",
    "        print(f\"âŒ GIF folder not found: {GIF_FOLDER}\")\n",
    "        return\n",
    "    \n",
    "    # ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µè¨­å®š\n",
    "    augmentation = GrayScottAugmentation()\n",
    "    \n",
    "    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ\n",
    "    dataset = GrayScottDataset(GIF_FOLDER, augmentation=augmentation)\n",
    "    dataloader = DataLoader(dataset, batch_size=16, shuffle=True, num_workers=4)\n",
    "    \n",
    "    # ãƒ¢ãƒ‡ãƒ«ä½œæˆ\n",
    "    model = Conv3DAutoencoderPhase4(latent_dim=512).to(device)\n",
    "    \n",
    "    print(f\"ğŸ“Š Model Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "    \n",
    "    # è¨“ç·´å®Ÿè¡Œ\n",
    "    train_losses = train_phase4_model(model, dataloader, num_epochs=30)\n",
    "    \n",
    "    # ãƒ¢ãƒ‡ãƒ«ä¿å­˜\n",
    "    torch.save(model.state_dict(), 'models/phase4_model.pth')\n",
    "    print(\"ğŸ’¾ Model saved to models/phase4_model.pth\")\n",
    "    \n",
    "    # è©•ä¾¡å®Ÿè¡Œ\n",
    "    evaluate_phase4_model(model, dataloader)\n",
    "\n",
    "def evaluate_phase4_model(model, dataloader):\n",
    "    \"\"\"Phase 4ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡\"\"\"\n",
    "    \n",
    "    model.eval()\n",
    "    all_latents = []\n",
    "    all_f_params = []\n",
    "    all_k_params = []\n",
    "    \n",
    "    print(\"ğŸ” Phase 4 Evaluation Started\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, f_params, k_params, _ in dataloader:\n",
    "            data = data.to(device)\n",
    "            _, latent, _ = model(data)\n",
    "            \n",
    "            all_latents.append(latent.cpu().numpy())\n",
    "            all_f_params.append(f_params.numpy())\n",
    "            all_k_params.append(k_params.numpy())\n",
    "    \n",
    "    # ãƒ‡ãƒ¼ã‚¿çµ±åˆ\n",
    "    all_latents = np.vstack(all_latents)\n",
    "    all_f_params = np.concatenate(all_f_params)\n",
    "    all_k_params = np.concatenate(all_k_params)\n",
    "    \n",
    "    # éšå±¤çš„ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°\n",
    "    hierarchical_clustering = HierarchicalClusteringAnalysis()\n",
    "    hierarchical_clustering.fit(all_latents)\n",
    "    \n",
    "    # ã‚¯ãƒ©ã‚¹ã‚¿ãƒ©ãƒ™ãƒ«å–å¾—\n",
    "    cluster_labels = hierarchical_clustering.get_cluster_labels()\n",
    "    \n",
    "    # åŒ…æ‹¬çš„è©•ä¾¡\n",
    "    evaluator = ComprehensiveEvaluationMetrics()\n",
    "    metrics = evaluator.calculate_all_metrics(\n",
    "        all_latents, cluster_labels, all_f_params, all_k_params\n",
    "    )\n",
    "    \n",
    "    # çµæœè¡¨ç¤º\n",
    "    evaluator.print_metrics()\n",
    "    \n",
    "    # å¯è¦–åŒ–\n",
    "    visualize_phase4_results(all_latents, cluster_labels, all_f_params, all_k_params)\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def visualize_phase4_results(latents, labels, f_params, k_params):\n",
    "    \"\"\"Phase 4çµæœã®å¯è¦–åŒ–\"\"\"\n",
    "    \n",
    "    # PCA\n",
    "    pca = PCA(n_components=2)\n",
    "    latents_pca = pca.fit_transform(latents)\n",
    "    \n",
    "    # t-SNE\n",
    "    tsne = TSNE(n_components=2, random_state=42, perplexity=min(30, len(latents)//4))\n",
    "    latents_tsne = tsne.fit_transform(latents)\n",
    "    \n",
    "    # å¯è¦–åŒ–\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # PCAå¯è¦–åŒ–\n",
    "    scatter = axes[0, 0].scatter(latents_pca[:, 0], latents_pca[:, 1], c=labels, cmap='tab10', s=30)\n",
    "    axes[0, 0].set_title('PCA Visualization')\n",
    "    axes[0, 0].set_xlabel('PC1')\n",
    "    axes[0, 0].set_ylabel('PC2')\n",
    "    plt.colorbar(scatter, ax=axes[0, 0])\n",
    "    \n",
    "    # t-SNEå¯è¦–åŒ–\n",
    "    scatter = axes[0, 1].scatter(latents_tsne[:, 0], latents_tsne[:, 1], c=labels, cmap='tab10', s=30)\n",
    "    axes[0, 1].set_title('t-SNE Visualization')\n",
    "    axes[0, 1].set_xlabel('t-SNE 1')\n",
    "    axes[0, 1].set_ylabel('t-SNE 2')\n",
    "    plt.colorbar(scatter, ax=axes[0, 1])\n",
    "    \n",
    "    # f-kç©ºé–“å¯è¦–åŒ–\n",
    "    scatter = axes[1, 0].scatter(f_params, k_params, c=labels, cmap='tab10', s=30)\n",
    "    axes[1, 0].set_title('f-k Parameter Space')\n",
    "    axes[1, 0].set_xlabel('f parameter')\n",
    "    axes[1, 0].set_ylabel('k parameter')\n",
    "    plt.colorbar(scatter, ax=axes[1, 0])\n",
    "    \n",
    "    # ã‚¯ãƒ©ã‚¹ã‚¿åˆ†å¸ƒ\n",
    "    unique_labels, counts = np.unique(labels, return_counts=True)\n",
    "    axes[1, 1].bar(unique_labels, counts)\n",
    "    axes[1, 1].set_title('Cluster Distribution')\n",
    "    axes[1, 1].set_xlabel('Cluster')\n",
    "    axes[1, 1].set_ylabel('Count')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('results/phase4_visualization.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import imageio.v2 as imageio\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "# GPUç¢ºèª\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory/1e9:.1f} GB\")\n",
    "    device = torch.device('cuda')\n",
    "    # GPUæœ€é©åŒ–è¨­å®š\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cudnn.deterministic = False\n",
    "else:\n",
    "    print(\"âš ï¸ GPU not available. Please enable GPU in Runtime > Change runtime type\")\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(f\"ğŸš€ Using device: {device}\")\n",
    "\n",
    "# ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n",
    "try:\n",
    "    import imageio\n",
    "    import seaborn\n",
    "    print(\"âœ… All packages available\")\n",
    "except ImportError:\n",
    "    print(\"ğŸ“¦ Installing required packages...\")\n",
    "    !pip install imageio scikit-learn seaborn\n",
    "    import imageio\n",
    "    import seaborn\n",
    "    print(\"âœ… Packages installed successfully\")\n",
    "\n",
    "# è¿½åŠ ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ç¢ºèª\n",
    "try:\n",
    "    import umap\n",
    "    import hdbscan\n",
    "    print(\"âœ… UMAP/HDBSCAN available\")\n",
    "except Exception:\n",
    "    print(\"ğŸ“¦ Installing umap-learn and hdbscan...\")\n",
    "    !pip install umap-learn hdbscan\n",
    "    import umap\n",
    "    import hdbscan\n",
    "    print(\"âœ… UMAP/HDBSCAN installed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Driveæ¥ç¶šã¨ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹ç¢ºèª\n",
    "from google.colab import drive\n",
    "\n",
    "# Google Driveã‚’ãƒã‚¦ãƒ³ãƒˆ\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹è¨­å®š\n",
    "GIF_FOLDER_PATH = '/content/drive/MyDrive/GrayScottML/gif'\n",
    "\n",
    "# ãƒ‡ãƒ¼ã‚¿ç¢ºèª\n",
    "if os.path.exists(GIF_FOLDER_PATH):\n",
    "    gif_files = [f for f in os.listdir(GIF_FOLDER_PATH) if f.endswith('.gif')]\n",
    "    gif_count = len(gif_files)\n",
    "    print(f\"âœ… Google Drive connected successfully!\")\n",
    "    print(f\"ğŸ“ Path: {GIF_FOLDER_PATH}\")\n",
    "    print(f\"ğŸ¬ GIF files found: {gif_count}\")\n",
    "    \n",
    "    if gif_count >= 1000:\n",
    "        print(\"ğŸ‰ Ready for Phase 2 training with last 64 frames!\")\n",
    "    else:\n",
    "        print(f\"âš ï¸ Not enough files. Expected: 1500, Found: {gif_count}\")\n",
    "        print(\"Please upload more GIF files to Google Drive.\")\n",
    "else:\n",
    "    print(\"âŒ Google Drive path not found!\")\n",
    "    print(f\"Expected path: {GIF_FOLDER_PATH}\")\n",
    "    print(\"Please ensure the following structure exists:\")\n",
    "    print(\"  MyDrive/\")\n",
    "    print(\"  â””â”€â”€ GrayScottML/\")\n",
    "    print(\"      â””â”€â”€ gif/\")\n",
    "    print(\"          â”œâ”€â”€ GrayScott-f0.0100-k0.0400-00.gif\")\n",
    "    print(\"          â””â”€â”€ ... (1500 files)\")\n",
    "    \n",
    "    # ãƒã‚¤ãƒ‰ãƒ©ã‚¤ãƒ–ã®å†…å®¹ã‚’è¡¨ç¤º\n",
    "    mydrive_path = '/content/drive/MyDrive'\n",
    "    if os.path.exists(mydrive_path):\n",
    "        print(f\"\\nğŸ“‚ Contents of MyDrive:\")\n",
    "        for item in sorted(os.listdir(mydrive_path))[:10]:\n",
    "            print(f\"   ğŸ“ {item}\")\n",
    "        print(\"   ... (showing first 10 items)\")\n",
    "    raise FileNotFoundError(\"Please set up the correct folder structure in Google Drive\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚¯ãƒ©ã‚¹ï¼ˆå¾ŒåŠ64ãƒ•ãƒ¬ãƒ¼ãƒ  + Augmentationï¼‰\n",
    "class GrayScottDatasetLast64Aug(Dataset):\n",
    "    def __init__(self, gif_folder, fixed_frames=64, target_size=(64, 64), max_samples=None, augment=True, max_shift_ratio=0.1):\n",
    "        self.gif_folder = gif_folder\n",
    "        self.fixed_frames = fixed_frames\n",
    "        self.target_size = target_size\n",
    "        self.max_samples = max_samples\n",
    "        self.augment = augment\n",
    "        self.max_shift_ratio = max_shift_ratio\n",
    "        \n",
    "        self.gif_files = []\n",
    "        self.f_values = []\n",
    "        self.k_values = []\n",
    "        self.tensors = []\n",
    "        \n",
    "        self._load_data()\n",
    "    \n",
    "    def _parse_filename(self, filename):\n",
    "        pattern = r\"GrayScott-f([0-9.]+)-k([0-9.]+)-\\d+\\.gif\"\n",
    "        m = re.match(pattern, filename)\n",
    "        if m:\n",
    "            return float(m.group(1)), float(m.group(2))\n",
    "        return None, None\n",
    "    \n",
    "    def _load_gif_as_tensor(self, gif_path):\n",
    "        try:\n",
    "            gif = imageio.mimread(gif_path)\n",
    "            total_frames = len(gif)\n",
    "            if total_frames >= self.fixed_frames:\n",
    "                start_idx = total_frames - self.fixed_frames\n",
    "                selected_frames = gif[start_idx:]\n",
    "            else:\n",
    "                selected_frames = gif\n",
    "            frames = []\n",
    "            for frame in selected_frames:\n",
    "                if len(frame.shape) == 3:\n",
    "                    frame = np.mean(frame, axis=2)\n",
    "                pil_frame = Image.fromarray(frame.astype(np.uint8))\n",
    "                pil_frame = pil_frame.resize(self.target_size)\n",
    "                frame_array = np.array(pil_frame) / 255.0\n",
    "                frames.append(frame_array)\n",
    "            while len(frames) < self.fixed_frames:\n",
    "                frames.append(frames[-1] if frames else np.zeros(self.target_size))\n",
    "            frames = frames[:self.fixed_frames]\n",
    "            tensor = torch.FloatTensor(np.array(frames))  # (T, H, W)\n",
    "            return tensor.unsqueeze(0)  # (1, T, H, W)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {gif_path}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def _load_data(self):\n",
    "        gif_files = [f for f in os.listdir(self.gif_folder) if f.endswith('.gif')]\n",
    "        if self.max_samples:\n",
    "            gif_files = gif_files[:self.max_samples]\n",
    "        print(f\"Loading {len(gif_files)} GIF files (last 64 frames each) with augmentation={self.augment}...\")\n",
    "        for i, filename in enumerate(gif_files):\n",
    "            if i % 100 == 0:\n",
    "                print(f\"Progress: {i+1}/{len(gif_files)} ({(i+1)/len(gif_files)*100:.1f}%)\")\n",
    "            f_val, k_val = self._parse_filename(filename)\n",
    "            if f_val is None or k_val is None:\n",
    "                continue\n",
    "            gif_path = os.path.join(self.gif_folder, filename)\n",
    "            tensor = self._load_gif_as_tensor(gif_path)\n",
    "            if tensor is not None:\n",
    "                self.gif_files.append(filename)\n",
    "                self.f_values.append(f_val)\n",
    "                self.k_values.append(k_val)\n",
    "                self.tensors.append(tensor)\n",
    "        print(f\"âœ… Successfully loaded {len(self.tensors)} samples\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.tensors)\n",
    "    \n",
    "    def _random_flip(self, x):\n",
    "        # x: (1, T, H, W)\n",
    "        if np.random.rand() < 0.5:\n",
    "            x = torch.flip(x, dims=[-1])  # horizontal\n",
    "        if np.random.rand() < 0.5:\n",
    "            x = torch.flip(x, dims=[-2])  # vertical\n",
    "        return x\n",
    "    \n",
    "    def _random_rotate_90(self, x):\n",
    "        k = np.random.choice([0,1,2,3])\n",
    "        if k:\n",
    "            x = torch.rot90(x, k=k, dims=(-2, -1))\n",
    "        return x\n",
    "    \n",
    "    def _random_translate(self, x):\n",
    "        # zero-padded translation by up to max_shift_ratio of size\n",
    "        _, _, H, W = x.shape\n",
    "        max_dx = int(W * self.max_shift_ratio)\n",
    "        max_dy = int(H * self.max_shift_ratio)\n",
    "        if max_dx == 0 and max_dy == 0:\n",
    "            return x\n",
    "        dx = int(np.random.randint(-max_dx, max_dx+1))\n",
    "        dy = int(np.random.randint(-max_dy, max_dy+1))\n",
    "        if dx == 0 and dy == 0:\n",
    "            return x\n",
    "        pad_left = max(dx, 0)\n",
    "        pad_right = max(-dx, 0)\n",
    "        pad_top = max(dy, 0)\n",
    "        pad_bottom = max(-dy, 0)\n",
    "        x_padded = F.pad(x, (pad_left, pad_right, pad_top, pad_bottom), mode='constant', value=0.0)\n",
    "        x_cropped = x_padded[:, :, pad_bottom:pad_bottom+H, pad_right:pad_right+W]\n",
    "        return x_cropped\n",
    "    \n",
    "    def _apply_augmentation(self, x):\n",
    "        x = self._random_flip(x)\n",
    "        x = self._random_rotate_90(x)\n",
    "        x = self._random_translate(x)\n",
    "        return x\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.tensors[idx].clone()  # (1, T, H, W)\n",
    "        if self.augment:\n",
    "            sample = self._apply_augmentation(sample)\n",
    "        return {\n",
    "            'tensor': sample,\n",
    "            'f_value': self.f_values[idx],\n",
    "            'k_value': self.k_values[idx],\n",
    "            'filename': self.gif_files[idx]\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚¯ãƒ©ã‚¹ï¼ˆå¾ŒåŠ64ãƒ•ãƒ¬ãƒ¼ãƒ å°‚ç”¨ï¼‰\n",
    "class GrayScottDatasetLast64(Dataset):\n",
    "    def __init__(self, gif_folder, fixed_frames=64, target_size=(64, 64), max_samples=None):\n",
    "        self.gif_folder = gif_folder\n",
    "        self.fixed_frames = fixed_frames\n",
    "        self.target_size = target_size\n",
    "        self.max_samples = max_samples\n",
    "        \n",
    "        self.gif_files = []\n",
    "        self.f_values = []\n",
    "        self.k_values = []\n",
    "        self.tensors = []\n",
    "        \n",
    "        self._load_data()\n",
    "    \n",
    "    def _parse_filename(self, filename):\n",
    "        pattern = r'GrayScott-f([0-9.]+)-k([0-9.]+)-\\d+\\.gif'\n",
    "        match = re.match(pattern, filename)\n",
    "        if match:\n",
    "            return float(match.group(1)), float(match.group(2))\n",
    "        return None, None\n",
    "    \n",
    "    def _load_gif_as_tensor(self, gif_path):\n",
    "        try:\n",
    "            gif = imageio.mimread(gif_path)\n",
    "            total_frames = len(gif)\n",
    "            \n",
    "            # å¾ŒåŠ64ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’æŠ½å‡º\n",
    "            if total_frames >= self.fixed_frames:\n",
    "                # å¾ŒåŠ64ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å–å¾—\n",
    "                start_idx = total_frames - self.fixed_frames\n",
    "                selected_frames = gif[start_idx:]\n",
    "            else:\n",
    "                # ãƒ•ãƒ¬ãƒ¼ãƒ æ•°ãŒ64æœªæº€ã®å ´åˆã¯å…¨ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä½¿ç”¨\n",
    "                selected_frames = gif\n",
    "                print(f\"Warning: Only {total_frames} frames available, using all frames\")\n",
    "            \n",
    "            frames = []\n",
    "            for frame in selected_frames:\n",
    "                if len(frame.shape) == 3:\n",
    "                    frame = np.mean(frame, axis=2)\n",
    "                \n",
    "                pil_frame = Image.fromarray(frame.astype(np.uint8))\n",
    "                pil_frame = pil_frame.resize(self.target_size)\n",
    "                frame_array = np.array(pil_frame) / 255.0\n",
    "                frames.append(frame_array)\n",
    "            \n",
    "            # 64ãƒ•ãƒ¬ãƒ¼ãƒ ã«ãªã‚‹ã‚ˆã†ã«ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰\n",
    "            while len(frames) < self.fixed_frames:\n",
    "                frames.append(frames[-1] if frames else np.zeros(self.target_size))\n",
    "            \n",
    "            # æ­£ç¢ºã«64ãƒ•ãƒ¬ãƒ¼ãƒ ã«ã™ã‚‹\n",
    "            frames = frames[:self.fixed_frames]\n",
    "            \n",
    "            tensor = torch.FloatTensor(np.array(frames))\n",
    "            return tensor.unsqueeze(0)  # ãƒãƒ£ãƒ³ãƒãƒ«æ¬¡å…ƒã‚’è¿½åŠ \n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {gif_path}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def _load_data(self):\n",
    "        gif_files = [f for f in os.listdir(self.gif_folder) if f.endswith('.gif')]\n",
    "        \n",
    "        if self.max_samples:\n",
    "            gif_files = gif_files[:self.max_samples]\n",
    "        \n",
    "        print(f\"Loading {len(gif_files)} GIF files (last 64 frames each)...\")\n",
    "        \n",
    "        for i, filename in enumerate(gif_files):\n",
    "            if i % 100 == 0:\n",
    "                print(f\"Progress: {i+1}/{len(gif_files)} ({(i+1)/len(gif_files)*100:.1f}%)\")\n",
    "            \n",
    "            f_val, k_val = self._parse_filename(filename)\n",
    "            if f_val is None or k_val is None:\n",
    "                continue\n",
    "            \n",
    "            gif_path = os.path.join(self.gif_folder, filename)\n",
    "            tensor = self._load_gif_as_tensor(gif_path)\n",
    "            \n",
    "            if tensor is not None:\n",
    "                self.gif_files.append(filename)\n",
    "                self.f_values.append(f_val)\n",
    "                self.k_values.append(k_val)\n",
    "                self.tensors.append(tensor)\n",
    "        \n",
    "        print(f\"âœ… Successfully loaded {len(self.tensors)} samples with last 64 frames each\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.tensors)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'tensor': self.tensors[idx],\n",
    "            'f_value': self.f_values[idx],\n",
    "            'k_value': self.k_values[idx],\n",
    "            'filename': self.gif_files[idx]\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ³¨æ„æ©Ÿæ§‹ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«\n",
    "class SpatioTemporalAttention(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        \n",
    "        # ç©ºé–“æ³¨æ„\n",
    "        self.spatial_attention = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool3d((None, 1, 1)),\n",
    "            nn.Conv3d(channels, channels//4, 1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(channels//4, channels, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # æ™‚é–“æ³¨æ„\n",
    "        self.temporal_attention = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool3d((1, None, None)),\n",
    "            nn.Conv3d(channels, channels//4, 1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(channels//4, channels, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # ãƒãƒ£ãƒ³ãƒãƒ«æ³¨æ„\n",
    "        self.channel_attention = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool3d(1),\n",
    "            nn.Conv3d(channels, channels//4, 1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(channels//4, channels, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        \n",
    "        # 3ã¤ã®æ³¨æ„æ©Ÿæ§‹ã‚’é©ç”¨\n",
    "        x = x * self.spatial_attention(x)\n",
    "        x = x * self.temporal_attention(x)\n",
    "        x = x * self.channel_attention(x)\n",
    "        \n",
    "        return x + identity * 0.1\n",
    "\n",
    "# æ®‹å·®æ³¨æ„ãƒ–ãƒ­ãƒƒã‚¯\n",
    "class ResidualAttentionBlock3D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv3d(in_channels, out_channels, 3, stride, 1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm3d(out_channels, momentum=0.1)\n",
    "        self.conv2 = nn.Conv3d(out_channels, out_channels, 3, 1, 1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm3d(out_channels, momentum=0.1)\n",
    "        \n",
    "        self.attention = SpatioTemporalAttention(out_channels)\n",
    "        \n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv3d(in_channels, out_channels, 1, stride, bias=False),\n",
    "                nn.BatchNorm3d(out_channels, momentum=0.1)\n",
    "            )\n",
    "        \n",
    "        self.dropout = nn.Dropout3d(0.1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        \n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.dropout(out)\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out = self.attention(out)\n",
    "        \n",
    "        out += self.shortcut(identity)\n",
    "        return F.relu(out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸš€ Step 3: Phase 2 å­¦ç¿’å®Ÿè¡Œï¼ˆ64ãƒ•ãƒ¬ãƒ¼ãƒ å¯¾å¿œï¼‰\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 4 architecture\n",
    "# åˆ©ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«: src/gray_scott_autoencoder_phase3.py ã® Conv3DAutoencoderPhase3 ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚\n",
    "# using embedded Conv3DAutoencoderPhase4 (import removed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 2 ãƒ¡ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«ï¼ˆ64ãƒ•ãƒ¬ãƒ¼ãƒ å¯¾å¿œï¼‰\n",
    "class Conv3DAutoencoderPhase4Last64(nn.Module):\n",
    "    def __init__(self, input_channels=1, fixed_frames=64, target_size=(64, 64), latent_dim=256):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.latent_dim = latent_dim\n",
    "        self.fixed_frames = fixed_frames\n",
    "        self.target_size = target_size\n",
    "        \n",
    "        # åˆæœŸç•³ã¿è¾¼ã¿ï¼ˆ64ãƒ•ãƒ¬ãƒ¼ãƒ å¯¾å¿œï¼‰\n",
    "        self.initial_conv = nn.Sequential(\n",
    "            nn.Conv3d(input_channels, 32, (5, 7, 7), (2, 2, 2), (2, 3, 3)),\n",
    "            nn.BatchNorm3d(32, momentum=0.1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout3d(0.05)\n",
    "        )\n",
    "        \n",
    "        # æ®‹å·®æ³¨æ„ãƒ–ãƒ­ãƒƒã‚¯ç¾¤ï¼ˆ64ãƒ•ãƒ¬ãƒ¼ãƒ ç”¨ã«èª¿æ•´ï¼‰\n",
    "        self.res_block1 = ResidualAttentionBlock3D(32, 64, stride=(2, 2, 2))\n",
    "        self.res_block2 = ResidualAttentionBlock3D(64, 64)\n",
    "        self.res_block3 = ResidualAttentionBlock3D(64, 128, stride=(2, 2, 2))\n",
    "        self.res_block4 = ResidualAttentionBlock3D(128, 128)\n",
    "        self.res_block5 = ResidualAttentionBlock3D(128, 256, stride=(2, 2, 2))\n",
    "        self.res_block6 = ResidualAttentionBlock3D(256, 256)\n",
    "        \n",
    "        # ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ—ãƒ¼ãƒªãƒ³ã‚°\n",
    "        self.global_pool = nn.AdaptiveAvgPool3d((2, 2, 2))\n",
    "        self.dropout_before_latent = nn.Dropout3d(0.3)\n",
    "        \n",
    "        # æ½œåœ¨ç©ºé–“å°„å½±\n",
    "        self.to_latent = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256 * 2 * 2 * 2, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(512, latent_dim),\n",
    "            nn.BatchNorm1d(latent_dim)\n",
    "        )\n",
    "        \n",
    "        # å¾©å…ƒ\n",
    "        self.from_latent = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(512, 256 * 2 * 2 * 2),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        # ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼ï¼ˆ64ãƒ•ãƒ¬ãƒ¼ãƒ å¾©å…ƒç”¨ï¼‰\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose3d(256, 128, (4, 4, 4), (2, 2, 2), (1, 1, 1)),\n",
    "            nn.BatchNorm3d(128, momentum=0.1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout3d(0.2),\n",
    "            \n",
    "            nn.ConvTranspose3d(128, 64, (4, 4, 4), (2, 2, 2), (1, 1, 1)),\n",
    "            nn.BatchNorm3d(64, momentum=0.1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout3d(0.15),\n",
    "            \n",
    "            nn.ConvTranspose3d(64, 32, (4, 4, 4), (2, 2, 2), (1, 1, 1)),\n",
    "            nn.BatchNorm3d(32, momentum=0.1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout3d(0.1),\n",
    "            \n",
    "            nn.ConvTranspose3d(32, input_channels, (6, 7, 7), (2, 2, 2), (2, 3, 3)),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def encode(self, x):\n",
    "        x = self.initial_conv(x)\n",
    "        x = self.res_block1(x)\n",
    "        x = self.res_block2(x)\n",
    "        x = self.res_block3(x)\n",
    "        x = self.res_block4(x)\n",
    "        x = self.res_block5(x)\n",
    "        x = self.res_block6(x)\n",
    "        x = self.global_pool(x)\n",
    "        x = self.dropout_before_latent(x)\n",
    "        return self.to_latent(x)\n",
    "    \n",
    "    def decode(self, latent):\n",
    "        x = self.from_latent(latent)\n",
    "        x = x.view(-1, 256, 2, 2, 2)\n",
    "        x = self.decoder(x)\n",
    "        target_h, target_w = self.target_size\n",
    "        return F.interpolate(x, size=(self.fixed_frames, target_h, target_w), \n",
    "                           mode='trilinear', align_corners=False)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        latent = self.encode(x)\n",
    "        reconstructed = self.decode(latent)\n",
    "        return reconstructed, latent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 4 å­¦ç¿’ãƒ»è©•ä¾¡å®Ÿè¡Œï¼ˆ64ãƒ•ãƒ¬ãƒ¼ãƒ ç‰ˆï¼‰\n",
    "def run_phase4_training_last64():\n",
    "    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š\n",
    "    fixed_frames = 64  # å¾ŒåŠ64ãƒ•ãƒ¬ãƒ¼ãƒ \n",
    "    target_size = (64, 64)\n",
    "    latent_dim = 512\n",
    "    num_epochs = 50\n",
    "    batch_size = 6 if torch.cuda.is_available() else 3  # 64ãƒ•ãƒ¬ãƒ¼ãƒ ãªã®ã§å°‘ã—å°ã•ã\n",
    "    learning_rate = 1e-3\n",
    "    weight_decay = 1e-4\n",
    "    n_clusters = 5\n",
    "    \n",
    "    print(\"ğŸ”„ Creating dataset (last 64 frames, with augmentation)...\")\n",
    "    dataset = GrayScottDatasetLast64Aug(GIF_FOLDER_PATH, fixed_frames, target_size, augment=True, max_samples=max_samples)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, \n",
    "                          num_workers=2, pin_memory=True)\n",
    "    \n",
    "    print(f\"ğŸ“Š Dataset: {len(dataset)} samples, Batch size: {batch_size}, Frames: {fixed_frames}\")\n",
    "    \n",
    "    print(\"ğŸ§  Creating Phase 4 model (64 frames)...\")\n",
    "    model = Conv3DAutoencoderPhase4(latent_dim=latent_dim, \n",
    "                                         fixed_frames=fixed_frames, \n",
    "                                         target_size=target_size).to(device)\n",
    "    \n",
    "    print(f\"ğŸ“Š Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "    \n",
    "    # è¨“ç·´\n",
    "    print(\"ğŸ¯ Starting training with last 64 frames...\")\n",
    "    model.train()\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=1e-6)\n",
    "    \n",
    "    losses = []\n",
    "    start_time = time.time()\n",
    "    \n",
    "    print(f\"ğŸš€ Phase 4 GPU Training: ResNet + Attention (Last 64 Frames)\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_start_time = time.time()\n",
    "        epoch_loss = 0.0\n",
    "        \n",
    "        for batch_idx, batch in enumerate(dataloader):\n",
    "            tensors = batch['tensor'].to(device, non_blocking=True)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            reconstructed, latent = model(tensors)\n",
    "            loss = criterion(reconstructed, tensors)\n",
    "            loss.backward()\n",
    "            \n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5)\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        avg_loss = epoch_loss / len(dataloader)\n",
    "        losses.append(avg_loss)\n",
    "        current_lr = scheduler.get_last_lr()[0]\n",
    "        epoch_time = time.time() - epoch_start_time\n",
    "        \n",
    "        # é€²æ—è¡¨ç¤º\n",
    "        progress = ((epoch + 1) / num_epochs) * 100\n",
    "        if (epoch + 1) % 5 == 0 or epoch < 5:\n",
    "            print(f'Epoch [{epoch+1:2d}/{num_epochs}] '\n",
    "                  f'({progress:5.1f}%) | '\n",
    "                  f'Loss: {avg_loss:.6f} | '\n",
    "                  f'LR: {current_lr:.2e} | '\n",
    "                  f'Time: {epoch_time:.1f}s')\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"ğŸ‰ Training completed in {total_time/60:.1f} minutes\")\n",
    "    \n",
    "    # å­¦ç¿’æ›²ç·šè¡¨ç¤º\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(losses, linewidth=2, color='purple')\n",
    "    plt.title('Phase 4: GPU Training Loss (ResNet + Attention, Last 64 Frames)', fontsize=14)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "    \n",
    "    # æ½œåœ¨ãƒ™ã‚¯ãƒˆãƒ«æŠ½å‡º\n",
    "    print(\"ğŸ” Extracting latent vectors...\")\n",
    "    # Rebuild dataset without augmentation for evaluation/feature extraction\n",
    "    dataset_eval = GrayScottDatasetLast64Aug(GIF_FOLDER_PATH, fixed_frames, target_size, augment=False, max_samples=max_samples)\n",
    "    dataloader_eval = DataLoader(dataset_eval, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "    model.eval()\n",
    "    latent_vectors = []\n",
    "    f_values = []\n",
    "    k_values = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader_eval:\n",
    "            tensors = batch['tensor'].to(device)\n",
    "            _, latent = model(tensors)\n",
    "            latent_vectors.append(latent.cpu().numpy())\n",
    "            f_values.extend(batch['f_value'].numpy())\n",
    "            k_values.extend(batch['k_value'].numpy())\n",
    "    \n",
    "    latent_vectors = np.vstack(latent_vectors)\n",
    "    f_values = np.array(f_values)\n",
    "    k_values = np.array(k_values)\n",
    "    \n",
    "    # ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°\n",
    "    print(\"ï¿½ï¿½ Performing clustering with multiple strategies...\")\n",
    "from sklearn.decomposition import PCA as _PCA\n",
    "from sklearn.preprocessing import StandardScaler as _SS\n",
    "from sklearn.cluster import KMeans as _KMeans\n",
    "# Strategy A: PCA(whiten=True) -> KMeans(n_init=50)\n",
    "Xa = _PCA(n_components=min(64, latent_vectors.shape[1]), whiten=True, random_state=42).fit_transform(latent_vectors)\n",
    "labels_a = _KMeans(n_clusters=n_clusters, n_init=50, random_state=42).fit_predict(Xa)\n",
    "sil_a = silhouette_score(latent_vectors, labels_a)\n",
    "print(f\"[A] PCA(whiten)+KMeans(n_init=50): Silhouette={sil_a:.4f}\")\n",
    "\n",
    "# Strategy B: L2-normalize -> KMeans(n_init=50)  (cosineè¿‘ä¼¼)\n",
    "Xb = latent_vectors / (np.linalg.norm(latent_vectors, axis=1, keepdims=True) + 1e-8)\n",
    "labels_b = _KMeans(n_clusters=n_clusters, n_init=50, random_state=42).fit_predict(Xb)\n",
    "sil_b = silhouette_score(latent_vectors, labels_b)\n",
    "print(f\"[B] L2-norm+KMeans(n_init=50): Silhouette={sil_b:.4f}\")\n",
    "\n",
    "# Strategy C: UMAP -> HDBSCAN\n",
    "try:\n",
    "    import umap\n",
    "    import hdbscan\n",
    "    U = umap.UMAP(n_neighbors=15, min_dist=0.1, n_components=10, random_state=42).fit_transform(latent_vectors)\n",
    "    labels_c = hdbscan.HDBSCAN(min_cluster_size=20).fit_predict(U)\n",
    "    # -1 ã¯ãƒã‚¤ã‚º\n",
    "    valid = labels_c != -1\n",
    "    if valid.any() and len(set(labels_c[valid]))>1:\n",
    "        sil_c = silhouette_score(latent_vectors[valid], labels_c[valid])\n",
    "        print(f\"[C] UMAP+HDBSCAN: clusters={len(set(labels_c[valid]))}, noise={(~valid).sum()}, Silhouette(valid)={sil_c:.4f}\")\n",
    "    else:\n",
    "        print(f\"[C] UMAP+HDBSCAN: clusters={len(set(labels_c)) if len(set(labels_c))>1 else 0}, noise={(labels_c==-1).sum()} (silhouette N/A)\")\n",
    "except Exception as e:\n",
    "    print(f\"[C] UMAP+HDBSCAN unavailable: {e}\")\n",
    "\n",
    "# æ—¢å®šã®å‡ºåŠ›ã‚’[A]ã«è¨­å®š\n",
    "cluster_labels = labels_a\n",
    "# Phase 1ã¨ã®æ¯”è¼ƒ\n",
    "phase1_score = 0.565\n",
    "improvement = ((silhouette_avg - phase1_score) / phase1_score) * 100\n",
    "\n",
    "print(f\"ğŸ“ˆ Performance Comparison:\")\n",
    "print(f\"   Phase 1 (30 frames): {phase1_score:.4f}\")\n",
    "print(f\"   Phase 4 (last 64 frames): {silhouette_avg:.4f}\")\n",
    "print(f\"   Improvement: {improvement:+.1f}%\")\n",
    "\n",
    "if improvement >= 15:\n",
    "print(\"ğŸ‰ Phase 4 ç›®æ¨™é”æˆï¼ (15%ä»¥ä¸Šã®å‘ä¸Š) - Last 64 frames strategy successful!\")\n",
    "else:\n",
    "print(f\"âš ï¸  Phase 4 ç›®æ¨™æœªé” ({improvement:.1f}% < 15%) - Consider further optimization\")\n",
    "\n",
    "return {\n",
    "'model': model,\n",
    "'losses': losses,\n",
    "'silhouette_score': silhouette_avg,\n",
    "'calinski_score': calinski_score,\n",
    "'davies_bouldin': davies_bouldin,\n",
    "'latent_vectors': latent_vectors,\n",
    "'cluster_labels': cluster_labels,\n",
    "'f_values': f_values,\n",
    "'k_values': k_values,\n",
    "'improvement': improvement,\n",
    "'frames_used': 'last_64'\n",
    "}\n",
    "\n",
    "# å®Ÿè¡Œ\n",
    "print(\"ğŸš€ Starting Phase 4 training with last 64 frames...\")\n",
    "results = run_phase4_training_last64()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure latent_vectors are available if only results exist\n",
    "if 'latent_vectors' not in globals():\n",
    "    if 'results' in globals() and isinstance(results, dict) and 'latent_vectors' in results:\n",
    "        latent_vectors = results['latent_vectors']\n",
    "        f_values = results.get('f_values', None)\n",
    "        k_values = results.get('k_values', None)\n",
    "        cluster_labels = results.get('cluster_labels', None)\n",
    "        print('Recovered latent_vectors from results dict:', latent_vectors.shape)\n",
    "    else:\n",
    "        print('latent_vectors not found. Run training to produce results and latent vectors.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“¥ Step 4: çµæœä¿å­˜ãƒ»ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# çµæœä¿å­˜ã¨ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆLast 64 framesç‰ˆï¼‰\n",
    "import pickle\n",
    "from google.colab import files\n",
    "\n",
    "# çµæœã‚’Google Driveã«ä¿å­˜\n",
    "results_path = '/content/drive/MyDrive/GrayScottML/phase4_results_last64_gpu.pkl'\n",
    "model_path = '/content/drive/MyDrive/GrayScottML/phase4_model_last64_gpu.pth'\n",
    "\n",
    "# çµæœä¿å­˜\n",
    "with open(results_path, 'wb') as f:\n",
    "    # ãƒ¢ãƒ‡ãƒ«ã¯é™¤ã„ã¦ä¿å­˜ï¼ˆã‚µã‚¤ã‚ºå‰Šæ¸›ï¼‰\n",
    "    save_results = {k: v for k, v in results.items() if k != 'model'}\n",
    "    pickle.dump(save_results, f)\n",
    "\n",
    "# ãƒ¢ãƒ‡ãƒ«ä¿å­˜\n",
    "torch.save(results['model'].state_dict(), model_path)\n",
    "\n",
    "print(f\"ğŸ’¾ Results saved to Google Drive:\")\n",
    "print(f\"   ğŸ“Š Results: {results_path}\")\n",
    "print(f\"   ğŸ§  Model: {model_path}\")\n",
    "\n",
    "# ãƒ­ãƒ¼ã‚«ãƒ«ã«ã‚‚ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ç”¨ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ\n",
    "local_results_path = 'phase4_results_last64_gpu.pkl'\n",
    "local_model_path = 'phase4_model_last64_gpu.pth'\n",
    "\n",
    "with open(local_results_path, 'wb') as f:\n",
    "    save_results = {k: v for k, v in results.items() if k != 'model'}\n",
    "    pickle.dump(save_results, f)\n",
    "\n",
    "torch.save(results['model'].state_dict(), local_model_path)\n",
    "\n",
    "print(\"\\nğŸ“¥ Downloading files...\")\n",
    "files.download(local_results_path)\n",
    "files.download(local_model_path)\n",
    "\n",
    "print(\"âœ… Download completed!\")\n",
    "print(f\"ğŸ¯ Final Results (Last 64 Frames):\")\n",
    "print(f\"   â­ Silhouette Score: {results['silhouette_score']:.4f}\")\n",
    "print(f\"   ğŸ“ˆ Improvement: {results['improvement']:+.1f}%\")\n",
    "print(f\"   ğŸ¬ Strategy: Using last 64 frames for more stable patterns\")\n",
    "print(f\"   ğŸ† Target: {'âœ… ACHIEVED' if results['improvement'] >= 15 else 'âŒ NOT ACHIEVED'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š Step 5: å¯è¦–åŒ–ãƒ»åˆ†æï¼ˆOptionalï¼‰\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Google Drive save directory for figures\n",
    "import os\n",
    "SAVE_DIR = os.environ.get('GSML_SAVE_DIR', '/content/drive/MyDrive/GrayScottML/results')\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "print('Figures will be saved to:', SAVE_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# çµæœã®è©³ç´°å¯è¦–åŒ–ï¼ˆLast 64 framesï¼‰\n",
    "def visualize_results_last64(results):\n",
    "    latent_vectors = results['latent_vectors']\n",
    "    cluster_labels = results['cluster_labels']\n",
    "    f_values = results['f_values']\n",
    "    k_values = results['k_values']\n",
    "    \n",
    "    # PCAã¨t-SNEã«ã‚ˆã‚‹æ¬¡å…ƒå‰Šæ¸›\n",
    "    print(\"ğŸ” Performing dimensionality reduction...\")\n",
    "    pca = PCA(n_components=2, random_state=42)\n",
    "    pca_result = pca.fit_transform(latent_vectors)\n",
    "    \n",
    "    tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
    "    tsne_result = tsne.fit_transform(latent_vectors)\n",
    "    \n",
    "    # å¯è¦–åŒ–\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle('Phase 2 Results: Phase 4 (Last 64 Frames) Analysis', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # f-kç©ºé–“ã§ã®ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°çµæœ\n",
    "    scatter1 = axes[0, 0].scatter(f_values, k_values, c=cluster_labels, cmap='tab10', alpha=0.7, s=20)\n",
    "    axes[0, 0].set_xlabel('f parameter')\n",
    "    axes[0, 0].set_ylabel('k parameter')\n",
    "    axes[0, 0].set_title('Clustering Results in f-k Parameter Space')\n",
    "    axes[0, 0].invert_yaxis()\n",
    "    plt.colorbar(scatter1, ax=axes[0, 0], label='Cluster ID')\n",
    "    \n",
    "    # PCAçµæœ\n",
    "    scatter2 = axes[0, 1].scatter(pca_result[:, 0], pca_result[:, 1], c=cluster_labels, cmap='tab10', alpha=0.7, s=20)\n",
    "    axes[0, 1].set_title(f'PCA of Latent Space (Phase 4 (Last 64 Frames))')\n",
    "    axes[0, 1].set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} variance)')\n",
    "    axes[0, 1].set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} variance)')\n",
    "    plt.colorbar(scatter2, ax=axes[0, 1], label='Cluster ID')\n",
    "    \n",
    "    # t-SNEçµæœ\n",
    "    scatter3 = axes[1, 0].scatter(tsne_result[:, 0], tsne_result[:, 1], c=cluster_labels, cmap='tab10', alpha=0.7, s=20)\n",
    "    axes[1, 0].set_title('t-SNE of Latent Space (Phase 4 (Last 64 Frames))')\n",
    "    plt.colorbar(scatter3, ax=axes[1, 0], label='Cluster ID')\n",
    "    \n",
    "    # ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼çµ±è¨ˆ\n",
    "    axes[1, 1].axis('off')\n",
    "    n_clusters = len(np.unique(cluster_labels))\n",
    "    stats_text = f\"Phase 4 (Last 64 Frames) Analysis:\\\\n\\\\n\"\n",
    "    stats_text += f\"Silhouette Score: {results['silhouette_score']:.4f}\\\\n\"\n",
    "    stats_text += f\"Improvement: {results['improvement']:+.1f}%\\\\n\\\\n\"\n",
    "    \n",
    "    for i in range(n_clusters):\n",
    "        mask = cluster_labels == i\n",
    "        count = np.sum(mask)\n",
    "        f_mean = f_values[mask].mean()\n",
    "        k_mean = k_values[mask].mean()\n",
    "        stats_text += f\"Cluster {i}: {count} samples\\\\n\"\n",
    "        stats_text += f\"  f_avg: {f_mean:.4f}\\\\n\"\n",
    "        stats_text += f\"  k_avg: {k_mean:.4f}\\\\n\\\\n\"\n",
    "    \n",
    "    axes[1, 1].text(0.1, 0.9, stats_text, transform=axes[1, 1].transAxes, \n",
    "                    fontsize=10, verticalalignment='top', fontfamily='monospace')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(SAVE_DIR, 'phase4_clustering_overview.png'), dpi=200, bbox_inches='tight'); plt.close()\n",
    "    \n",
    "    print(\"ğŸ“Š Visualization completed!\")\n",
    "    print(f\"ğŸ¬ Strategy: Last 64 frames captured more stable, mature patterns\")\n",
    "    print(f\"â­ Final Score: {results['silhouette_score']:.4f}\")\n",
    "\n",
    "# å¯è¦–åŒ–å®Ÿè¡Œ\n",
    "print(\"ğŸ¨ Creating visualizations...\")\n",
    "visualize_results_last64(results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
