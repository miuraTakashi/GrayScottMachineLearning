{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# ðŸš€ Gray-Scott Phase 2: GPUåŠ é€Ÿç‰ˆï¼ˆGoogle Colabï¼‰\n",
        "\n",
        "**ç›®æ¨™**: Phase 1 (0.565) â†’ Phase 2 (0.65+) ã¸ã®ã•ã‚‰ãªã‚‹å‘ä¸Š\n",
        "\n",
        "**ä¸»è¦æ”¹å–„ç‚¹**:\n",
        "- âœ… æ®‹å·®æŽ¥ç¶šï¼ˆResNetï¼‰\n",
        "- âœ… æ™‚ç©ºé–“æ³¨æ„æ©Ÿæ§‹\n",
        "- âœ… GPUé«˜é€ŸåŒ–ï¼ˆCPUæ¯” 5-10å€ï¼‰\n",
        "\n",
        "**å®Ÿè¡Œæ™‚é–“äºˆæ¸¬**: CPU 25-30åˆ† â†’ **GPU 3-5åˆ†** ðŸƒâ€â™‚ï¸ðŸ’¨\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ðŸ“‹ Step 1: ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# GPUç¢ºèªã¨ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—\n",
        "import torch\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory/1e9:.1f} GB\")\n",
        "else:\n",
        "    print(\"âš ï¸ GPU not available. Please enable GPU in Runtime > Change runtime type\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
