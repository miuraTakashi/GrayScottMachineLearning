#!/usr/bin/env python3
"""
Gray-Scott Project Cleanup Tool
ä¸è¦ãªå®Ÿé¨“ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ•´ç†
"""

import os
import shutil
from pathlib import Path

def analyze_files():
    """ç¾åœ¨ã®ãƒ•ã‚¡ã‚¤ãƒ«æ§‹æˆã‚’åˆ†æ"""
    
    print("ğŸ“‚ Gray-Scott ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ ãƒ•ã‚¡ã‚¤ãƒ«åˆ†æ")
    print("=" * 50)
    
    # å¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆä¿æŒã™ã¹ãï¼‰
    essential_files = {
        'src/train_autoencoder.py': 'âœ… å­¦ç¿’ãƒ¡ã‚¤ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆ',
        'src/cluster_analysis.py': 'âœ… ã‚¯ãƒ©ã‚¹ã‚¿åˆ†æ',
        'src/visualize_results.py': 'âœ… å¯è¦–åŒ–ï¼ˆä¿®æ­£æ¸ˆã¿ï¼‰',
        'src/simple_visualize.py': 'âœ… å¯è¦–åŒ–ï¼ˆã‚¨ãƒ©ãƒ¼å›é¿ç‰ˆï¼‰',
        'src/main_workflow.py': 'âœ… ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼çµ±åˆ',
        'README.md': 'âœ… ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆèª¬æ˜',
        'requirements.txt': 'âœ… ä¾å­˜é–¢ä¿‚',
    }
    
    # å®Ÿé¨“ãƒ»é–‹ç™ºç”¨ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆå‰Šé™¤å€™è£œï¼‰
    experimental_files = {
        'quick_fix_visualize.py': 'ğŸ§ª ä¸€æ™‚çš„ãªä¿®æ­£ãƒ„ãƒ¼ãƒ«',
        'scalable_improvements.py': 'ğŸ§ª ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£å®Ÿé¨“',
        'scalability_analysis.py': 'ğŸ§ª ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£åˆ†æ',
        'improvement_phase1.py': 'ğŸ§ª æ€§èƒ½æ”¹å–„å®Ÿé¨“',
        'quick_analysis.py': 'ğŸ§ª ã‚¯ã‚¤ãƒƒã‚¯åˆ†æ',
        'analyze_current_performance.py': 'ğŸ§ª æ€§èƒ½åˆ†æå®Ÿé¨“',
        'improve_classification_accuracy.py': 'ğŸ§ª ç²¾åº¦å‘ä¸Šå®Ÿé¨“',
        'test_frame_range.py': 'ğŸ§ª ãƒ•ãƒ¬ãƒ¼ãƒ ç¯„å›²ãƒ†ã‚¹ãƒˆ',
        'run_analysis.sh': 'ğŸ§ª åˆ†æå®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ',
    }
    
    print("ğŸ“‹ å¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«:")
    for file, desc in essential_files.items():
        status = "âœ“" if os.path.exists(file) else "âœ—"
        print(f"  {status} {file} - {desc}")
    
    print("\nğŸ§ª å®Ÿé¨“ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆå‰Šé™¤å€™è£œï¼‰:")
    existing_experimental = []
    for file, desc in experimental_files.items():
        if os.path.exists(file):
            existing_experimental.append(file)
            size = os.path.getsize(file) / 1024
            print(f"  ğŸ“„ {file} ({size:.1f}KB) - {desc}")
    
    return existing_experimental

def cleanup_files(file_list, create_backup=True):
    """ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
    
    if not file_list:
        print("ğŸ‰ å‰Šé™¤å¯¾è±¡ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯ã‚ã‚Šã¾ã›ã‚“")
        return
    
    if create_backup:
        # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        backup_dir = "backup_experimental_files"
        os.makedirs(backup_dir, exist_ok=True)
        print(f"ğŸ“¦ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ: {backup_dir}/")
    
    total_size = 0
    
    for file_path in file_list:
        try:
            size = os.path.getsize(file_path)
            total_size += size
            
            if create_backup:
                # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã«ç§»å‹•
                backup_path = os.path.join(backup_dir, os.path.basename(file_path))
                shutil.move(file_path, backup_path)
                print(f"  ğŸ“¦ {file_path} â†’ {backup_path}")
            else:
                # å®Œå…¨å‰Šé™¤
                os.remove(file_path)
                print(f"  ğŸ—‘ï¸  {file_path} å‰Šé™¤")
                
        except Exception as e:
            print(f"  âŒ {file_path} ã‚¨ãƒ©ãƒ¼: {e}")
    
    print(f"\nğŸ’¾ è§£æ”¾ã•ã‚ŒãŸå®¹é‡: {total_size/1024:.1f} KB")

def check_directory_structure():
    """ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ã®ç¢ºèª"""
    
    print("\nğŸ“ ç¾åœ¨ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ :")
    print("=" * 30)
    
    required_dirs = ['src', 'data', 'models', 'results', 'tests', 'docs', 'notebooks']
    
    for dir_name in required_dirs:
        if os.path.exists(dir_name):
            file_count = len([f for f in Path(dir_name).rglob('*') if f.is_file()])
            print(f"  âœ… {dir_name}/ ({file_count} files)")
        else:
            print(f"  âŒ {dir_name}/ (missing)")

def create_project_summary():
    """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ¦‚è¦ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ"""
    
    summary_content = """# Gray-Scott Machine Learning Project

## ğŸ¯ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ¦‚è¦
Gray-Scottãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ©Ÿæ¢°å­¦ç¿’ã«ã‚ˆã‚‹åˆ†é¡ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ

## ğŸ“ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ 
```
GrayScottMachineLearning/
â”œâ”€â”€ src/                    # ãƒ¡ã‚¤ãƒ³ã‚³ãƒ¼ãƒ‰
â”‚   â”œâ”€â”€ train_autoencoder.py    # å­¦ç¿’ãƒ¡ã‚¤ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
â”‚   â”œâ”€â”€ cluster_analysis.py     # ã‚¯ãƒ©ã‚¹ã‚¿åˆ†æ
â”‚   â”œâ”€â”€ visualize_results.py    # å¯è¦–åŒ–ï¼ˆä¿®æ­£æ¸ˆã¿ï¼‰
â”‚   â”œâ”€â”€ simple_visualize.py     # å¯è¦–åŒ–ï¼ˆã‚¨ãƒ©ãƒ¼å›é¿ç‰ˆï¼‰
â”‚   â””â”€â”€ main_workflow.py        # ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼çµ±åˆ
â”œâ”€â”€ data/                   # ãƒ‡ãƒ¼ã‚¿
â”‚   â””â”€â”€ gif/               # GIFãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ375å€‹ï¼‰
â”œâ”€â”€ models/                # å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«
â”œâ”€â”€ results/               # çµæœãƒ»ç”»åƒ
â”œâ”€â”€ tests/                 # ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«
â”œâ”€â”€ docs/                  # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
â”œâ”€â”€ notebooks/             # Jupyterãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯
â”œâ”€â”€ README.md              # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆèª¬æ˜
â””â”€â”€ requirements.txt       # ä¾å­˜é–¢ä¿‚
```

## ğŸš€ åŸºæœ¬çš„ãªä½¿ç”¨æ–¹æ³•

### 1. å­¦ç¿’å®Ÿè¡Œ
```bash
cd src
python train_autoencoder.py
```

### 2. å¯è¦–åŒ–
```bash
python simple_visualize.py  # ã‚¨ãƒ©ãƒ¼å›é¿ç‰ˆï¼ˆæ¨å¥¨ï¼‰
python visualize_results.py  # é€šå¸¸ç‰ˆ
```

### 3. çµ±åˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼
```bash
python main_workflow.py
```

## ğŸ“Š ç¾åœ¨ã®æ€§èƒ½
- 375ã‚µãƒ³ãƒ—ãƒ«ã€20ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼
- ã‚·ãƒ«ã‚¨ãƒƒãƒˆã‚¹ã‚³ã‚¢: 0.551
- ãƒ•ãƒ¬ãƒ¼ãƒ ç¯„å›²æŒ‡å®šæ©Ÿèƒ½ã‚ã‚Š

## ğŸ”§ é–‹ç™ºæ¸ˆã¿æ©Ÿèƒ½
- ãƒ•ãƒ¬ãƒ¼ãƒ ç¯„å›²æŒ‡å®šã§ã®GIFå‡¦ç†
- PCAãƒ»t-SNEå¯è¦–åŒ–
- f-kãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç©ºé–“åˆ†æ
- viridisã‚¨ãƒ©ãƒ¼å›é¿æ©Ÿèƒ½

---
Generated by cleanup tool
"""
    
    with open('PROJECT_SUMMARY.md', 'w', encoding='utf-8') as f:
        f.write(summary_content)
    
    print("ğŸ“‹ PROJECT_SUMMARY.md ã‚’ä½œæˆã—ã¾ã—ãŸ")

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    
    print("ğŸ§¹ Gray-Scott ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ãƒ„ãƒ¼ãƒ«")
    print("=" * 50)
    
    # ãƒ•ã‚¡ã‚¤ãƒ«åˆ†æ
    experimental_files = analyze_files()
    
    # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ç¢ºèª
    check_directory_structure()
    
    if experimental_files:
        print(f"\nğŸ—‚ï¸  å®Ÿé¨“ãƒ•ã‚¡ã‚¤ãƒ« {len(experimental_files)} å€‹ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")
        print("\nğŸ“ æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³:")
        print("1. ğŸ”„ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã—ã¦å‰Šé™¤ï¼ˆå®‰å…¨ï¼‰")
        print("2. ğŸ—‘ï¸  å®Œå…¨å‰Šé™¤ï¼ˆå®¹é‡ç¯€ç´„ï¼‰")
        print("3. â¹ï¸  ä½•ã‚‚ã—ãªã„")
        
        choice = input("\né¸æŠã—ã¦ãã ã•ã„ (1/2/3): ").strip()
        
        if choice == "1":
            print("\nğŸ”„ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã—ã¦å‰Šé™¤ã‚’å®Ÿè¡Œ...")
            cleanup_files(experimental_files, create_backup=True)
            print("âœ… å®Œäº†ï¼å®Ÿé¨“ãƒ•ã‚¡ã‚¤ãƒ«ã¯ backup_experimental_files/ ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸ")
            
        elif choice == "2":
            confirm = input("âš ï¸  å®Œå…¨å‰Šé™¤ã—ã¾ã™ã‹ï¼Ÿ (yes/no): ").strip().lower()
            if confirm == "yes":
                print("\nğŸ—‘ï¸  å®Œå…¨å‰Šé™¤ã‚’å®Ÿè¡Œ...")
                cleanup_files(experimental_files, create_backup=False)
                print("âœ… å®Œäº†ï¼")
            else:
                print("âŒ ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã—ãŸ")
                
        elif choice == "3":
            print("â¹ï¸  ä½•ã‚‚å¤‰æ›´ã—ã¾ã›ã‚“ã§ã—ãŸ")
            
        else:
            print("âŒ ç„¡åŠ¹ãªé¸æŠã§ã™")
    
    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ¦‚è¦ä½œæˆ
    create_project_summary()
    
    print("\nğŸ‰ ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†ï¼")
    print("ğŸ’¡ åŸºæœ¬çš„ãªè§£æã«ã¯ src/ ãƒ•ã‚©ãƒ«ãƒ€å†…ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ã§ååˆ†ã§ã™")

if __name__ == "__main__":
    main() 