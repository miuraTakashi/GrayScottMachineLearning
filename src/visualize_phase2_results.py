#!/usr/bin/env python3
"""
Phase 2 ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°çµæœã®å¯è¦–åŒ–
Google Colab ã§å®Ÿè¡Œã•ã‚ŒãŸPhase 2ã®çµæœã‚’è¡¨ç¤ºã™ã‚‹
"""

import pickle
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.manifold import TSNE
from sklearn.decomposition import PCA
from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score
import os

def load_phase2_results():
    """Phase 2ã®çµæœã‚’èª­ã¿è¾¼ã‚€"""
    results_path = 'results/phase2_results_gpu.pkl'
    
    if not os.path.exists(results_path):
        print(f"ã‚¨ãƒ©ãƒ¼: {results_path} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return None
    
    try:
        with open(results_path, 'rb') as f:
            results = pickle.load(f)
        print("Phase 2çµæœã®èª­ã¿è¾¼ã¿ãŒå®Œäº†ã—ã¾ã—ãŸ")
        return results
    except Exception as e:
        print(f"çµæœã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return None

def print_results_summary(results):
    """çµæœã®æ¦‚è¦ã‚’è¡¨ç¤º"""
    print("\n" + "="*50)
    print("Phase 2 ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°çµæœ æ¦‚è¦")
    print("="*50)
    
    if 'latent_vectors' in results:
        print(f"æ½œåœ¨ãƒ™ã‚¯ãƒˆãƒ«æ•°: {len(results['latent_vectors'])}")
        print(f"æ½œåœ¨æ¬¡å…ƒ: {results['latent_vectors'].shape[1] if len(results['latent_vectors'].shape) > 1 else 'N/A'}")
    
    if 'cluster_labels' in results:
        unique_labels = np.unique(results['cluster_labels'])
        print(f"ã‚¯ãƒ©ã‚¹ã‚¿æ•°: {len(unique_labels)}")
        print(f"ã‚¯ãƒ©ã‚¹ã‚¿ãƒ©ãƒ™ãƒ«: {unique_labels}")
        
        # å„ã‚¯ãƒ©ã‚¹ã‚¿ã®ã‚µãƒ³ãƒ—ãƒ«æ•°
        for label in unique_labels:
            count = np.sum(results['cluster_labels'] == label)
            percentage = (count / len(results['cluster_labels'])) * 100
            print(f"  ã‚¯ãƒ©ã‚¹ã‚¿ {label}: {count}ã‚µãƒ³ãƒ—ãƒ« ({percentage:.1f}%)")
    
    # è©•ä¾¡æŒ‡æ¨™
    if 'metrics' in results:
        metrics = results['metrics']
        print(f"\nè©•ä¾¡æŒ‡æ¨™:")
        if 'silhouette_score' in metrics:
            print(f"  ã‚·ãƒ«ã‚¨ãƒƒãƒˆã‚¹ã‚³ã‚¢: {metrics['silhouette_score']:.4f}")
        if 'calinski_harabasz_score' in metrics:
            print(f"  Calinski-Harabasz ã‚¹ã‚³ã‚¢: {metrics['calinski_harabasz_score']:.2f}")
        if 'davies_bouldin_score' in metrics:
            print(f"  Davies-Bouldin ã‚¹ã‚³ã‚¢: {metrics['davies_bouldin_score']:.4f}")
    
    # å­¦ç¿’æƒ…å ±
    if 'training_info' in results:
        info = results['training_info']
        print(f"\nå­¦ç¿’æƒ…å ±:")
        if 'final_loss' in info:
            print(f"  æœ€çµ‚æå¤±: {info['final_loss']:.6f}")
        if 'training_time' in info:
            print(f"  å­¦ç¿’æ™‚é–“: {info['training_time']:.1f}ç§’")
        if 'epochs' in info:
            print(f"  ã‚¨ãƒãƒƒã‚¯æ•°: {info['epochs']}")

def visualize_clustering_results(results):
    """ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°çµæœã‚’å¯è¦–åŒ–"""
    if 'latent_vectors' not in results or 'cluster_labels' not in results:
        print("å¯è¦–åŒ–ã«å¿…è¦ãªãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™")
        return
    
    latent_vectors = results['latent_vectors']
    cluster_labels = results['cluster_labels']
    f_values = results.get('f_values', None)
    k_values = results.get('k_values', None)
    
    # 6ã¤ã®ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆã‚’ä½œæˆï¼ˆ3x2ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆï¼‰
    fig, axes = plt.subplots(3, 2, figsize=(16, 18))
    fig.suptitle('Phase 2 ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°çµæœ', fontsize=16, fontweight='bold')
    
    # 1. PCA 2Då¯è¦–åŒ–
    pca = PCA(n_components=2)
    pca_result = pca.fit_transform(latent_vectors)
    
    scatter = axes[0, 0].scatter(pca_result[:, 0], pca_result[:, 1], 
                                c=cluster_labels, cmap='tab10', alpha=0.7)
    axes[0, 0].set_title(f'PCA 2D (åˆ†æ•£èª¬æ˜ç‡: {pca.explained_variance_ratio_.sum():.3f})')
    axes[0, 0].set_xlabel('PC1')
    axes[0, 0].set_ylabel('PC2')
    plt.colorbar(scatter, ax=axes[0, 0])
    
    # 2. t-SNE 2Då¯è¦–åŒ–
    tsne = TSNE(n_components=2, random_state=42, perplexity=30)
    tsne_result = tsne.fit_transform(latent_vectors)
    
    scatter = axes[0, 1].scatter(tsne_result[:, 0], tsne_result[:, 1], 
                                c=cluster_labels, cmap='tab10', alpha=0.7)
    axes[0, 1].set_title('t-SNE 2D')
    axes[0, 1].set_xlabel('t-SNE 1')
    axes[0, 1].set_ylabel('t-SNE 2')
    plt.colorbar(scatter, ax=axes[0, 1])
    
    # 3. f-k ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç©ºé–“ã§ã®åˆ†å¸ƒ
    if f_values is not None and k_values is not None:
        scatter = axes[1, 0].scatter(f_values, k_values, c=cluster_labels, 
                                   cmap='tab10', alpha=0.7, s=20)
        axes[1, 0].set_title('f-k ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç©ºé–“ã§ã®ã‚¯ãƒ©ã‚¹ã‚¿åˆ†å¸ƒ')
        axes[1, 0].set_xlabel('f (feed rate)')
        axes[1, 0].set_ylabel('k (kill rate)')
        axes[1, 0].grid(True, alpha=0.3)
        plt.colorbar(scatter, ax=axes[1, 0])
        
        # f-kç©ºé–“ã®ç¯„å›²ã‚’è¡¨ç¤º
        f_range = f"f: {f_values.min():.4f} - {f_values.max():.4f}"
        k_range = f"k: {k_values.min():.4f} - {k_values.max():.4f}"
        axes[1, 0].text(0.02, 0.98, f"{f_range}\n{k_range}", 
                       transform=axes[1, 0].transAxes, 
                       verticalalignment='top',
                       bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))
    else:
        axes[1, 0].text(0.5, 0.5, 'f-k ãƒ‡ãƒ¼ã‚¿ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“', 
                       ha='center', va='center', transform=axes[1, 0].transAxes)
        axes[1, 0].set_title('f-k ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç©ºé–“')
    
    # 4. f-kç©ºé–“ã®ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ï¼ˆã‚¯ãƒ©ã‚¹ã‚¿å¯†åº¦ï¼‰
    if f_values is not None and k_values is not None:
        # å„ã‚¯ãƒ©ã‚¹ã‚¿åˆ¥ã®æ•£å¸ƒå›³
        unique_labels = np.unique(cluster_labels)
        colors = plt.cm.tab10(np.linspace(0, 1, len(unique_labels)))
        
        axes[1, 1].set_title('f-kç©ºé–“ ã‚¯ãƒ©ã‚¹ã‚¿åˆ¥åˆ†å¸ƒ')
        axes[1, 1].set_xlabel('f (feed rate)')
        axes[1, 1].set_ylabel('k (kill rate)')
        
        for i, label in enumerate(unique_labels):
            mask = cluster_labels == label
            if np.sum(mask) > 0:
                f_cluster = f_values[mask]
                k_cluster = k_values[mask]
                axes[1, 1].scatter(f_cluster, k_cluster, 
                                 color=colors[i], alpha=0.7, s=25,
                                 label=f'Cluster {label} ({np.sum(mask)})')
        
        axes[1, 1].legend(loc='upper right', fontsize=9)
        axes[1, 1].grid(True, alpha=0.3)
        
        # f-kç©ºé–“ã®çµ±è¨ˆæƒ…å ±ã‚’è¿½åŠ 
        stats_text = f"Total samples: {len(f_values)}\n"
        stats_text += f"f range: [{f_values.min():.4f}, {f_values.max():.4f}]\n"
        stats_text += f"k range: [{k_values.min():.4f}, {k_values.max():.4f}]"
        axes[1, 1].text(0.02, 0.02, stats_text, 
                       transform=axes[1, 1].transAxes, 
                       verticalalignment='bottom',
                       bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))
    else:
        axes[1, 1].text(0.5, 0.5, 'f-k ãƒ‡ãƒ¼ã‚¿ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“', 
                       ha='center', va='center', transform=axes[1, 1].transAxes)
        axes[1, 1].set_title('f-kç©ºé–“ å¯†åº¦åˆ†å¸ƒ')
    
    # 5. ã‚¯ãƒ©ã‚¹ã‚¿ã‚µã‚¤ã‚ºåˆ†å¸ƒ
    unique_labels, counts = np.unique(cluster_labels, return_counts=True)
    bars = axes[2, 0].bar(unique_labels, counts, color='skyblue', alpha=0.7)
    axes[2, 0].set_title('ã‚¯ãƒ©ã‚¹ã‚¿ã‚µã‚¤ã‚ºåˆ†å¸ƒ')
    axes[2, 0].set_xlabel('ã‚¯ãƒ©ã‚¹ã‚¿ãƒ©ãƒ™ãƒ«')
    axes[2, 0].set_ylabel('ã‚µãƒ³ãƒ—ãƒ«æ•°')
    
    # ãƒãƒ¼ã®ä¸Šã«æ•°å€¤ã‚’è¡¨ç¤º
    for bar, count in zip(bars, counts):
        axes[2, 0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 5,
                       str(count), ha='center', va='bottom')
    
    # 6. è©•ä¾¡æŒ‡æ¨™è¡¨ç¤º
    axes[2, 1].axis('off')
    metrics_text = "è©•ä¾¡æŒ‡æ¨™\n\n"
    
    if 'metrics' in results:
        metrics = results['metrics']
        if 'silhouette_score' in metrics:
            metrics_text += f"ã‚·ãƒ«ã‚¨ãƒƒãƒˆã‚¹ã‚³ã‚¢: {metrics['silhouette_score']:.4f}\n"
        if 'calinski_harabasz_score' in metrics:
            metrics_text += f"Calinski-Harabasz: {metrics['calinski_harabasz_score']:.2f}\n"
        if 'davies_bouldin_score' in metrics:
            metrics_text += f"Davies-Bouldin: {metrics['davies_bouldin_score']:.4f}\n"
    
    # Phase 1ã¨ã®æ¯”è¼ƒæƒ…å ±ãŒã‚ã‚Œã°è¡¨ç¤º
    if 'comparison' in results:
        comp = results['comparison']
        metrics_text += f"\nPhase 1ã¨ã®æ¯”è¼ƒ:\n"
        if 'silhouette_improvement' in comp:
            metrics_text += f"ã‚·ãƒ«ã‚¨ãƒƒãƒˆæ”¹å–„: +{comp['silhouette_improvement']:.1f}%\n"
        if 'phase1_silhouette' in comp:
            metrics_text += f"Phase 1: {comp['phase1_silhouette']:.4f}\n"
            metrics_text += f"Phase 2: {comp['phase2_silhouette']:.4f}\n"
    
    axes[2, 1].text(0.1, 0.9, metrics_text, transform=axes[2, 1].transAxes,
                   fontsize=12, verticalalignment='top',
                   bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))
    
    # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆèª¿æ•´
    plt.tight_layout()
    
    # çµæœã‚’ä¿å­˜
    output_path = 'results/phase2_clustering_visualization_with_fk.png'
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    print(f"\nå¯è¦–åŒ–çµæœã‚’ä¿å­˜ã—ã¾ã—ãŸ: {output_path}")
    
    plt.show()

def compare_with_phase1(results):
    """Phase 1ã¨ã®æ¯”è¼ƒ"""
    phase1_path = 'results/phase1_comparison_results.pkl'
    
    if not os.path.exists(phase1_path):
        print("Phase 1ã®çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚æ¯”è¼ƒã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
        return
    
    try:
        with open(phase1_path, 'rb') as f:
            phase1_results = pickle.load(f)
        
        print("\n" + "="*50)
        print("Phase 1 vs Phase 2 æ¯”è¼ƒ")
        print("="*50)
        
        # Phase 1ã®çµæœ
        if 'phase1_metrics' in phase1_results:
            p1_metrics = phase1_results['phase1_metrics']
            print(f"Phase 1 ã‚·ãƒ«ã‚¨ãƒƒãƒˆã‚¹ã‚³ã‚¢: {p1_metrics.get('silhouette_score', 'N/A')}")
        
        # Phase 2ã®çµæœ
        if 'metrics' in results:
            p2_metrics = results['metrics']
            print(f"Phase 2 ã‚·ãƒ«ã‚¨ãƒƒãƒˆã‚¹ã‚³ã‚¢: {p2_metrics.get('silhouette_score', 'N/A')}")
            
            # æ”¹å–„ç‡ã‚’è¨ˆç®—
            if 'phase1_metrics' in phase1_results and 'silhouette_score' in p1_metrics and 'silhouette_score' in p2_metrics:
                p1_score = p1_metrics['silhouette_score']
                p2_score = p2_metrics['silhouette_score']
                improvement = ((p2_score - p1_score) / p1_score) * 100
                print(f"æ”¹å–„ç‡: {improvement:+.1f}%")
                
                if improvement > 15:
                    print("ğŸ‰ ç›®æ¨™ã®15%æ”¹å–„ã‚’é”æˆã—ã¾ã—ãŸï¼")
                else:
                    print("ğŸ“Š æ›´ãªã‚‹æ”¹å–„ã®ä½™åœ°ãŒã‚ã‚Šã¾ã™")
    
    except Exception as e:
        print(f"Phase 1ã¨ã®æ¯”è¼ƒã‚¨ãƒ©ãƒ¼: {e}")

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("Phase 2 ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°çµæœã®å¯è¦–åŒ–ã‚’é–‹å§‹ã—ã¾ã™...")
    
    # çµæœã‚’èª­ã¿è¾¼ã¿
    results = load_phase2_results()
    if results is None:
        return
    
    # çµæœã®æ¦‚è¦ã‚’è¡¨ç¤º
    print_results_summary(results)
    
    # å¯è¦–åŒ–
    visualize_clustering_results(results)
    
    # Phase 1ã¨ã®æ¯”è¼ƒ
    compare_with_phase1(results)
    
    print("\nâœ… å¯è¦–åŒ–ãŒå®Œäº†ã—ã¾ã—ãŸï¼")

if __name__ == "__main__":
    main() 