#!/usr/bin/env python3
"""
k=4 æœ€é©ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼æ•°ã§ã®1500ã‚µãƒ³ãƒ—ãƒ«å¯è¦–åŒ–
ãƒãƒ©ãƒ³ã‚¹é‡è¦–ã®æ¨å¥¨å€¤ã§ã®çµ±åˆå¯è¦–åŒ–
"""

import os
import pickle
import numpy as np
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
from sklearn.metrics import silhouette_score
from matplotlib.patches import Patch
import matplotlib as mpl

def load_and_process_k4_data():
    """1500ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’k=4ã§ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°å®Ÿè¡Œ"""
    
    print("ğŸ“‚ 1500ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­...")
    
    data_file = '../results/latent_representations_frames_all.pkl'
    
    if not os.path.exists(data_file):
        print(f"âŒ {data_file} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return None
    
    with open(data_file, 'rb') as f:
        data = pickle.load(f)
    
    latent_vectors = data['latent_vectors']  # (1500, 128)
    filenames = data['filenames']            # 1500å€‹
    f_values = data['f_values']              # 1500å€‹
    k_values = data['k_values']              # 1500å€‹
    
    print(f"âœ… ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {len(filenames)} ã‚µãƒ³ãƒ—ãƒ«")
    
    # k=4ã§ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°å®Ÿè¡Œ
    print("ğŸ” k=4ã§ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°å®Ÿè¡Œä¸­...")
    n_clusters = 4
    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
    cluster_labels = kmeans.fit_predict(latent_vectors)
    silhouette = silhouette_score(latent_vectors, cluster_labels)
    print(f"   ã‚·ãƒ«ã‚¨ãƒƒãƒˆã‚¹ã‚³ã‚¢: {silhouette:.3f}")
    
    # ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼åˆ†å¸ƒè¡¨ç¤º
    unique, counts = np.unique(cluster_labels, return_counts=True)
    print(f"   ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼åˆ†å¸ƒ:")
    for cluster, count in zip(unique, counts):
        print(f"     Cluster {cluster}: {count} samples ({count/len(cluster_labels)*100:.1f}%)")
    
    # æ¬¡å…ƒå‰Šæ¸›å®Ÿè¡Œ
    print("ğŸ“‰ æ¬¡å…ƒå‰Šæ¸›å®Ÿè¡Œä¸­...")
    pca = PCA(n_components=2, random_state=42)
    pca_result = pca.fit_transform(latent_vectors)
    print(f"   PCAå¯„ä¸ç‡: PC1={pca.explained_variance_ratio_[0]:.3f}, PC2={pca.explained_variance_ratio_[1]:.3f}")
    
    tsne = TSNE(n_components=2, random_state=42, perplexity=30)
    tsne_result = tsne.fit_transform(latent_vectors)
    print("   t-SNEå®Œäº†")
    
    return {
        'f_values': f_values,
        'k_values': k_values,
        'cluster_labels': cluster_labels,
        'pca_result': pca_result,
        'tsne_result': tsne_result,
        'silhouette_score': silhouette,
        'n_samples': len(filenames),
        'cluster_counts': counts
    }

def create_k4_visualization(results, figsize=(15, 12), dpi=300, save_name='gray_scott_clustering_results_k4_1500samples.png'):
    """k=4ã§ã®çµ±åˆå¯è¦–åŒ–ï¼ˆ1500ã‚µãƒ³ãƒ—ãƒ«ç‰ˆï¼‰"""
    
    f_values = results['f_values']
    k_values = results['k_values']
    cluster_labels = results['cluster_labels']
    latent_2d_pca = results['pca_result']
    latent_2d_tsne = results['tsne_result']
    
    print(f"ğŸ¨ k=4çµ±åˆå¯è¦–åŒ–ä½œæˆä¸­ (1500ã‚µãƒ³ãƒ—ãƒ«)...")
    
    # å®‰å…¨ãªã‚«ãƒ©ãƒ¼ãƒãƒƒãƒ—ã‚’é¸æŠ
    try:
        colormap = 'viridis'
        test_cmap = plt.cm.get_cmap(colormap)
    except:
        colormap = 'Set1'  # k=4ãªã®ã§ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«ã‚«ãƒ©ãƒ¼ã‚‚ä½¿ç”¨å¯èƒ½
        print(f"âš ï¸  viridis not available, using {colormap}")
    
    # k=4å°‚ç”¨ã®è‰²è¨­å®š
    cluster_colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']  # è¦‹ã‚„ã™ã„4è‰²
    cluster_names = ['Pattern A', 'Pattern B', 'Pattern C', 'Pattern D']
    
    fig, axes = plt.subplots(2, 2, figsize=figsize)
    
    # 1. f-kç©ºé–“ã§ã®ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°çµæœ
    for i, cluster in enumerate(np.unique(cluster_labels)):
        mask = cluster_labels == cluster
        count = np.sum(mask)
        axes[0, 0].scatter(f_values[mask], k_values[mask], 
                           c=cluster_colors[i], alpha=0.7, s=25,
                           label=f'{cluster_names[i]} ({count} samples)')
    
    axes[0, 0].set_xlabel('f parameter', fontsize=12)
    axes[0, 0].set_ylabel('k parameter', fontsize=12)
    axes[0, 0].set_title('Clustering Results in f-k Space\n(k=4, 1500 samples)', fontsize=14, fontweight='bold')
    axes[0, 0].legend(loc='upper right', fontsize=10)
    axes[0, 0].grid(True, alpha=0.3)
    axes[0, 0].invert_yaxis()
    
    # 2. PCAå¯è¦–åŒ–
    for i, cluster in enumerate(np.unique(cluster_labels)):
        mask = cluster_labels == cluster
        count = np.sum(mask)
        axes[0, 1].scatter(latent_2d_pca[mask, 0], latent_2d_pca[mask, 1], 
                           c=cluster_colors[i], alpha=0.7, s=25,
                           label=f'{cluster_names[i]} ({count})')
    
    axes[0, 1].set_xlabel('PCA Component 1', fontsize=12)
    axes[0, 1].set_ylabel('PCA Component 2', fontsize=12)
    axes[0, 1].set_title('PCA Visualization of Latent Space\n(k=4, 1500 samples)', fontsize=14, fontweight='bold')
    axes[0, 1].legend(loc='upper right', fontsize=10)
    axes[0, 1].grid(True, alpha=0.3)
    
    # 3. t-SNEå¯è¦–åŒ–
    for i, cluster in enumerate(np.unique(cluster_labels)):
        mask = cluster_labels == cluster
        count = np.sum(mask)
        axes[1, 0].scatter(latent_2d_tsne[mask, 0], latent_2d_tsne[mask, 1], 
                           c=cluster_colors[i], alpha=0.7, s=25,
                           label=f'{cluster_names[i]} ({count})')
    
    axes[1, 0].set_xlabel('t-SNE Component 1', fontsize=12)
    axes[1, 0].set_ylabel('t-SNE Component 2', fontsize=12)
    axes[1, 0].set_title('t-SNE Visualization of Latent Space\n(k=4, 1500 samples)', fontsize=14, fontweight='bold')
    axes[1, 0].legend(loc='upper right', fontsize=10)
    axes[1, 0].grid(True, alpha=0.3)
    
    # 4. f-kå¹³é¢ã®ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ï¼ˆk=4ç”¨ã«æœ€é©åŒ–ï¼‰
    f_unique = np.unique(f_values)
    k_unique = np.unique(k_values)
    
    heatmap_data = np.full((len(f_unique), len(k_unique)), np.nan)
    
    for i, f in enumerate(f_values):
        k = k_values[i]
        cluster = cluster_labels[i]
        
        f_idx = np.where(f_unique == f)[0][0]
        k_idx = np.where(k_unique == k)[0][0]
        heatmap_data[f_idx, k_idx] = cluster
    
    # k=4ç”¨ã®ã‚«ã‚¹ã‚¿ãƒ ã‚«ãƒ©ãƒ¼ãƒãƒƒãƒ—
    from matplotlib.colors import ListedColormap
    custom_cmap = ListedColormap(cluster_colors)
    
    im = axes[1, 1].imshow(heatmap_data, cmap=custom_cmap, aspect='auto', origin='upper', vmin=0, vmax=3)
    
    # ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã®è»¸è¨­å®šï¼ˆk=4ãªã®ã§è©³ç´°ã«è¡¨ç¤ºï¼‰
    step_k = max(1, len(k_unique) // 8)
    step_f = max(1, len(f_unique) // 8)
    
    axes[1, 1].set_xticks(range(0, len(k_unique), step_k))
    axes[1, 1].set_yticks(range(0, len(f_unique), step_f))
    axes[1, 1].set_xticklabels([f'{k:.4f}' for k in k_unique[::step_k]], rotation=45, fontsize=9)
    axes[1, 1].set_yticklabels([f'{f:.4f}' for f in f_unique[::step_f]], fontsize=9)
    axes[1, 1].set_xlabel('k parameter', fontsize=12)
    axes[1, 1].set_ylabel('f parameter', fontsize=12)
    axes[1, 1].set_title('Cluster Heatmap in f-k Space\n(k=4, 1500 samples)', fontsize=14, fontweight='bold')
    axes[1, 1].invert_yaxis()
    
    # k=4ç”¨ã®å‡¡ä¾‹ï¼ˆ4ã¤ãªã®ã§å…¨ã¦è¡¨ç¤ºï¼‰
    legend_elements = [Patch(facecolor=cluster_colors[i], 
                           label=cluster_names[i]) 
                     for i in range(4)]
    axes[1, 1].legend(handles=legend_elements, bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=10)
    
    # å…¨ä½“ã®ã‚¿ã‚¤ãƒˆãƒ«
    fig.suptitle(f'Gray-Scott Clustering Results (k=4, 1500 samples)\nSilhouette Score: {results["silhouette_score"]:.3f}', 
                 fontsize=16, fontweight='bold', y=0.95)
    
    plt.tight_layout()
    
    # ä¿å­˜ãƒ‘ã‚¹ã®ä¿®æ­£
    if not save_name.startswith('../results/'):
        save_name = f'../results/{save_name}'
    
    plt.savefig(save_name, dpi=dpi, bbox_inches='tight')
    plt.show()
    
    print(f"âœ… Saved: {save_name}")

def analyze_k4_clusters(results):
    """k=4ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã®è©³ç´°åˆ†æ"""
    
    print(f"\nğŸ“Š k=4ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼è©³ç´°åˆ†æ")
    print("=" * 50)
    
    f_values = results['f_values']
    k_values = results['k_values']
    cluster_labels = results['cluster_labels']
    cluster_counts = results['cluster_counts']
    
    cluster_names = ['Pattern A', 'Pattern B', 'Pattern C', 'Pattern D']
    
    for cluster in range(4):
        mask = cluster_labels == cluster
        count = np.sum(mask)
        
        f_mean = f_values[mask].mean()
        k_mean = k_values[mask].mean()
        f_std = f_values[mask].std()
        k_std = k_values[mask].std()
        f_range = f_values[mask].max() - f_values[mask].min()
        k_range = k_values[mask].max() - k_values[mask].min()
        
        print(f"\nğŸ¯ {cluster_names[cluster]} (Cluster {cluster}):")
        print(f"   ã‚µãƒ³ãƒ—ãƒ«æ•°: {count} ({count/len(cluster_labels)*100:.1f}%)")
        print(f"   få€¤: {f_mean:.4f} Â± {f_std:.4f} (ç¯„å›²: {f_range:.4f})")
        print(f"   kå€¤: {k_mean:.4f} Â± {k_std:.4f} (ç¯„å›²: {k_range:.4f})")
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ç‰¹å¾´æ¨å®š
        if f_mean < 0.025:
            pattern_type = "å®‰å®šãƒ‘ã‚¿ãƒ¼ãƒ³ (ä½få€¤)"
        elif f_mean > 0.045:
            pattern_type = "å‹•çš„ãƒ‘ã‚¿ãƒ¼ãƒ³ (é«˜få€¤)"
        elif k_mean < 0.050:
            pattern_type = "æ‹¡æ•£ãƒ‘ã‚¿ãƒ¼ãƒ³ (ä½kå€¤)"
        else:
            pattern_type = "è¤‡é›‘ãƒ‘ã‚¿ãƒ¼ãƒ³ (é«˜kå€¤)"
        
        print(f"   æ¨å®šãƒ‘ã‚¿ãƒ¼ãƒ³: {pattern_type}")

def print_k4_comparison():
    """k=4ã¨ä»–ã®ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼æ•°ã¨ã®æ¯”è¼ƒ"""
    
    print(f"\nğŸ“ˆ k=4 vs ä»–ã®ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼æ•°æ¯”è¼ƒ")
    print("=" * 50)
    print(f"ğŸ¯ k=4ã®åˆ©ç‚¹:")
    print(f"   âœ… è§£é‡ˆã—ã‚„ã™ã„4ã¤ã®ä¸»è¦ãƒ‘ã‚¿ãƒ¼ãƒ³")
    print(f"   âœ… ãƒãƒ©ãƒ³ã‚¹ã®è‰¯ã„ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã‚µã‚¤ã‚º")
    print(f"   âœ… ååˆ†ãªçµ±è¨ˆçš„ä¿¡é ¼æ€§")
    print(f"   âœ… å¯è¦–åŒ–ã§ã®è‰²åˆ†ã‘ãŒè¦‹ã‚„ã™ã„")
    
    print(f"\nğŸ”„ ä»–ã®é¸æŠè‚¢:")
    print(f"   k=2: ã‚ˆã‚Šå¤§ã¾ã‹ãªåˆ†é¡ï¼ˆæœ€é«˜ã‚·ãƒ«ã‚¨ãƒƒãƒˆã‚¹ã‚³ã‚¢ï¼‰")
    print(f"   k=20: å¾“æ¥ã®375ã‚µãƒ³ãƒ—ãƒ«æ™‚ä»£ã¨ã®æ¯”è¼ƒç”¨")
    print(f"   k=30+: éå¸¸ã«ç´°ã‹ã„åˆ†é¡ï¼ˆç ”ç©¶ç”¨ï¼‰")

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    
    print("ğŸ¨ Gray-Scott k=4æœ€é©ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼å¯è¦–åŒ–")
    print("=" * 50)
    print(f"ğŸ”§ Matplotlib version: {mpl.__version__}")
    
    # ãƒ‡ãƒ¼ã‚¿å‡¦ç†
    results = load_and_process_k4_data()
    if results is None:
        return
    
    # k=4çµ±åˆå¯è¦–åŒ–ä½œæˆ
    create_k4_visualization(results)
    
    # ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼è©³ç´°åˆ†æ
    analyze_k4_clusters(results)
    
    # æ¯”è¼ƒæƒ…å ±è¡¨ç¤º
    print_k4_comparison()
    
    print(f"\nğŸ‰ k=4å¯è¦–åŒ–å®Œäº†!")
    print(f"ğŸ“ ä¿å­˜ãƒ•ã‚¡ã‚¤ãƒ«: gray_scott_clustering_results_k4_1500samples.png")
    print(f"ğŸ¯ æœ€é©ãªãƒãƒ©ãƒ³ã‚¹é‡è¦–ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼æ•°ã§ã®åˆ†æçµæœã§ã™")

if __name__ == "__main__":
    main() 