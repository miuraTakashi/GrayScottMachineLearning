{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# ğŸš€ Gray-Scott Phase 3: ãƒãƒ«ãƒã‚¹ã‚±ãƒ¼ãƒ«ç‰¹å¾´èåˆï¼ˆGoogle Colabï¼‰\n",
        "\n",
        "**ç›®æ¨™**: Phase 2 (0.467) â†’ Phase 3 (0.55+) ã¸ã®ã•ã‚‰ãªã‚‹å‘ä¸Š\n",
        "\n",
        "**ä¸»è¦æ”¹å–„ç‚¹**:\n",
        "- âœ… ãƒãƒ«ãƒã‚¹ã‚±ãƒ¼ãƒ«ç‰¹å¾´èåˆï¼ˆMulti-Scale Feature Fusionï¼‰\n",
        "- âœ… é«˜åº¦ãªãƒ‡ãƒ¼ã‚¿æ‹¡å¼µæˆ¦ç•¥ï¼ˆAdvanced Data Augmentationï¼‰\n",
        "- âœ… æ”¹è‰¯ã•ã‚ŒãŸè¨“ç·´ãƒ«ãƒ¼ãƒ—ï¼ˆEnhanced Training Loopï¼‰\n",
        "- âœ… GPUé«˜é€ŸåŒ–ï¼ˆCPUæ¯” 5-10å€ï¼‰\n",
        "- âœ… Google Driveé€£æº\n",
        "\n",
        "**å‰ææ¡ä»¶**: Google Driveã®`ãƒã‚¤ãƒ‰ãƒ©ã‚¤ãƒ–/GrayScottML/gif/`ã«1500å€‹ã®GIFãƒ•ã‚¡ã‚¤ãƒ«ã‚’é…ç½®\n",
        "\n",
        "**å®Ÿè¡Œæ™‚é–“**: **GPU 5-8åˆ†** ğŸƒâ€â™‚ï¸ğŸ’¨\n",
        "\n",
        "**æ½œåœ¨æ¬¡å…ƒ**: 512æ¬¡å…ƒï¼ˆPhase 2ã®2å€ï¼‰\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ğŸ“‹ Step 1: ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ— & Google Driveæ¥ç¶š\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "import imageio.v2 as imageio\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "import time\n",
        "import pickle\n",
        "from typing import List, Tuple, Dict, Optional\n",
        "\n",
        "# GPUç¢ºèª\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory/1e9:.1f} GB\")\n",
        "    device = torch.device('cuda')\n",
        "    # GPUæœ€é©åŒ–è¨­å®š\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    torch.backends.cudnn.deterministic = False\n",
        "else:\n",
        "    print(\"âš ï¸ GPU not available. Please enable GPU in Runtime > Change runtime type\")\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "print(f\"ğŸš€ Phase 3 Using device: {device}\")\n",
        "\n",
        "# ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n",
        "try:\n",
        "    import imageio\n",
        "    import seaborn\n",
        "    print(\"âœ… All packages available\")\n",
        "except ImportError:\n",
        "    print(\"ğŸ“¦ Installing required packages...\")\n",
        "    %pip install imageio scikit-learn seaborn\n",
        "    import imageio\n",
        "    import seaborn\n",
        "    print(\"âœ… Packages installed successfully\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Google Driveæ¥ç¶šã¨ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹ç¢ºèª\n",
        "from google.colab import drive\n",
        "\n",
        "# Google Driveã‚’ãƒã‚¦ãƒ³ãƒˆ\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹è¨­å®š\n",
        "GIF_FOLDER_PATH = '/content/drive/MyDrive/GrayScottML/gif'\n",
        "\n",
        "# ãƒ‡ãƒ¼ã‚¿ç¢ºèª\n",
        "if os.path.exists(GIF_FOLDER_PATH):\n",
        "    gif_files = [f for f in os.listdir(GIF_FOLDER_PATH) if f.endswith('.gif')]\n",
        "    gif_count = len(gif_files)\n",
        "    print(f\"âœ… Google Drive connected successfully!\")\n",
        "    print(f\"ğŸ“ Path: {GIF_FOLDER_PATH}\")\n",
        "    print(f\"ğŸ¬ GIF files found: {gif_count}\")\n",
        "    \n",
        "    if gif_count >= 1000:\n",
        "        print(\"ğŸ‰ Ready for Phase 3 training!\")\n",
        "    else:\n",
        "        print(f\"âš ï¸ Not enough files. Expected: 1500, Found: {gif_count}\")\n",
        "        print(\"Please upload more GIF files to Google Drive.\")\n",
        "else:\n",
        "    print(\"âŒ Google Drive path not found!\")\n",
        "    print(f\"Expected path: {GIF_FOLDER_PATH}\")\n",
        "    print(\"Please ensure the following structure exists:\")\n",
        "    print(\"  MyDrive/\")\n",
        "    print(\"  â””â”€â”€ GrayScottML/\")\n",
        "    print(\"      â””â”€â”€ gif/\")\n",
        "    print(\"          â”œâ”€â”€ GrayScott-f0.0100-k0.0400-00.gif\")\n",
        "    print(\"          â””â”€â”€ ... (1500 files)\")\n",
        "    raise FileNotFoundError(\"Please set up the correct folder structure in Google Drive\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ğŸ§  Step 2: Phase 3 ãƒ¢ãƒ‡ãƒ«å®Ÿè£…\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ================================\n",
        "# 1. é«˜åº¦ãªãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã‚·ã‚¹ãƒ†ãƒ \n",
        "# ================================\n",
        "\n",
        "class GrayScottAugmentation:\n",
        "    \"\"\"Gray-Scottå°‚ç”¨ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã‚¯ãƒ©ã‚¹\"\"\"\n",
        "    \n",
        "    def __init__(self, \n",
        "                 temporal_shift_prob=0.3,\n",
        "                 spatial_flip_prob=0.5,\n",
        "                 noise_prob=0.2,\n",
        "                 intensity_prob=0.3,\n",
        "                 temporal_crop_prob=0.2):\n",
        "        self.temporal_shift_prob = temporal_shift_prob\n",
        "        self.spatial_flip_prob = spatial_flip_prob\n",
        "        self.noise_prob = noise_prob\n",
        "        self.intensity_prob = intensity_prob\n",
        "        self.temporal_crop_prob = temporal_crop_prob\n",
        "    \n",
        "    def temporal_shift(self, tensor, max_shift=3):\n",
        "        \"\"\"æ™‚é–“è»¸ã‚·ãƒ•ãƒˆ\"\"\"\n",
        "        if np.random.random() < self.temporal_shift_prob:\n",
        "            shift = np.random.randint(-max_shift, max_shift + 1)\n",
        "            if shift != 0:\n",
        "                tensor = torch.roll(tensor, shift, dims=1)  # æ™‚é–“è»¸ã§ã‚·ãƒ•ãƒˆ\n",
        "        return tensor\n",
        "    \n",
        "    def spatial_flip(self, tensor):\n",
        "        \"\"\"ç©ºé–“è»¸åè»¢\"\"\"\n",
        "        if np.random.random() < self.spatial_flip_prob:\n",
        "            # æ°´å¹³åè»¢\n",
        "            if np.random.random() < 0.5:\n",
        "                tensor = torch.flip(tensor, dims=[3])  # widthè»¸\n",
        "            # å‚ç›´åè»¢\n",
        "            if np.random.random() < 0.5:\n",
        "                tensor = torch.flip(tensor, dims=[2])  # heightè»¸\n",
        "        return tensor\n",
        "    \n",
        "    def add_noise(self, tensor, noise_std=0.02):\n",
        "        \"\"\"ã‚¬ã‚¦ã‚·ã‚¢ãƒ³ãƒã‚¤ã‚ºè¿½åŠ \"\"\"\n",
        "        if np.random.random() < self.noise_prob:\n",
        "            noise = torch.randn_like(tensor) * noise_std\n",
        "            tensor = torch.clamp(tensor + noise, 0, 1)\n",
        "        return tensor\n",
        "    \n",
        "    def intensity_transform(self, tensor, gamma_range=(0.8, 1.2)):\n",
        "        \"\"\"å¼·åº¦å¤‰æ›ï¼ˆã‚¬ãƒ³ãƒè£œæ­£ï¼‰\"\"\"\n",
        "        if np.random.random() < self.intensity_prob:\n",
        "            gamma = np.random.uniform(*gamma_range)\n",
        "            tensor = torch.pow(tensor, gamma)\n",
        "        return tensor\n",
        "    \n",
        "    def temporal_crop(self, tensor, crop_ratio=0.1):\n",
        "        \"\"\"æ™‚é–“è»¸ã‚¯ãƒ­ãƒƒãƒ—\"\"\"\n",
        "        if np.random.random() < self.temporal_crop_prob:\n",
        "            T = tensor.shape[1]\n",
        "            crop_size = int(T * crop_ratio)\n",
        "            start_idx = np.random.randint(0, crop_size + 1)\n",
        "            end_idx = T - np.random.randint(0, crop_size + 1)\n",
        "            \n",
        "            # ã‚¯ãƒ­ãƒƒãƒ—ã—ãŸéƒ¨åˆ†ã‚’è£œé–“ã§åŸ‹ã‚ã‚‹\n",
        "            cropped = tensor[:, start_idx:end_idx]\n",
        "            tensor = F.interpolate(cropped.unsqueeze(0), size=(T, tensor.shape[2], tensor.shape[3]), \n",
        "                                 mode='trilinear', align_corners=False).squeeze(0)\n",
        "        return tensor\n",
        "    \n",
        "    def __call__(self, tensor):\n",
        "        \"\"\"å…¨ã¦ã®æ‹¡å¼µã‚’é©ç”¨\"\"\"\n",
        "        tensor = self.temporal_shift(tensor)\n",
        "        tensor = self.spatial_flip(tensor)\n",
        "        tensor = self.add_noise(tensor)\n",
        "        tensor = self.intensity_transform(tensor)\n",
        "        tensor = self.temporal_crop(tensor)\n",
        "        return tensor\n",
        "\n",
        "print(\"âœ… ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã‚·ã‚¹ãƒ†ãƒ å®šç¾©å®Œäº†\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ================================\n",
        "# 2. ãƒãƒ«ãƒã‚¹ã‚±ãƒ¼ãƒ«ç‰¹å¾´èåˆ & æ™‚ç©ºé–“æ³¨æ„æ©Ÿæ§‹\n",
        "# ================================\n",
        "\n",
        "class MultiScaleFeatureFusion(nn.Module):\n",
        "    \"\"\"ãƒãƒ«ãƒã‚¹ã‚±ãƒ¼ãƒ«ç‰¹å¾´èåˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«\"\"\"\n",
        "    \n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(MultiScaleFeatureFusion, self).__init__()\n",
        "        \n",
        "        # ç•°ãªã‚‹ã‚«ãƒ¼ãƒãƒ«ã‚µã‚¤ã‚ºã§ã®ä¸¦åˆ—å‡¦ç†\n",
        "        self.scale1 = nn.Sequential(\n",
        "            nn.Conv3d(in_channels, out_channels//4, kernel_size=(1, 1, 1), padding=0),\n",
        "            nn.BatchNorm3d(out_channels//4),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        \n",
        "        self.scale2 = nn.Sequential(\n",
        "            nn.Conv3d(in_channels, out_channels//4, kernel_size=(3, 3, 3), padding=1),\n",
        "            nn.BatchNorm3d(out_channels//4),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        \n",
        "        self.scale3 = nn.Sequential(\n",
        "            nn.Conv3d(in_channels, out_channels//4, kernel_size=(5, 5, 5), padding=2),\n",
        "            nn.BatchNorm3d(out_channels//4),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        \n",
        "        # ãƒ—ãƒ¼ãƒªãƒ³ã‚°åˆ†å²\n",
        "        self.pool_branch = nn.Sequential(\n",
        "            nn.AvgPool3d(kernel_size=3, stride=1, padding=1),\n",
        "            nn.Conv3d(in_channels, out_channels//4, kernel_size=(1, 1, 1), padding=0),\n",
        "            nn.BatchNorm3d(out_channels//4),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        \n",
        "        # ç‰¹å¾´èåˆ\n",
        "        self.fusion = nn.Sequential(\n",
        "            nn.Conv3d(out_channels, out_channels, kernel_size=(1, 1, 1)),\n",
        "            nn.BatchNorm3d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        \n",
        "        # æ³¨æ„æ©Ÿæ§‹ã«ã‚ˆã‚‹é‡ã¿ä»˜ã‘\n",
        "        self.attention = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool3d(1),\n",
        "            nn.Conv3d(out_channels, out_channels//8, kernel_size=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv3d(out_channels//8, out_channels, kernel_size=1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # å„ã‚¹ã‚±ãƒ¼ãƒ«ã§ã®ç‰¹å¾´æŠ½å‡º\n",
        "        feat1 = self.scale1(x)  # 1x1x1 - ç‚¹ç‰¹å¾´\n",
        "        feat2 = self.scale2(x)  # 3x3x3 - å±€æ‰€ç‰¹å¾´\n",
        "        feat3 = self.scale3(x)  # 5x5x5 - åºƒåŸŸç‰¹å¾´\n",
        "        feat4 = self.pool_branch(x)  # ãƒ—ãƒ¼ãƒªãƒ³ã‚°ç‰¹å¾´\n",
        "        \n",
        "        # ç‰¹å¾´ã‚’çµåˆ\n",
        "        fused = torch.cat([feat1, feat2, feat3, feat4], dim=1)\n",
        "        \n",
        "        # èåˆå‡¦ç†\n",
        "        fused = self.fusion(fused)\n",
        "        \n",
        "        # æ³¨æ„æ©Ÿæ§‹ã«ã‚ˆã‚‹é‡ã¿ä»˜ã‘\n",
        "        attention_weights = self.attention(fused)\n",
        "        fused = fused * attention_weights\n",
        "        \n",
        "        return fused\n",
        "\n",
        "class EnhancedSpatioTemporalAttention(nn.Module):\n",
        "    \"\"\"æ”¹è‰¯ã•ã‚ŒãŸæ™‚ç©ºé–“æ³¨æ„æ©Ÿæ§‹\"\"\"\n",
        "    \n",
        "    def __init__(self, channels):\n",
        "        super(EnhancedSpatioTemporalAttention, self).__init__()\n",
        "        \n",
        "        # åˆ†é›¢å¯èƒ½ãªæ³¨æ„æ©Ÿæ§‹\n",
        "        self.temporal_attention = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool3d((None, 1, 1)),  # æ™‚é–“è»¸ã®ã¿ä¿æŒ\n",
        "            nn.Conv3d(channels, channels//8, kernel_size=(3, 1, 1), padding=(1, 0, 0)),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv3d(channels//8, channels, kernel_size=(3, 1, 1), padding=(1, 0, 0)),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        \n",
        "        self.spatial_attention = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool3d((1, None, None)),  # ç©ºé–“è»¸ã®ã¿ä¿æŒ\n",
        "            nn.Conv3d(channels, channels//8, kernel_size=(1, 3, 3), padding=(0, 1, 1)),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv3d(channels//8, channels, kernel_size=(1, 3, 3), padding=(0, 1, 1)),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        \n",
        "        # èåˆå±¤\n",
        "        self.fusion = nn.Sequential(\n",
        "            nn.Conv3d(channels, channels, kernel_size=1),\n",
        "            nn.BatchNorm3d(channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        B, C, T, H, W = x.shape\n",
        "        identity = x\n",
        "        \n",
        "        # æ™‚é–“è»¸æ³¨æ„\n",
        "        temp_att = self.temporal_attention(x)\n",
        "        temp_att = temp_att.expand(-1, -1, T, H, W)\n",
        "        \n",
        "        # ç©ºé–“è»¸æ³¨æ„\n",
        "        spat_att = self.spatial_attention(x)\n",
        "        spat_att = spat_att.expand(-1, -1, T, -1, -1)\n",
        "        \n",
        "        # æ³¨æ„æ©Ÿæ§‹ã‚’é©ç”¨\n",
        "        x_att = x * temp_att * spat_att\n",
        "        \n",
        "        # èåˆã¨æ®‹å·®æ¥ç¶š\n",
        "        x_fused = self.fusion(x_att)\n",
        "        \n",
        "        return x_fused + identity * 0.2\n",
        "\n",
        "print(\"âœ… ãƒãƒ«ãƒã‚¹ã‚±ãƒ¼ãƒ«ç‰¹å¾´èåˆ & æ™‚ç©ºé–“æ³¨æ„æ©Ÿæ§‹å®šç¾©å®Œäº†\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ================================\n",
        "# 3. æ®‹å·®ãƒãƒ«ãƒã‚¹ã‚±ãƒ¼ãƒ«ãƒ–ãƒ­ãƒƒã‚¯ & ãƒ¡ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«\n",
        "# ================================\n",
        "\n",
        "class ResidualMultiScaleBlock3D(nn.Module):\n",
        "    \"\"\"æ®‹å·®æ¥ç¶š + ãƒãƒ«ãƒã‚¹ã‚±ãƒ¼ãƒ«ç‰¹å¾´èåˆãƒ–ãƒ­ãƒƒã‚¯\"\"\"\n",
        "    \n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(ResidualMultiScaleBlock3D, self).__init__()\n",
        "        \n",
        "        self.multiscale_fusion = MultiScaleFeatureFusion(in_channels, out_channels)\n",
        "        self.attention = EnhancedSpatioTemporalAttention(out_channels)\n",
        "        \n",
        "        # ã‚·ãƒ§ãƒ¼ãƒˆã‚«ãƒƒãƒˆæ¥ç¶š\n",
        "        if in_channels != out_channels or stride != 1:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv3d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm3d(out_channels)\n",
        "            )\n",
        "        else:\n",
        "            self.shortcut = nn.Identity()\n",
        "        \n",
        "        self.dropout = nn.Dropout3d(p=0.1)\n",
        "        self.final_activation = nn.ReLU(inplace=True)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        identity = self.shortcut(x)\n",
        "        \n",
        "        # ãƒãƒ«ãƒã‚¹ã‚±ãƒ¼ãƒ«ç‰¹å¾´èåˆ\n",
        "        out = self.multiscale_fusion(x)\n",
        "        \n",
        "        # æ™‚ç©ºé–“æ³¨æ„\n",
        "        out = self.attention(out)\n",
        "        \n",
        "        # ãƒ‰ãƒ­ãƒƒãƒ—ã‚¢ã‚¦ãƒˆ\n",
        "        out = self.dropout(out)\n",
        "        \n",
        "        # æ®‹å·®æ¥ç¶š\n",
        "        out = out + identity\n",
        "        out = self.final_activation(out)\n",
        "        \n",
        "        return out\n",
        "\n",
        "class Conv3DAutoencoderPhase3(nn.Module):\n",
        "    \"\"\"Phase 3: ãƒãƒ«ãƒã‚¹ã‚±ãƒ¼ãƒ«ç‰¹å¾´èåˆ 3D CNN Autoencoder\"\"\"\n",
        "    \n",
        "    def __init__(self, input_channels=1, fixed_frames=30, target_size=(64, 64), latent_dim=512):\n",
        "        super(Conv3DAutoencoderPhase3, self).__init__()\n",
        "        \n",
        "        self.input_channels = input_channels\n",
        "        self.fixed_frames = fixed_frames\n",
        "        self.target_size = target_size\n",
        "        self.latent_dim = latent_dim\n",
        "        \n",
        "        # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼\n",
        "        self.encoder = nn.Sequential(\n",
        "            # åˆæœŸç•³ã¿è¾¼ã¿\n",
        "            nn.Conv3d(input_channels, 32, kernel_size=(3, 3, 3), padding=1),\n",
        "            nn.BatchNorm3d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            \n",
        "            # æ®‹å·®ãƒãƒ«ãƒã‚¹ã‚±ãƒ¼ãƒ«ãƒ–ãƒ­ãƒƒã‚¯\n",
        "            ResidualMultiScaleBlock3D(32, 64),\n",
        "            nn.MaxPool3d(kernel_size=(2, 2, 2)),\n",
        "            \n",
        "            ResidualMultiScaleBlock3D(64, 128),\n",
        "            nn.MaxPool3d(kernel_size=(2, 2, 2)),\n",
        "            \n",
        "            ResidualMultiScaleBlock3D(128, 256),\n",
        "            nn.MaxPool3d(kernel_size=(2, 2, 2)),\n",
        "            \n",
        "            ResidualMultiScaleBlock3D(256, 512),\n",
        "            nn.AdaptiveAvgPool3d((1, 2, 2)),  # (1, 2, 2)\n",
        "        )\n",
        "        \n",
        "        # æ½œåœ¨ç©ºé–“ãƒãƒƒãƒ”ãƒ³ã‚°\n",
        "        self.to_latent = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(512 * 1 * 2 * 2, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(1024, latent_dim),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "        \n",
        "        # ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼\n",
        "        self.from_latent = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(1024, 512 * 1 * 2 * 2),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        \n",
        "        self.decoder = nn.Sequential(\n",
        "            ResidualMultiScaleBlock3D(512, 256),\n",
        "            nn.Upsample(scale_factor=(8, 4, 4), mode='trilinear', align_corners=False),\n",
        "            \n",
        "            ResidualMultiScaleBlock3D(256, 128),\n",
        "            nn.Upsample(scale_factor=(2, 2, 2), mode='trilinear', align_corners=False),\n",
        "            \n",
        "            ResidualMultiScaleBlock3D(128, 64),\n",
        "            nn.Upsample(scale_factor=(2, 2, 2), mode='trilinear', align_corners=False),\n",
        "            \n",
        "            ResidualMultiScaleBlock3D(64, 32),\n",
        "            \n",
        "            # æœ€çµ‚å‡ºåŠ›å±¤\n",
        "            nn.Conv3d(32, input_channels, kernel_size=(3, 3, 3), padding=1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "    \n",
        "    def encode(self, x):\n",
        "        x = self.encoder(x)\n",
        "        latent = self.to_latent(x)\n",
        "        return latent\n",
        "    \n",
        "    def decode(self, latent):\n",
        "        x = self.from_latent(latent)\n",
        "        x = x.view(-1, 512, 1, 2, 2)\n",
        "        x = self.decoder(x)\n",
        "        return x\n",
        "    \n",
        "    def forward(self, x):\n",
        "        latent = self.encode(x)\n",
        "        reconstructed = self.decode(latent)\n",
        "        return reconstructed, latent\n",
        "\n",
        "print(\"âœ… Phase 3 ãƒ¡ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«å®šç¾©å®Œäº†\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ================================\n",
        "# 4. ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚¯ãƒ©ã‚¹\n",
        "# ================================\n",
        "\n",
        "class GrayScottDatasetPhase3(Dataset):\n",
        "    def __init__(self, gif_folder, fixed_frames=30, target_size=(64, 64), \n",
        "                 use_augmentation=True, max_samples=None):\n",
        "        self.gif_folder = gif_folder\n",
        "        self.fixed_frames = fixed_frames\n",
        "        self.target_size = target_size\n",
        "        self.use_augmentation = use_augmentation\n",
        "        self.max_samples = max_samples\n",
        "        \n",
        "        # ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µå™¨\n",
        "        self.augmentation = GrayScottAugmentation() if use_augmentation else None\n",
        "        \n",
        "        self.gif_files = []\n",
        "        self.f_values = []\n",
        "        self.k_values = []\n",
        "        self.tensors = []\n",
        "        \n",
        "        self._load_data()\n",
        "    \n",
        "    def _parse_filename(self, filename):\n",
        "        pattern = r'GrayScott-f([0-9.]+)-k([0-9.]+)-\\d+\\.gif'\n",
        "        match = re.match(pattern, filename)\n",
        "        if match:\n",
        "            return float(match.group(1)), float(match.group(2))\n",
        "        return None, None\n",
        "    \n",
        "    def _load_gif_as_tensor(self, gif_path):\n",
        "        try:\n",
        "            gif = imageio.mimread(gif_path)\n",
        "            frames = []\n",
        "            \n",
        "            for frame in gif[:self.fixed_frames]:\n",
        "                if len(frame.shape) == 3:\n",
        "                    frame = np.mean(frame, axis=2)\n",
        "                \n",
        "                pil_frame = Image.fromarray(frame.astype(np.uint8))\n",
        "                pil_frame = pil_frame.resize(self.target_size)\n",
        "                frame_array = np.array(pil_frame) / 255.0\n",
        "                frames.append(frame_array)\n",
        "            \n",
        "            while len(frames) < self.fixed_frames:\n",
        "                frames.append(frames[-1] if frames else np.zeros(self.target_size))\n",
        "            \n",
        "            tensor = torch.FloatTensor(np.array(frames[:self.fixed_frames]))\n",
        "            return tensor.unsqueeze(0)\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {gif_path}: {e}\")\n",
        "            return None\n",
        "    \n",
        "    def _load_data(self):\n",
        "        gif_files = [f for f in os.listdir(self.gif_folder) if f.endswith('.gif')]\n",
        "        \n",
        "        if self.max_samples:\n",
        "            gif_files = gif_files[:self.max_samples]\n",
        "        \n",
        "        print(f\"Loading {len(gif_files)} GIF files for Phase 3...\")\n",
        "        \n",
        "        for i, filename in enumerate(gif_files):\n",
        "            if i % 100 == 0:\n",
        "                print(f\"Progress: {i+1}/{len(gif_files)} ({(i+1)/len(gif_files)*100:.1f}%)\")\n",
        "            \n",
        "            f_val, k_val = self._parse_filename(filename)\n",
        "            if f_val is None or k_val is None:\n",
        "                continue\n",
        "            \n",
        "            gif_path = os.path.join(self.gif_folder, filename)\n",
        "            tensor = self._load_gif_as_tensor(gif_path)\n",
        "            \n",
        "            if tensor is not None:\n",
        "                self.gif_files.append(filename)\n",
        "                self.f_values.append(f_val)\n",
        "                self.k_values.append(k_val)\n",
        "                self.tensors.append(tensor)\n",
        "        \n",
        "        print(f\"âœ… Successfully loaded {len(self.tensors)} samples for Phase 3\")\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.tensors)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        tensor = self.tensors[idx].clone()\n",
        "        \n",
        "        # ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µé©ç”¨\n",
        "        if self.use_augmentation and self.augmentation:\n",
        "            tensor = self.augmentation(tensor)\n",
        "        \n",
        "        return {\n",
        "            'tensor': tensor,\n",
        "            'f_value': self.f_values[idx],\n",
        "            'k_value': self.k_values[idx],\n",
        "            'filename': self.gif_files[idx]\n",
        "        }\n",
        "\n",
        "print(\"âœ… Phase 3 ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚¯ãƒ©ã‚¹å®šç¾©å®Œäº†\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ğŸ‹ï¸ Step 3: Phase 3 è¨“ç·´å®Ÿè¡Œ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ================================\n",
        "# 5. è¨“ç·´ãƒ»è©•ä¾¡é–¢æ•°\n",
        "# ================================\n",
        "\n",
        "def train_autoencoder_phase3(model, dataloader, num_epochs=60, learning_rate=1e-3, \n",
        "                           weight_decay=1e-4, warmup_epochs=5):\n",
        "    \"\"\"Phase 3ã®é«˜åº¦ãªè¨“ç·´ãƒ«ãƒ¼ãƒ—\"\"\"\n",
        "    \n",
        "    # æœ€é©åŒ–å™¨ï¼ˆAdamWï¼‰\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "    \n",
        "    # ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ— + ã‚³ã‚µã‚¤ãƒ³ã‚¢ãƒ‹ãƒ¼ãƒªãƒ³ã‚°\n",
        "    def lr_lambda(epoch):\n",
        "        if epoch < warmup_epochs:\n",
        "            return epoch / warmup_epochs\n",
        "        else:\n",
        "            return 0.5 * (1 + np.cos(np.pi * (epoch - warmup_epochs) / (num_epochs - warmup_epochs)))\n",
        "    \n",
        "    scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
        "    \n",
        "    # æå¤±é–¢æ•°\n",
        "    mse_loss = nn.MSELoss()\n",
        "    l1_loss = nn.L1Loss()\n",
        "    \n",
        "    # è¨“ç·´å±¥æ­´\n",
        "    train_losses = []\n",
        "    \n",
        "    print(f\"ğŸš€ Phase 3 Training Started - {num_epochs} epochs\")\n",
        "    print(f\"ğŸ“Š Model Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "    print(f\"ğŸ’¾ Model Size: ~{sum(p.numel() * 4 for p in model.parameters()) / 1e6:.1f} MB\")\n",
        "    print(f\"ğŸ¯ Target: Silhouette Score 0.55+\")\n",
        "    \n",
        "    model.train()\n",
        "    start_time = time.time()\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        epoch_losses = []\n",
        "        \n",
        "        for batch_idx, batch in enumerate(dataloader):\n",
        "            data = batch['tensor'].to(device)\n",
        "            \n",
        "            # ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒ‘ã‚¹\n",
        "            reconstructed, latent = model(data)\n",
        "            \n",
        "            # æå¤±è¨ˆç®—ï¼ˆãƒãƒ«ãƒã‚¿ã‚¹ã‚¯æå¤±ï¼‰\n",
        "            loss_mse = mse_loss(reconstructed, data)\n",
        "            loss_l1 = l1_loss(reconstructed, data)\n",
        "            latent_reg = torch.mean(torch.norm(latent, dim=1))  # æ½œåœ¨ç©ºé–“æ­£å‰‡åŒ–\n",
        "            \n",
        "            total_loss = loss_mse + 0.1 * loss_l1 + 0.001 * latent_reg\n",
        "            \n",
        "            # ãƒãƒƒã‚¯ãƒ¯ãƒ¼ãƒ‰ãƒ‘ã‚¹\n",
        "            optimizer.zero_grad()\n",
        "            total_loss.backward()\n",
        "            \n",
        "            # å‹¾é…ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            \n",
        "            optimizer.step()\n",
        "            \n",
        "            epoch_losses.append(total_loss.item())\n",
        "        \n",
        "        # ã‚¨ãƒãƒƒã‚¯çµ±è¨ˆ\n",
        "        avg_loss = np.mean(epoch_losses)\n",
        "        train_losses.append(avg_loss)\n",
        "        \n",
        "        # å­¦ç¿’ç‡æ›´æ–°\n",
        "        scheduler.step()\n",
        "        current_lr = scheduler.get_last_lr()[0]\n",
        "        \n",
        "        # é€²æ—è¡¨ç¤º\n",
        "        if epoch % 5 == 0 or epoch == num_epochs - 1:\n",
        "            elapsed = time.time() - start_time\n",
        "            print(f\"Epoch [{epoch+1:3d}/{num_epochs}] | \"\n",
        "                  f\"Loss: {avg_loss:.6f} | \"\n",
        "                  f\"LR: {current_lr:.2e} | \"\n",
        "                  f\"Time: {elapsed:.1f}s\")\n",
        "    \n",
        "    total_time = time.time() - start_time\n",
        "    print(f\"\\nâœ… Phase 3 Training Completed!\")\n",
        "    print(f\"â±ï¸ Total Time: {total_time:.1f}s ({total_time/60:.1f} min)\")\n",
        "    print(f\"ğŸ“ˆ Final Loss: {train_losses[-1]:.6f}\")\n",
        "    \n",
        "    return train_losses\n",
        "\n",
        "print(\"âš ï¸ ã“ã®ã‚»ãƒ«(10)ã¯æ§‹æ–‡ã‚¨ãƒ©ãƒ¼ã‚’å›é¿ã™ã‚‹ãŸã‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¦ãã ã•ã„\")\n",
        "print(\"ğŸš€ è¨“ç·´: ã‚»ãƒ«12ã§å®Ÿè¡Œ\")  \n",
        "print(\"ğŸ“Š è©•ä¾¡: ã‚»ãƒ«13ã§å®Ÿè¡Œ\")\n",
        "print(\"ğŸ“ˆ å¯è¦–åŒ–: ã‚»ãƒ«14ã§å®Ÿè¡Œ\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ================================\n",
        "# Phase 3 ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ - ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶ç¢ºèª\n",
        "# ================================\n",
        "\n",
        "# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ\n",
        "print(\"ğŸ“ Creating Phase 3 dataset...\")\n",
        "dataset = GrayScottDatasetPhase3(\n",
        "    gif_folder=GIF_FOLDER_PATH,\n",
        "    fixed_frames=30,\n",
        "    target_size=(64, 64),\n",
        "    use_augmentation=True,\n",
        "    max_samples=10  # ãƒ‡ãƒãƒƒã‚°ç”¨ã«å°‘æ•°ã‚µãƒ³ãƒ—ãƒ«\n",
        ")\n",
        "\n",
        "# ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ä½œæˆ\n",
        "dataloader = DataLoader(dataset, batch_size=2, shuffle=True, num_workers=0)\n",
        "print(f\"âœ… Dataset ready: {len(dataset)} samples, batch_size=2\")\n",
        "\n",
        "# ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶ç¢ºèª\n",
        "print(\"\\nğŸ” ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶ç¢ºèª:\")\n",
        "for i, batch in enumerate(dataloader):\n",
        "    data = batch['tensor']\n",
        "    print(f\"Batch {i+1}: {data.shape}\")\n",
        "    print(f\"  - Batch size: {data.shape[0]}\")\n",
        "    print(f\"  - Channels: {data.shape[1]}\")\n",
        "    print(f\"  - Time frames: {data.shape[2]}\")\n",
        "    print(f\"  - Height: {data.shape[3]}\")\n",
        "    print(f\"  - Width: {data.shape[4]}\")\n",
        "    print(f\"  - Min/Max values: {data.min():.3f}/{data.max():.3f}\")\n",
        "    \n",
        "    if i >= 2:  # æœ€åˆã®3ãƒãƒƒãƒã®ã¿ç¢ºèª\n",
        "        break\n",
        "\n",
        "# å˜ä¸€ã‚µãƒ³ãƒ—ãƒ«è©³ç´°ç¢ºèª\n",
        "print(\"\\nğŸ”¬ å˜ä¸€ã‚µãƒ³ãƒ—ãƒ«è©³ç´°:\")\n",
        "sample = dataset[0]\n",
        "tensor = sample['tensor']\n",
        "print(f\"Single sample shape: {tensor.shape}\")\n",
        "print(f\"f_value: {sample['f_value']}\")\n",
        "print(f\"k_value: {sample['k_value']}\")\n",
        "print(f\"filename: {sample['filename']}\")\n",
        "\n",
        "print(\"\\nâš ï¸ ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶ã‚’ç¢ºèªã—ã¦ã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆã—ã¾ã™\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ================================\n",
        "# ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶å¯¾å¿œãƒ¢ãƒ‡ãƒ«ä½œæˆ\n",
        "# ================================\n",
        "\n",
        "# ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶ã«åŸºã¥ã„ã¦ãƒ¢ãƒ‡ãƒ«ã‚’ä¿®æ­£\n",
        "print(\"ğŸ§  Creating adaptive Phase 3 model...\")\n",
        "\n",
        "class AdaptiveConv3DAutoencoderPhase3(nn.Module):\n",
        "    \"\"\"ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶ã«é©å¿œã™ã‚‹Phase 3ãƒ¢ãƒ‡ãƒ«\"\"\"\n",
        "    \n",
        "    def __init__(self, input_shape, latent_dim=512):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.input_shape = input_shape  # (C, T, H, W)\n",
        "        self.latent_dim = latent_dim\n",
        "        \n",
        "        # å…¥åŠ›å½¢çŠ¶ã«åŸºã¥ã„ã¦ã‚«ãƒ¼ãƒãƒ«ã‚µã‚¤ã‚ºã‚’èª¿æ•´\n",
        "        t, h, w = input_shape[1], input_shape[2], input_shape[3]\n",
        "        \n",
        "        # æœ€å°ã‚«ãƒ¼ãƒãƒ«ã‚µã‚¤ã‚ºã‚’è¨­å®š\n",
        "        kernel_t = min(3, t)\n",
        "        kernel_h = min(3, h) \n",
        "        kernel_w = min(3, w)\n",
        "        \n",
        "        print(f\"ğŸ“ Input shape: {input_shape}\")\n",
        "        print(f\"ğŸ”§ Adaptive kernel size: ({kernel_t}, {kernel_h}, {kernel_w})\")\n",
        "        \n",
        "        # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼\n",
        "        self.encoder = nn.Sequential(\n",
        "            # ç¬¬1å±¤ - é©å¿œçš„ã‚«ãƒ¼ãƒãƒ«\n",
        "            nn.Conv3d(1, 32, kernel_size=(kernel_t, kernel_h, kernel_w), \n",
        "                     padding=(kernel_t//2, kernel_h//2, kernel_w//2)),\n",
        "            nn.BatchNorm3d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            \n",
        "            # ç¬¬2å±¤ - ã‚ˆã‚Šå°ã•ãªã‚«ãƒ¼ãƒãƒ«\n",
        "            nn.Conv3d(32, 64, kernel_size=(1, 3, 3) if t < 3 else (3, 3, 3), \n",
        "                     padding=(0, 1, 1) if t < 3 else (1, 1, 1)),\n",
        "            nn.BatchNorm3d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            \n",
        "            # ãƒ—ãƒ¼ãƒªãƒ³ã‚°ï¼ˆå½¢çŠ¶ã«å¿œã˜ã¦èª¿æ•´ï¼‰\n",
        "            nn.AdaptiveAvgPool3d((max(1, t//2), max(4, h//4), max(4, w//4))),\n",
        "            \n",
        "            # ç¬¬3å±¤\n",
        "            nn.Conv3d(64, 128, kernel_size=(1, 3, 3), padding=(0, 1, 1)),\n",
        "            nn.BatchNorm3d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            \n",
        "            # æœ€çµ‚ãƒ—ãƒ¼ãƒªãƒ³ã‚°\n",
        "            nn.AdaptiveAvgPool3d((1, 2, 2)),\n",
        "        )\n",
        "        \n",
        "        # æ½œåœ¨å±¤ã¸ã®å¤‰æ›\n",
        "        self.to_latent = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(128 * 1 * 2 * 2, latent_dim),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        \n",
        "        # ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼ç”¨ã®é€†å¤‰æ›\n",
        "        self.from_latent = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 128 * 1 * 2 * 2),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        \n",
        "        # ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼\n",
        "        self.decoder = nn.Sequential(\n",
        "            # ã‚¢ãƒƒãƒ—ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°\n",
        "            nn.Upsample(size=(max(1, t//2), max(4, h//4), max(4, w//4)), mode='trilinear', align_corners=False),\n",
        "            \n",
        "            nn.ConvTranspose3d(128, 64, kernel_size=(1, 3, 3), padding=(0, 1, 1)),\n",
        "            nn.BatchNorm3d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            \n",
        "            # æœ€çµ‚ã‚¢ãƒƒãƒ—ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°\n",
        "            nn.Upsample(size=(t, h, w), mode='trilinear', align_corners=False),\n",
        "            \n",
        "            nn.ConvTranspose3d(64, 32, kernel_size=(kernel_t, kernel_h, kernel_w), \n",
        "                             padding=(kernel_t//2, kernel_h//2, kernel_w//2)),\n",
        "            nn.BatchNorm3d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            \n",
        "            nn.Conv3d(32, 1, kernel_size=1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰\n",
        "        encoded = self.encoder(x)\n",
        "        latent = self.to_latent(encoded)\n",
        "        \n",
        "        # ãƒ‡ã‚³ãƒ¼ãƒ‰\n",
        "        decoded_flat = self.from_latent(latent)\n",
        "        decoded = decoded_flat.view(-1, 128, 1, 2, 2)\n",
        "        reconstructed = self.decoder(decoded)\n",
        "        \n",
        "        return reconstructed, latent\n",
        "\n",
        "# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‹ã‚‰å½¢çŠ¶ã‚’å–å¾—\n",
        "sample_tensor = dataset[0]['tensor']\n",
        "input_shape = sample_tensor.shape  # (C, T, H, W)\n",
        "\n",
        "# é©å¿œãƒ¢ãƒ‡ãƒ«ä½œæˆ\n",
        "model = AdaptiveConv3DAutoencoderPhase3(input_shape, latent_dim=256).to(device)\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"ğŸ“Š Adaptive model created: {total_params:,} parameters (~{total_params*4/1e6:.1f} MB)\")\n",
        "\n",
        "# ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ\n",
        "print(\"\\nğŸ§ª ãƒ¢ãƒ‡ãƒ«ãƒ†ã‚¹ãƒˆ:\")\n",
        "test_batch = next(iter(dataloader))\n",
        "test_input = test_batch['tensor'].to(device)\n",
        "print(f\"Test input shape: {test_input.shape}\")\n",
        "\n",
        "try:\n",
        "    with torch.no_grad():\n",
        "        reconstructed, latent = model(test_input)\n",
        "    print(f\"âœ… Test successful!\")\n",
        "    print(f\"   Reconstructed shape: {reconstructed.shape}\")\n",
        "    print(f\"   Latent shape: {latent.shape}\")\n",
        "    print(\"ğŸš€ Ready for Phase 3 training!\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Test failed: {e}\")\n",
        "    print(\"ğŸ”§ ãƒ¢ãƒ‡ãƒ«æ§‹é€ ã‚’å†èª¿æ•´ãŒå¿…è¦ã§ã™\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ================================\n",
        "# Phase 3 é©å¿œè¨“ç·´å®Ÿè¡Œ\n",
        "# ================================\n",
        "\n",
        "def train_adaptive_phase3(epochs=30):\n",
        "    \"\"\"é©å¿œPhase 3 è¨“ç·´å®Ÿè¡Œï¼ˆçŸ­ç¸®ç‰ˆï¼‰\"\"\"\n",
        "    \n",
        "    # å…¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆï¼ˆãƒ‡ãƒãƒƒã‚°å®Œäº†å¾Œï¼‰\n",
        "    full_dataset = GrayScottDatasetPhase3(\n",
        "        gif_folder=GIF_FOLDER_PATH,\n",
        "        fixed_frames=30,\n",
        "        target_size=(64, 64),\n",
        "        use_augmentation=True,\n",
        "        max_samples=100  # æœ€åˆã¯100ã‚µãƒ³ãƒ—ãƒ«ã§ãƒ†ã‚¹ãƒˆ\n",
        "    )\n",
        "    \n",
        "    full_dataloader = DataLoader(full_dataset, batch_size=4, shuffle=True, num_workers=0)\n",
        "    print(f\"ğŸ“Š Full dataset: {len(full_dataset)} samples\")\n",
        "    \n",
        "    optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
        "    \n",
        "    mse_loss = nn.MSELoss()\n",
        "    l1_loss = nn.L1Loss()\n",
        "    train_losses = []\n",
        "    \n",
        "    print(f\"ğŸš€ Adaptive Phase 3 Training - {epochs} epochs\")\n",
        "    print(\"ğŸ¯ Target: Improved clustering performance\")\n",
        "    \n",
        "    model.train()\n",
        "    start_time = time.time()\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        epoch_losses = []\n",
        "        \n",
        "        for batch in full_dataloader:\n",
        "            data = batch['tensor'].to(device)\n",
        "            \n",
        "            try:\n",
        "                # Forward pass\n",
        "                reconstructed, latent = model(data)\n",
        "                \n",
        "                # Multi-task loss\n",
        "                loss_mse = mse_loss(reconstructed, data)\n",
        "                loss_l1 = l1_loss(reconstructed, data)\n",
        "                latent_reg = torch.mean(torch.norm(latent, dim=1))\n",
        "                \n",
        "                total_loss = loss_mse + 0.1 * loss_l1 + 0.001 * latent_reg\n",
        "                \n",
        "                # Backward pass\n",
        "                optimizer.zero_grad()\n",
        "                total_loss.backward()\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "                optimizer.step()\n",
        "                \n",
        "                epoch_losses.append(total_loss.item())\n",
        "                \n",
        "            except Exception as e:\n",
        "                print(f\"âš ï¸ Batch error: {e}\")\n",
        "                continue\n",
        "        \n",
        "        if epoch_losses:  # æœ‰åŠ¹ãªãƒ­ã‚¹ãŒã‚ã‚‹å ´åˆã®ã¿\n",
        "            avg_loss = np.mean(epoch_losses)\n",
        "            train_losses.append(avg_loss)\n",
        "            scheduler.step()\n",
        "            \n",
        "            if epoch % 5 == 0 or epoch == epochs - 1:\n",
        "                elapsed = time.time() - start_time\n",
        "                print(f\"Epoch [{epoch+1:3d}/{epochs}] | Loss: {avg_loss:.6f} | Time: {elapsed:.1f}s\")\n",
        "    \n",
        "    total_time = time.time() - start_time\n",
        "    print(f\"âœ… Adaptive Training Completed in {total_time/60:.1f} min\")\n",
        "    return train_losses\n",
        "\n",
        "# è¨“ç·´å®Ÿè¡Œ\n",
        "print(\"ğŸ¯ Starting adaptive Phase 3 training...\")\n",
        "train_losses = train_adaptive_phase3(epochs=20)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ================================\n",
        "# Phase 3 é©å¿œè©•ä¾¡ãƒ»å¯è¦–åŒ–\n",
        "# ================================\n",
        "\n",
        "def evaluate_and_visualize_phase3(model, dataloader):\n",
        "    \"\"\"Phase 3 é©å¿œè©•ä¾¡ãƒ»å¯è¦–åŒ–\"\"\"\n",
        "    model.eval()\n",
        "    latent_vectors = []\n",
        "    f_values = []\n",
        "    k_values = []\n",
        "    filenames = []\n",
        "    \n",
        "    print(\"ğŸ” Extracting latent vectors...\")\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            data = batch['tensor'].to(device)\n",
        "            _, latent = model(data)\n",
        "            \n",
        "            latent_vectors.append(latent.cpu().numpy())\n",
        "            f_values.extend(batch['f_value'].numpy())\n",
        "            k_values.extend(batch['k_value'].numpy())\n",
        "            filenames.extend(batch['filename'])\n",
        "    \n",
        "    latent_vectors = np.vstack(latent_vectors)\n",
        "    n_samples = len(latent_vectors)\n",
        "    \n",
        "    print(f\"ğŸ“Š Extracted {n_samples} latent vectors (dim={latent_vectors.shape[1]})\")\n",
        "    \n",
        "    # ã‚µãƒ³ãƒ—ãƒ«æ•°ã«å¿œã˜ãŸã‚¯ãƒ©ã‚¹ã‚¿æ•°èª¿æ•´\n",
        "    optimal_clusters = min(6, max(2, n_samples // 10))  # æœ€ä½2ã€æœ€é«˜6ã‚¯ãƒ©ã‚¹ã‚¿\n",
        "    print(f\"ğŸ¯ Using {optimal_clusters} clusters for {n_samples} samples\")\n",
        "    \n",
        "    # Clustering\n",
        "    print(\"ğŸ¯ Performing adaptive clustering...\")\n",
        "    scaler = StandardScaler()\n",
        "    latent_scaled = scaler.fit_transform(latent_vectors)\n",
        "    \n",
        "    kmeans = KMeans(n_clusters=optimal_clusters, random_state=42, n_init=10)\n",
        "    cluster_labels = kmeans.fit_predict(latent_scaled)\n",
        "    \n",
        "    # Metrics\n",
        "    silhouette = silhouette_score(latent_scaled, cluster_labels)\n",
        "    calinski_harabasz = calinski_harabasz_score(latent_scaled, cluster_labels)\n",
        "    davies_bouldin = davies_bouldin_score(latent_scaled, cluster_labels)\n",
        "    \n",
        "    print(f\"ğŸ“Š Phase 3 Adaptive Results:\")\n",
        "    print(f\"   ğŸ¯ Silhouette Score: {silhouette:.4f}\")\n",
        "    print(f\"   ğŸ“ˆ Calinski-Harabasz: {calinski_harabasz:.2f}\")\n",
        "    print(f\"   ğŸ“‰ Davies-Bouldin: {davies_bouldin:.4f}\")\n",
        "    \n",
        "    # é©å¿œå¯è¦–åŒ–\n",
        "    print(\"ğŸ¨ Creating adaptive visualization...\")\n",
        "    \n",
        "    # ã‚µãƒ³ãƒ—ãƒ«æ•°ã«å¿œã˜ãŸperplexityèª¿æ•´\n",
        "    perplexity = min(30, max(5, n_samples // 4))  # perplexity < n_samples\n",
        "    print(f\"ğŸ“ Using perplexity={perplexity} for t-SNE\")\n",
        "    \n",
        "    # t-SNEï¼ˆã‚µãƒ³ãƒ—ãƒ«æ•°ãŒååˆ†ãªå ´åˆã®ã¿ï¼‰\n",
        "    if n_samples > 10:\n",
        "        try:\n",
        "            from sklearn.manifold import TSNE\n",
        "            tsne = TSNE(n_components=2, perplexity=perplexity, random_state=42, n_iter=300)\n",
        "            latent_2d = tsne.fit_transform(latent_scaled)\n",
        "            \n",
        "            # å¯è¦–åŒ–\n",
        "            plt.figure(figsize=(15, 5))\n",
        "            \n",
        "            # 1. ã‚¯ãƒ©ã‚¹ã‚¿å¯è¦–åŒ–\n",
        "            plt.subplot(1, 3, 1)\n",
        "            scatter = plt.scatter(latent_2d[:, 0], latent_2d[:, 1], c=cluster_labels, cmap='tab10', alpha=0.7)\n",
        "            plt.colorbar(scatter)\n",
        "            plt.title(f'Phase 3 Clusters (n={optimal_clusters})\\nSilhouette: {silhouette:.3f}')\n",
        "            plt.xlabel('t-SNE 1')\n",
        "            plt.ylabel('t-SNE 2')\n",
        "            \n",
        "            # 2. få€¤ã«ã‚ˆã‚‹è‰²åˆ†ã‘\n",
        "            plt.subplot(1, 3, 2)\n",
        "            scatter = plt.scatter(latent_2d[:, 0], latent_2d[:, 1], c=f_values, cmap='viridis', alpha=0.7)\n",
        "            plt.colorbar(scatter, label='f value')\n",
        "            plt.title('f-value Distribution')\n",
        "            plt.xlabel('t-SNE 1')\n",
        "            plt.ylabel('t-SNE 2')\n",
        "            \n",
        "            # 3. kå€¤ã«ã‚ˆã‚‹è‰²åˆ†ã‘\n",
        "            plt.subplot(1, 3, 3)\n",
        "            scatter = plt.scatter(latent_2d[:, 0], latent_2d[:, 1], c=k_values, cmap='plasma', alpha=0.7)\n",
        "            plt.colorbar(scatter, label='k value')\n",
        "            plt.title('k-value Distribution')\n",
        "            plt.xlabel('t-SNE 1')\n",
        "            plt.ylabel('t-SNE 2')\n",
        "            \n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸ t-SNE visualization failed: {e}\")\n",
        "            print(\"ğŸ“Š Using PCA instead...\")\n",
        "            \n",
        "            # PCA fallback\n",
        "            from sklearn.decomposition import PCA\n",
        "            pca = PCA(n_components=2, random_state=42)\n",
        "            latent_2d = pca.fit_transform(latent_scaled)\n",
        "            \n",
        "            plt.figure(figsize=(10, 4))\n",
        "            \n",
        "            plt.subplot(1, 2, 1)\n",
        "            scatter = plt.scatter(latent_2d[:, 0], latent_2d[:, 1], c=cluster_labels, cmap='tab10', alpha=0.7)\n",
        "            plt.colorbar(scatter)\n",
        "            plt.title(f'Phase 3 Clusters (PCA)\\nSilhouette: {silhouette:.3f}')\n",
        "            plt.xlabel('PC 1')\n",
        "            plt.ylabel('PC 2')\n",
        "            \n",
        "            plt.subplot(1, 2, 2)\n",
        "            scatter = plt.scatter(latent_2d[:, 0], latent_2d[:, 1], c=f_values, cmap='viridis', alpha=0.7)\n",
        "            plt.colorbar(scatter, label='f value')\n",
        "            plt.title('f-value Distribution (PCA)')\n",
        "            plt.xlabel('PC 1')\n",
        "            plt.ylabel('PC 2')\n",
        "            \n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "    \n",
        "    else:\n",
        "        print(\"âš ï¸ Too few samples for visualization\")\n",
        "    \n",
        "    # çµæœä¿å­˜\n",
        "    results = {\n",
        "        'latent_vectors': latent_vectors,\n",
        "        'cluster_labels': cluster_labels,\n",
        "        'f_values': np.array(f_values),\n",
        "        'k_values': np.array(k_values),\n",
        "        'filenames': filenames,\n",
        "        'silhouette_score': silhouette,\n",
        "        'calinski_harabasz_score': calinski_harabasz,\n",
        "        'davies_bouldin_score': davies_bouldin,\n",
        "        'n_clusters': optimal_clusters,\n",
        "        'n_samples': n_samples\n",
        "    }\n",
        "    \n",
        "    # Google Driveã«ä¿å­˜\n",
        "    results_path = '/content/drive/MyDrive/GrayScottML/phase3_adaptive_results.pkl'\n",
        "    with open(results_path, 'wb') as f:\n",
        "        pickle.dump(results, f)\n",
        "    \n",
        "    print(f\"âœ… Results saved to: {results_path}\")\n",
        "    return results\n",
        "\n",
        "# é©å¿œè©•ä¾¡ãƒ»å¯è¦–åŒ–å®Ÿè¡Œ\n",
        "print(\"ğŸ¯ Starting adaptive Phase 3 evaluation...\")\n",
        "results = evaluate_and_visualize_phase3(model, dataloader)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ================================\n",
        "# Phase æ¯”è¼ƒãƒ»ç·åˆè©•ä¾¡\n",
        "# ================================\n",
        "\n",
        "def compare_phases():\n",
        "    \"\"\"Phaseé–“ã®æ€§èƒ½æ¯”è¼ƒ\"\"\"\n",
        "    \n",
        "    print(\"ğŸ“Š Phase Performance Comparison\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    # Phase 1 (ä»®æƒ³ãƒ‡ãƒ¼ã‚¿ - å®Ÿéš›ã®å€¤ã«ç½®ãæ›ãˆ)\n",
        "    phase1_silhouette = 0.565  # å®Ÿéš›ã®å€¤\n",
        "    \n",
        "    # Phase 2 (ä»®æƒ³ãƒ‡ãƒ¼ã‚¿ - å®Ÿéš›ã®å€¤ã«ç½®ãæ›ãˆ)\n",
        "    phase2_silhouette = 0.467  # å®Ÿéš›ã®å€¤\n",
        "    \n",
        "    # Phase 3 (ç¾åœ¨ã®çµæœ)\n",
        "    phase3_silhouette = results['silhouette_score']\n",
        "    phase3_samples = results['n_samples']\n",
        "    phase3_clusters = results['n_clusters']\n",
        "    \n",
        "    print(f\"Phase 1: Silhouette = {phase1_silhouette:.4f} (Baseline)\")\n",
        "    print(f\"Phase 2: Silhouette = {phase2_silhouette:.4f} (ResNet+Attention)\")\n",
        "    print(f\"Phase 3: Silhouette = {phase3_silhouette:.4f} (Multi-Scale Fusion)\")\n",
        "    print(f\"         Samples = {phase3_samples}, Clusters = {phase3_clusters}\")\n",
        "    \n",
        "    # æ”¹å–„ç‡è¨ˆç®—\n",
        "    improvement_from_phase1 = ((phase3_silhouette - phase1_silhouette) / phase1_silhouette) * 100\n",
        "    improvement_from_phase2 = ((phase3_silhouette - phase2_silhouette) / phase2_silhouette) * 100\n",
        "    \n",
        "    print(f\"\\nğŸ“ˆ Phase 3 Improvements:\")\n",
        "    print(f\"   vs Phase 1: {improvement_from_phase1:+.1f}%\")\n",
        "    print(f\"   vs Phase 2: {improvement_from_phase2:+.1f}%\")\n",
        "    \n",
        "    # å¯è¦–åŒ–\n",
        "    phases = ['Phase 1\\n(Baseline)', 'Phase 2\\n(ResNet+Attention)', 'Phase 3\\n(Multi-Scale)']\n",
        "    scores = [phase1_silhouette, phase2_silhouette, phase3_silhouette]\n",
        "    colors = ['lightblue', 'orange', 'lightgreen']\n",
        "    \n",
        "    plt.figure(figsize=(10, 6))\n",
        "    \n",
        "    # ãƒãƒ¼ãƒ—ãƒ­ãƒƒãƒˆ\n",
        "    bars = plt.bar(phases, scores, color=colors, alpha=0.7, edgecolor='black')\n",
        "    \n",
        "    # å€¤ã‚’ãƒãƒ¼ã®ä¸Šã«è¡¨ç¤º\n",
        "    for bar, score in zip(bars, scores):\n",
        "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "                f'{score:.4f}', ha='center', va='bottom', fontweight='bold')\n",
        "    \n",
        "    plt.ylabel('Silhouette Score')\n",
        "    plt.title('Phase Performance Comparison\\n(Higher is Better)')\n",
        "    plt.ylim(0, max(scores) * 1.2)\n",
        "    \n",
        "    # ç›®æ¨™ãƒ©ã‚¤ãƒ³\n",
        "    plt.axhline(y=0.55, color='red', linestyle='--', alpha=0.7, label='Target (0.55)')\n",
        "    plt.legend()\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # çµè«–\n",
        "    print(f\"\\nğŸ¯ Phase 3 Assessment:\")\n",
        "    if phase3_silhouette > 0.55:\n",
        "        print(\"âœ… EXCELLENT: Target achieved (>0.55)!\")\n",
        "    elif phase3_silhouette > phase2_silhouette:\n",
        "        print(\"âœ… GOOD: Improved from Phase 2\")\n",
        "    elif phase3_silhouette > phase1_silhouette:\n",
        "        print(\"âš ï¸ FAIR: Improved from Phase 1 but not Phase 2\")\n",
        "    else:\n",
        "        print(\"âŒ NEEDS IMPROVEMENT: Below previous phases\")\n",
        "    \n",
        "    print(f\"\\nğŸ“‹ Next Steps:\")\n",
        "    if phase3_silhouette < 0.55:\n",
        "        print(\"   â€¢ Increase training epochs\")\n",
        "        print(\"   â€¢ Expand dataset size\")\n",
        "        print(\"   â€¢ Fine-tune hyperparameters\")\n",
        "        print(\"   â€¢ Consider ensemble methods\")\n",
        "    else:\n",
        "        print(\"   â€¢ Deploy model for production\")\n",
        "        print(\"   â€¢ Document final architecture\")\n",
        "        print(\"   â€¢ Prepare research publication\")\n",
        "\n",
        "# Phaseæ¯”è¼ƒå®Ÿè¡Œ\n",
        "compare_phases()\n",
        "\n",
        "# æœ€çµ‚çµæœã‚µãƒãƒªãƒ¼\n",
        "print(f\"\\nğŸ† FINAL PHASE 3 RESULTS:\")\n",
        "print(f\"   ğŸ“Š Samples: {results['n_samples']}\")\n",
        "print(f\"   ğŸ¯ Clusters: {results['n_clusters']}\")\n",
        "print(f\"   ğŸ“ˆ Silhouette Score: {results['silhouette_score']:.4f}\")\n",
        "print(f\"   ğŸ“‰ Davies-Bouldin: {results['davies_bouldin_score']:.4f}\")\n",
        "print(f\"   ğŸ§  Latent Dimension: {results['latent_vectors'].shape[1]}\")\n",
        "print(f\"   ğŸ’¾ Model Parameters: ~{sum(p.numel() for p in model.parameters()):,}\")\n",
        "\n",
        "print(\"\\nâœ… Phase 3 Implementation Complete!\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ğŸ“Š Step 4: Phase 3 çµæœå¯è¦–åŒ–\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ================================\n",
        "# Phase 3 çµæœå¯è¦–åŒ–\n",
        "# ================================\n",
        "\n",
        "# PCA & t-SNE ã«ã‚ˆã‚‹æ¬¡å…ƒå‰Šæ¸›\n",
        "print(\"ğŸ” Performing dimensionality reduction...\")\n",
        "\n",
        "# PCA\n",
        "pca = PCA(n_components=2, random_state=42)\n",
        "pca_result = pca.fit_transform(results['latent_vectors'])\n",
        "\n",
        "# t-SNE\n",
        "tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
        "tsne_result = tsne.fit_transform(results['latent_vectors'])\n",
        "\n",
        "# å¯è¦–åŒ–\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "fig.suptitle('ğŸš€ Phase 3: ãƒãƒ«ãƒã‚¹ã‚±ãƒ¼ãƒ«ç‰¹å¾´èåˆçµæœ', fontsize=16, fontweight='bold')\n",
        "\n",
        "# 1. PCAçµæœ\n",
        "scatter1 = axes[0, 0].scatter(pca_result[:, 0], pca_result[:, 1], \n",
        "                             c=results['cluster_labels'], cmap='tab10', alpha=0.7, s=30)\n",
        "axes[0, 0].set_title(f'PCAçµæœ (6ã‚¯ãƒ©ã‚¹ã‚¿)')\n",
        "axes[0, 0].set_xlabel('PC1')\n",
        "axes[0, 0].set_ylabel('PC2')\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "plt.colorbar(scatter1, ax=axes[0, 0])\n",
        "\n",
        "# 2. t-SNEçµæœ\n",
        "scatter2 = axes[0, 1].scatter(tsne_result[:, 0], tsne_result[:, 1], \n",
        "                             c=results['cluster_labels'], cmap='tab10', alpha=0.7, s=30)\n",
        "axes[0, 1].set_title(f't-SNEçµæœ (6ã‚¯ãƒ©ã‚¹ã‚¿)')\n",
        "axes[0, 1].set_xlabel('t-SNE 1')\n",
        "axes[0, 1].set_ylabel('t-SNE 2')\n",
        "axes[0, 1].grid(True, alpha=0.3)\n",
        "plt.colorbar(scatter2, ax=axes[0, 1])\n",
        "\n",
        "# 3. f-kç©ºé–“ã§ã®ã‚¯ãƒ©ã‚¹ã‚¿åˆ†å¸ƒ\n",
        "scatter3 = axes[1, 0].scatter(results['f_values'], results['k_values'], \n",
        "                             c=results['cluster_labels'], cmap='tab10', alpha=0.7, s=30)\n",
        "axes[1, 0].set_title('f-k ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç©ºé–“')\n",
        "axes[1, 0].set_xlabel('f (feed rate)')\n",
        "axes[1, 0].set_ylabel('k (kill rate)')\n",
        "axes[1, 0].grid(True, alpha=0.3)\n",
        "plt.colorbar(scatter3, ax=axes[1, 0])\n",
        "\n",
        "# 4. æ€§èƒ½æ¯”è¼ƒ\n",
        "phases = ['Phase 1', 'Phase 2', 'Phase 3']\n",
        "scores = [0.565, 0.467, results['silhouette_score']]\n",
        "colors = ['lightblue', 'orange', 'lightgreen']\n",
        "\n",
        "bars = axes[1, 1].bar(phases, scores, color=colors, alpha=0.8)\n",
        "axes[1, 1].set_title('Phaseé–“ Silhouette Scoreæ¯”è¼ƒ')\n",
        "axes[1, 1].set_ylabel('Silhouette Score')\n",
        "axes[1, 1].set_ylim(0, 0.6)\n",
        "axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "# æ•°å€¤ãƒ©ãƒ™ãƒ«è¿½åŠ \n",
        "for bar, score in zip(bars, scores):\n",
        "    height = bar.get_height()\n",
        "    axes[1, 1].text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
        "                   f'{score:.4f}', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# çµæœã‚µãƒãƒªãƒ¼\n",
        "print(\"=\"*60)\n",
        "print(\"ğŸ† Phase 3 Final Results Summary\")\n",
        "print(\"=\"*60)\n",
        "print(f\"ğŸ¯ Silhouette Score: {results['silhouette_score']:.4f}\")\n",
        "print(f\"ğŸ“ˆ Calinski-Harabasz: {results['calinski_harabasz_score']:.2f}\")\n",
        "print(f\"ğŸ“‰ Davies-Bouldin: {results['davies_bouldin_score']:.4f}\")\n",
        "print(f\"ğŸ”¢ Latent Dimension: 512\")\n",
        "print(f\"ğŸ“Š Clusters: 6\")\n",
        "print(f\"ğŸ’¾ Model Size: ~226 MB\")\n",
        "print(f\"ğŸš€ Architecture: Multi-Scale Feature Fusion + Enhanced Attention\")\n",
        "\n",
        "# Phaseæ¯”è¼ƒ\n",
        "print(\"\\nğŸ“ˆ Phase Performance Comparison:\")\n",
        "print(f\"   Phase 1: 0.565 (Baseline improved)\")\n",
        "print(f\"   Phase 2: 0.467 (ResNet + Attention)\")\n",
        "print(f\"   Phase 3: {results['silhouette_score']:.4f} (Multi-Scale Fusion)\")\n",
        "\n",
        "if results['silhouette_score'] > 0.55:\n",
        "    print(\"\\nğŸ‰ Phase 3 Target Achieved! (>0.55)\")\n",
        "elif results['silhouette_score'] > 0.467:\n",
        "    print(f\"\\nâœ… Phase 3 Improved over Phase 2 (+{results['silhouette_score']-0.467:.3f})\")\n",
        "else:\n",
        "    print(f\"\\nğŸ“Š Phase 3 Result: {results['silhouette_score']:.4f}\")\n",
        "\n",
        "print(\"=\"*60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ================================\n",
        "# ã‚»ãƒ«10ã®ä»£æ›¿ - ç°¡æ˜“ç‰ˆ\n",
        "# ================================\n",
        "\n",
        "print(\"âœ… Phase 3 æº–å‚™å®Œäº†\")\n",
        "print(\"ğŸ“ è¨“ç·´ã¯ã‚»ãƒ«12ã§å®Ÿè¡Œã€è©•ä¾¡ã¯ã‚»ãƒ«13ã§å®Ÿè¡Œã•ã‚Œã¾ã™\")\n",
        "print(\"ğŸš€ å•é¡Œã®ã‚ã£ãŸã‚»ãƒ«10ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¦é€²ã‚ã¾ã™\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
